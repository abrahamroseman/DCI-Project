{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cd1498-5696-429a-837f-aad22805da76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading in Packages and Data\n",
    "\n",
    "#Importing Packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "import matplotlib.gridspec as gridspec\n",
    "import xarray as xr\n",
    "import os; import time\n",
    "import pickle\n",
    "import h5py\n",
    "###############################################################\n",
    "def coefs(coefficients,degree):\n",
    "    coef=coefficients\n",
    "    coefs=\"\"\n",
    "    for n in range(degree, -1, -1):\n",
    "        string=f\"({coefficients[len(coef)-(n+1)]:.1e})\"\n",
    "        coefs+=string + f\"x^{n}\"\n",
    "        if n != 0:\n",
    "            coefs+=\" + \"\n",
    "    return coefs\n",
    "###############################################################\n",
    "\n",
    "# Importing Model Data\n",
    "check=False\n",
    "dir='/mnt/lustre/koa/koastore/torri_group/air_directory/DCI-Project/'\n",
    "\n",
    "# dx = 1 km; Np = 1M; Nt = 5 min\n",
    "data=xr.open_dataset(dir+'../cm1r20.3/run/cm1out_1km_5min.nc', decode_timedelta=True) #***\n",
    "parcel=xr.open_dataset(dir+'../cm1r20.3/run/cm1out_pdata_1km_5min_1e6.nc', decode_timedelta=True) #***\n",
    "res='1km';t_res='5min'\n",
    "Np_str='1e6'\n",
    "\n",
    "# # dx = 1km; Np = 50M\n",
    "# #Importing Model Data\n",
    "# dir2='/home/air673/koa_scratch/'\n",
    "# data=xr.open_dataset(dir2+'cm1out_1km_1min.nc', decode_timedelta=True) #***\n",
    "# parcel=xr.open_dataset(dir2+'cm1out_pdata_1km_1min_50M.nc', decode_timedelta=True) #***\n",
    "# res='1km'; t_res='1min'; Np_str='50e6'\n",
    "\n",
    "# # dx = 1km; Np = 50M; Nz = 95\n",
    "# #Importing Model Data\n",
    "# dir2='/home/air673/koa_scratch/'\n",
    "# data=xr.open_dataset(dir2+'cm1out_1km_1min_95nz.nc', decode_timedelta=True) #***\n",
    "# parcel=xr.open_dataset(dir2+'cm1out_pdata_1km_1min_95nz.nc', decode_timedelta=True) #***\n",
    "# res='1km'; t_res='1min_95nz'; Np_str='50e6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3296dc-3e84-47eb-bb15-2d1fc92a227b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "dir2='/mnt/lustre/koa/koastore/torri_group/air_directory/DCI-Project/'\n",
    "path=dir2+'../Functions/'\n",
    "sys.path.append(path)\n",
    "\n",
    "import NumericalFunctions\n",
    "from NumericalFunctions import * # import NumericalFunctions \n",
    "import PlottingFunctions\n",
    "from PlottingFunctions import * # import PlottingFunctions\n",
    "\n",
    "# # Get all functions in NumericalFunctions\n",
    "# import inspect\n",
    "# functions = [f[0] for f in inspect.getmembers(NumericalFunctions, inspect.isfunction)]\n",
    "# functions\n",
    "\n",
    "#####\n",
    "\n",
    "#Import StatisticalFunctions \n",
    "import sys\n",
    "dir2='/mnt/lustre/koa/koastore/torri_group/air_directory/DCI-Project/'\n",
    "path=dir2+'../Functions/'\n",
    "sys.path.append(path)\n",
    "\n",
    "import StatisticalFunctions\n",
    "from StatisticalFunctions import * # import NumericalFunctions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ca1e18-fad0-4324-92d1-7e85da85e539",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD VARIABLES\n",
    "################################################################################\n",
    "def LoadData(data_t,approximation):\n",
    "    horiz_avg=False #not using horizontal average, instead using model average \n",
    "    \n",
    "    #LOADING TERMS\n",
    "    th=data_t['th'].data\n",
    "    rv=data_t['qv'].data #called qv in cm1, but is really rv (\"mixing ratio\")\n",
    "    rl=data_t['qc'].data+data_t['qr'].data\n",
    "\n",
    "    if horiz_avg==False:\n",
    "        th0=data.isel(time=0)['th'][:,0,0].data[:, np.newaxis, np.newaxis]\n",
    "        rv0=data.isel(time=0)['qv'][:,0,0].data[:, np.newaxis, np.newaxis]\n",
    "        rl0=data.isel(time=0)['qc'][:,0,0].data[:, np.newaxis, np.newaxis]+data.isel(time=0)['qr'].data[:,0,0][:, np.newaxis, np.newaxis]\n",
    "\n",
    "    #MAKING MEAN TERMS\n",
    "    if horiz_avg==True:\n",
    "        #using horizontal average at each timestep\n",
    "        th_mean = np.mean(th, axis=(1, 2), keepdims=True)   # shape (z, 1, 1)\n",
    "        rv_mean = np.mean(rv, axis=(1, 2), keepdims=True)\n",
    "        rl_mean = np.mean(rl, axis=(1, 2), keepdims=True)\n",
    "\n",
    "    if horiz_avg==False:\n",
    "        #using first timestep single column, as in cm1\n",
    "        th_mean = th0.copy()\n",
    "        rv_mean = rv0.copy()\n",
    "        rl_mean = rl0.copy()\n",
    "\n",
    "    #MAKING PERTURBATION TERMS\n",
    "    th_prime = th - th_mean\n",
    "    rv_prime = rv - rv_mean\n",
    "    rl_prime = rl - rl_mean\n",
    "\n",
    "    #CALCULATING THETA_V_BAR\n",
    "    Rd=287.04; Rv=461.5; eps=Rd/Rv #located in cm1/src/constants.F \n",
    "    if approximation==True:\n",
    "        a=((1/eps) - 1) #~0.6077\n",
    "\n",
    "        if horiz_avg==True:\n",
    "            #using horizontal average at each timestep\n",
    "            th_v = th*(1+(a*rv)-rl)\n",
    "            th_v_mean = np.mean(th_v, axis=(1, 2), keepdims=True)\n",
    "\n",
    "        if horiz_avg==False:\n",
    "            #using first timestep single column, as in cm1\n",
    "            th_v_mean = th0*(1+(a*rv0)-rl0)\n",
    "        \n",
    "    # elif approximation==False:\n",
    "    #     a=((1/eps) - 1) #~0.6077\n",
    "\n",
    "    #     if horiz_avg==True:\n",
    "    #         #using horizontal average at each timestep\n",
    "    #         N=th*(1+(rv/eps)) #numerator\n",
    "    #         D=(1+rv+rl) #denominator\n",
    "    #         th_v = N/D\n",
    "    #         th_v_mean = np.mean(th_v, axis=(1, 2), keepdims=True)\n",
    "\n",
    "    #     if horiz_avg==False:\n",
    "    #         #using first timestep single column, as in cm1\n",
    "    #         N=th0*(1+(rv0/eps)) #numerator\n",
    "    #         D=(1+rv0+rl0) #denominator\n",
    "    #         th_v_mean = N/D\n",
    "    \n",
    "    return th,th_prime, rv,rv_prime, rl,rl_prime, th_v_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4c8def-3dfb-4ea5-a665-33b3ea0b8fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetTrueBuoyancy(data, data_t, model=False):\n",
    "    if model:\n",
    "        return data_t['buoyancy'].data  # Use model output directly\n",
    "    \n",
    "    # Constants\n",
    "    Rd = 287.04\n",
    "    Rv = 461.5\n",
    "    eps = Rd / Rv\n",
    "    a = (1 / eps) - 1  # ≈ 0.6077\n",
    "    g = 9.81\n",
    "\n",
    "    # Reference state (assumes (z,) or (z, 1, 1) for vertical profile)\n",
    "    th0 = data.isel(time=0)['th'][:, 0, 0].data[:, np.newaxis, np.newaxis]\n",
    "    rv0 = data.isel(time=0)['qv'][:, 0, 0].data[:, np.newaxis, np.newaxis]\n",
    "    rl0 = (data.isel(time=0)['qc'][:, 0, 0].data + data.isel(time=0)['qr'][:, 0, 0].data)[:, np.newaxis, np.newaxis]\n",
    "    \n",
    "    th_v_mean = th0 * (1 + a * rv0 - rl0)\n",
    "\n",
    "    # Time-varying fields\n",
    "    th = data_t['th'].data\n",
    "    rv = data_t['qv'].data\n",
    "    rl = (data_t['qc'] + data_t['qr']).data\n",
    "\n",
    "    th_v = th * (1 + a * rv - rl)\n",
    "\n",
    "    # Perturbation and buoyancy\n",
    "    th_v_prime = th_v - th_v_mean\n",
    "    buoyancy = g * th_v_prime / th_v_mean\n",
    "    return buoyancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4e173a-7a6f-4b80-94a2-0c3fb58f30aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BuoyancyDecompTerms(data_t, approximation):\n",
    "    #GETTING DATA\n",
    "    [th,th_prime, rv,rv_prime, rl,rl_prime, th_v_mean] = LoadData(data_t,approximation)\n",
    "\n",
    "    #CALCULATING VARIABLES\n",
    "    Rd=287.04; Rv=461.5; eps=Rd/Rv #located in cm1/src/constants.F \n",
    "    if approximation==True:\n",
    "        a=((1/eps) - 1) #~0.6077\n",
    "        D=th_v_mean\n",
    "\n",
    "        #MAKING INDIVIDUAL BUOYANCY TERMS (3 TOTAL)\n",
    "        N=(1+(a*rv)-rl)\n",
    "        th_term = N/D\n",
    "        N=(a*th)\n",
    "        rv_term = N/D\n",
    "        N=-th\n",
    "        rl_term = N/D\n",
    "\n",
    "        #also need to multiply by gravity constant g\n",
    "        g=9.81 #located in cm1/src/constants.F \n",
    "        th_term*=g; rv_term*=g; rl_term*=g\n",
    "\n",
    "        #also multiply by prime terms with each term\n",
    "        th_term*=th_prime\n",
    "        rv_term*=rv_prime\n",
    "        rl_term*=rl_prime\n",
    "\n",
    "    # elif approximation==False:\n",
    "    #     A=(1+(rv/eps))/(1+rv+rl)\n",
    "    #     D=th_v_mean\n",
    "\n",
    "    #     #SOME TERM CONSOLIDATIONS\n",
    "    #     B1=(1-eps+rl)\n",
    "    #     B2=(eps+rv)\n",
    "    #     B3=eps*((1+rv+rl)**2)\n",
    "\n",
    "    #     #MAKING INDIVIDUAL BUOYANCY TERMS (3 TOTAL)\n",
    "    #     N=A\n",
    "    #     th_term = N/D\n",
    "    #     N=th*B1/B3\n",
    "    #     rv_term = N/D\n",
    "    #     N=th*B2/B3\n",
    "    #     rl_term = N/D\n",
    "\n",
    "    #     #also need to multiply by gravity constant g\n",
    "    #     g=9.81 #located in cm1/src/constants.F \n",
    "    #     th_term*=g; rv_term*=g; rl_term*=g\n",
    "\n",
    "    #     #also multiply by prime terms with each term\n",
    "    #     th_term*=th_prime\n",
    "    #     rv_term*=rv_prime\n",
    "    #     rl_term*=rl_prime\n",
    "        \n",
    "\n",
    "    #CALCULATING BUOYANCY\n",
    "    buoyancy=GetTrueBuoyancy(data,data_t,model=False)\n",
    "\n",
    "    #STORING VARIABLES\n",
    "    VARS={\n",
    "        'buoyancy': buoyancy,\n",
    "        'th_term': th_term,\n",
    "        'rv_term': rv_term,\n",
    "        'rl_term': rl_term\n",
    "         }\n",
    "    return VARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09aa1e0-4d1c-4810-b668-ecb44b1c29cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetOutputName(approximation):\n",
    "    dir2='/mnt/lustre/koa/koastore/torri_group/air_directory/DCI-Project/'\n",
    "    # dir2='/mnt/lustre/koa/scratch/air673/'\n",
    "    if approximation==True:\n",
    "        out_file = dir2 + 'Variable_Calculation/OUTPUT/' + f'Buoyancy_Decomp_{res}_{t_res}.h5'\n",
    "    elif approximation==False:\n",
    "        out_file = dir2 + 'Variable_Calculation/OUTPUT/' + f'Buoyancy_Decomp_FULL_{res}_{t_res}.h5'\n",
    "    return out_file\n",
    "    \n",
    "def initiate_array(VarNames,approximation):\n",
    "    # Define array dimensions (adjust based on your data)\n",
    "    t_size = len(data['time'])  # Number of timesteps\n",
    "    z_size = len(data['zh'])    # Number of vertical levels\n",
    "    y_size = len(data['yh'])    # Number of y-axis points\n",
    "    x_size = len(data['xh'])    # Number of x-axis points\n",
    "\n",
    "    out_file=GetOutputName(approximation)\n",
    "\n",
    "    with h5py.File(out_file, 'a') as f:\n",
    "        for var_name in VarNames:\n",
    "            if var_name not in f:\n",
    "                f.create_dataset(\n",
    "                    var_name,\n",
    "                    shape=(t_size, z_size, y_size, x_size),\n",
    "                    maxshape=(None, z_size, y_size, x_size),\n",
    "                    dtype='float64',\n",
    "                    chunks=(1, z_size, y_size, x_size)\n",
    "                )\n",
    "\n",
    "def add_timestep_at_index(VARS, index, approximation):\n",
    "    out_file=GetOutputName(approximation)\n",
    "    \n",
    "    with h5py.File(out_file, 'a') as f:\n",
    "        for var_name, timestep_data in VARS.items():\n",
    "            if var_name in f:\n",
    "                f[var_name][index] = timestep_data\n",
    "            else:\n",
    "                raise KeyError(f\"Dataset '{var_name}' does not exist in {out_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80724eef-9233-4407-a125-f2c561bdaa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUNNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61280de5-5522-4f9a-bc09-c98d411294d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#MAKING ARRAY TO STORE THETA_E\n",
    "VarNames=['buoyancy','th_term','rv_term','rl_term']\n",
    "\n",
    "approximation=True #CHOOSE IF USING FIRST ORDER TAYLOR SERIES APPROXIMATION \n",
    "# approximation=False #CHOOSE IF NOT USING ANY APPROXIMATION (data will store will \"_FULL\" after) (difference is O(1e-6))\n",
    "initiate_array(VarNames,approximation)\n",
    "\n",
    "#CALCULATING AND APPENDING TO DATA EACH TIMESTEP\n",
    "for t in range(len(data['time'])):\n",
    "    if np.mod(t,1)==0: print(f'Current time {t}')\n",
    "    data_t=data.isel(time=t)\n",
    "    \n",
    "    VARS = BuoyancyDecompTerms(data_t, approximation)\n",
    "    add_timestep_at_index(VARS, t, approximation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0193483a-e31c-46fd-a281-ce35d98a33f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bdf0a2-6e24-433e-98cc-5c6e14558465",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed94e15-98fe-4e4d-9ac3-3cd002c96da2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43171041-0fb3-4a7a-9b00-fd736d6e6a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "# #READING BACK IN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7464010b-f240-4370-a0a6-fde4e3f54fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t=100\n",
    "# approximation=True\n",
    "# # approximation=False\n",
    "# in_file=GetOutputName(approximation)\n",
    "# #READING FINAL OUTPUT\n",
    "# dir2='/mnt/lustre/koa/koastore/torri_group/air_directory/DCI-Project/'\n",
    "# # dir2='/mnt/lustre/koa/scratch/air673/'\n",
    "# with h5py.File(in_file, 'a') as f:\n",
    "#     # Access the existing dataset 'MSE'\n",
    "#     th_term = f['th_term'][t]\n",
    "#     rv_term = f['rv_term'][t]\n",
    "#     rl_term = f['rl_term'][t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f61e18-470c-4c36-a516-5eaf95b580a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "# #TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddcc9b3-f3bf-449c-9a04-0716944503b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "# Setup and data loading - unchanged\n",
    "t = 500\n",
    "\n",
    "# First dataset (approximation=False)\n",
    "approximation = True\n",
    "# approximation = False\n",
    "in_file = GetOutputName(approximation)\n",
    "with h5py.File(in_file, 'a') as f:\n",
    "    th_term = f['th_term'][t]\n",
    "    rv_term = f['rv_term'][t]\n",
    "    rl_term = f['rl_term'][t]\n",
    "\n",
    "z_lev = 5\n",
    "\n",
    "one = th_term[z_lev]\n",
    "two = rv_term[z_lev]\n",
    "three = rl_term[z_lev]\n",
    "\n",
    "sum_terms=one+two+three\n",
    "\n",
    "# Second dataset (approximation=True)\n",
    "approximation = True\n",
    "in_file = GetOutputName(approximation)\n",
    "with h5py.File(in_file, 'a') as f:\n",
    "    buoyancy1 = f['buoyancy'][t] #*#*#\n",
    "    th_term_approx = f['th_term'][t]\n",
    "    rv_term_approx = f['rv_term'][t]\n",
    "    rl_term_approx = f['rl_term'][t]\n",
    "\n",
    "# Assuming `data` is loaded elsewhere, since you use data.isel(time=t)['buoyancy']\n",
    "data_t=data.isel(time=t); buoyancy1 = GetTrueBuoyancy(data,data_t,model=True) #*#*#\n",
    "buoyancy2 = th_term_approx + rv_term_approx + rl_term_approx  # RECONSTRUCTED BUOYANCY\n",
    "\n",
    "num_levels=20\n",
    "# Compute min/max for the first row based on sum_terms for consistent color scale\n",
    "vmin=buoyancy2[z_lev].min();vmax=buoyancy2[z_lev].max()\n",
    "levels_first_row = np.linspace(vmin, vmax, num_levels)\n",
    "\n",
    "b1 = buoyancy1[z_lev]\n",
    "b2 = buoyancy2[z_lev]\n",
    "diff = b1 - b2\n",
    "\n",
    "# Shared color levels for buoyancy plots (second row)\n",
    "vmin_b = min(b1.min(), b2.min())\n",
    "vmax_b = max(b1.max(), b2.max())\n",
    "vmax_sym = max(abs(vmin_b), abs(vmax_b))\n",
    "levels_shared = np.linspace(-vmax_sym, vmax_sym, num_levels)\n",
    "\n",
    "# Levels for difference plot (symmetric)\n",
    "diff_max = np.max(np.abs(diff))\n",
    "levels_diff = np.linspace(-diff_max, diff_max, num_levels)\n",
    "\n",
    "# Create figure and GridSpec layout 2x4 (4 plots in first row, 2 in second)\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "gs = GridSpec(2, 4, figure=fig, wspace=0.2, hspace=0.3)\n",
    "\n",
    "# First row: sum_terms first, then th_term, rv_term, rl_term\n",
    "ax_sum = fig.add_subplot(gs[0, 0])\n",
    "cs_sum = ax_sum.contourf(sum_terms, levels=levels_first_row, cmap=\"RdBu_r\",extend='both')\n",
    "ax_sum.set_title('Reconstructed (Sum of Terms)')\n",
    "ax_sum.set_xticks([])\n",
    "ax_sum.set_yticks([])\n",
    "\n",
    "ax_th = fig.add_subplot(gs[0, 1])\n",
    "cs_th = ax_th.contourf(one, levels=levels_first_row, cmap=\"RdBu_r\",extend='both')\n",
    "ax_th.set_title('th_term')\n",
    "ax_th.set_xticks([])\n",
    "ax_th.set_yticks([])\n",
    "\n",
    "ax_rv = fig.add_subplot(gs[0, 2])\n",
    "cs_rv = ax_rv.contourf(two, levels=levels_first_row, cmap=\"RdBu_r\",extend='both')\n",
    "ax_rv.set_title('rv_term')\n",
    "ax_rv.set_xticks([])\n",
    "ax_rv.set_yticks([])\n",
    "\n",
    "ax_rl = fig.add_subplot(gs[0, 3])\n",
    "cs_rl = ax_rl.contourf(three, levels=levels_first_row, cmap=\"RdBu_r\",extend='both')\n",
    "ax_rl.set_title('rl_term')\n",
    "ax_rl.set_xticks([])\n",
    "ax_rl.set_yticks([])\n",
    "\n",
    "# Second row: Model Buoyancy and Difference/Error (span 2 columns each)\n",
    "ax_buoy = fig.add_subplot(gs[1, 0:1])\n",
    "cs_buoy = ax_buoy.contourf(b1, levels=num_levels, cmap='RdBu_r')\n",
    "ax_buoy.set_title('Model Buoyancy')\n",
    "ax_buoy.set_xticks([])\n",
    "ax_buoy.set_yticks([])\n",
    "\n",
    "ax_diff = fig.add_subplot(gs[1, 2:4])\n",
    "cs_diff = ax_diff.contourf(diff, levels=num_levels, cmap='coolwarm')\n",
    "ax_diff.set_title('Difference (Model - Reconstructed)')\n",
    "ax_diff.set_xticks([])\n",
    "ax_diff.set_yticks([])\n",
    "\n",
    "# Colorbars — consistent fraction for all\n",
    "colorbar_fraction = 0.03\n",
    "\n",
    "# Shared colorbar for first row (4 plots)\n",
    "cbar1 = fig.colorbar(cs_sum, ax=[ax_sum, ax_th, ax_rv, ax_rl], orientation='vertical', fraction=colorbar_fraction, pad=0.04)\n",
    "cbar1.set_label('Terms')\n",
    "\n",
    "# Shared colorbar for second row Model Buoyancy\n",
    "cbar2 = fig.colorbar(cs_buoy, ax=ax_buoy, orientation='vertical', fraction=colorbar_fraction+0.015, pad=0.04)\n",
    "cbar2.set_label('Buoyancy')\n",
    "\n",
    "# Separate colorbar for difference\n",
    "cbar3 = fig.colorbar(cs_diff, ax=ax_diff, orientation='vertical', fraction=colorbar_fraction, pad=0.04)\n",
    "cbar3.set_label('Difference')\n",
    "\n",
    "fig.suptitle(f\"Compared Model Buoyancy and Reconstructed Buoyancy Approximation at {data['zh'][z_lev].data*1000:.0f} m\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "work"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
