{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e661fd2-d578-41ef-b048-a4b882a9ba28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading in Packages and Data\n",
    "\n",
    "#Importing Packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "import matplotlib.gridspec as gridspec\n",
    "import xarray as xr\n",
    "import os; import time\n",
    "import pickle\n",
    "import h5py\n",
    "###############################################################\n",
    "def coefs(coefficients,degree):\n",
    "    coef=coefficients\n",
    "    coefs=\"\"\n",
    "    for n in range(degree, -1, -1):\n",
    "        string=f\"({coefficients[len(coef)-(n+1)]:.1e})\"\n",
    "        coefs+=string + f\"x^{n}\"\n",
    "        if n != 0:\n",
    "            coefs+=\" + \"\n",
    "    return coefs\n",
    "###############################################################\n",
    "start_time = time.time();\n",
    "\n",
    "#Importing Model Data\n",
    "check=False\n",
    "dir='/mnt/lustre/koa/koastore/torri_group/air_directory/DCI-Project/'\n",
    "job_array=False;index_adjust=0\n",
    "ocean_fraction=2/8\n",
    "\n",
    "# dx = 1 km; Np = 1M; Nt = 5 min\n",
    "data1=xr.open_dataset(dir+'../cm1r20.3/run/cm1out_1km_5min.nc', decode_timedelta=True) #***\n",
    "parcel1=xr.open_dataset(dir+'../cm1r20.3/run/cm1out_pdata_1km_5min_1e6.nc', decode_timedelta=True) #***\n",
    "res='1km';t_res='5min'\n",
    "Np_str='1e6'\n",
    "\n",
    "# # dx = 1km; Np = 50M\n",
    "# #Importing Model Data\n",
    "# dir2='/home/air673/koa_scratch/'\n",
    "# data1=xr.open_dataset(dir2+'cm1out_1km_1min.nc', decode_timedelta=True) #***\n",
    "# parcel1=xr.open_dataset(dir2+'cm1out_pdata_1km_1min_50M.nc', decode_timedelta=True) #***\n",
    "# res='1km'; t_res='1min'; Np_str='50e6'\n",
    "\n",
    "# # dx = 1km; Np = 50M; Nz = 95\n",
    "# #Importing Model Data\n",
    "# dir2='/home/air673/koa_scratch/'\n",
    "# data1=xr.open_dataset(dir2+'cm1out_1km_1min_95nz.nc', decode_timedelta=True) #***\n",
    "# parcel1=xr.open_dataset(dir2+'cm1out_pdata_1km_1min_95nz.nc', decode_timedelta=True) #***\n",
    "# res='1km'; t_res='1min_95nz'; Np_str='50e6'\n",
    "\n",
    "# # dx = 250m; Np = 50M\n",
    "# #Importing Model Data\n",
    "# dir2='/home/air673/koa_scratch/'\n",
    "# data1=xr.open_dataset(dir2+'cm1out_250m_1min_50M.nc', decode_timedelta=True) #***\n",
    "# parcel1=xr.open_dataset(dir2+'cm1out_pdata_250m_1min_50M.nc', decode_timedelta=True) #***\n",
    "# res='250m'; t_res='1min'; Np_str='50e6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d759de-8dc1-428e-8d11-01d4da2e92a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################\n",
    "#MODEL AND ALGORITHM NUMERICAL PARAMETERS\n",
    "times=data1['time'].values/(1e9 * 60); times=times.astype(float);\n",
    "minutes=1/times[1] #1 / minutes per timestep = timesteps per minute\n",
    "kms=np.argmax(data1['xh'].values-data1['xh'][0].values >= 1) #finds how many x grids is 1 km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f759a2a1-cd92-4b97-953a-443424b74f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#JOB ARRAY SETUP\n",
    "def StartJobArray(num_jobs):\n",
    "    total_elements=len(data1['time']) #total num of variables\n",
    "    \n",
    "    if num_jobs >= total_elements:\n",
    "        raise ValueError(\"Number of jobs cannot be greater than or equal to total elements.\")\n",
    "    \n",
    "    job_range = total_elements // num_jobs  # Base size for each chunk\n",
    "    remaining = total_elements % num_jobs   # Number of chunks with 1 extra \n",
    "    \n",
    "    # Function to compute the start and end for each job_id\n",
    "    def get_job_range(job_id):\n",
    "        job_id-=1\n",
    "        # Add one extra element to the first 'remaining' chunks\n",
    "        start_job = job_id * job_range + min(job_id, remaining)\n",
    "        end_job = start_job + job_range + (1 if job_id < remaining else 0)\n",
    "    \n",
    "        if job_id == num_jobs - 1: \n",
    "            end_job = total_elements #- 1\n",
    "        return start_job, end_job\n",
    "    # def job_testing():\n",
    "    #     #TESTING\n",
    "    #     start=[];end=[]\n",
    "    #     for job_id in range(1,num_jobs+1):\n",
    "    #         start_job, end_job = get_job_range(job_id)\n",
    "    #         print(start_job,end_job)\n",
    "    #         start.append(start_job)\n",
    "    #         end.append(end_job)\n",
    "    #     print(np.all(start!=end))\n",
    "    #     print(len(np.unique(start))==len(start))\n",
    "    #     print(len(np.unique(end))==len(end))\n",
    "    # job_testing()\n",
    "    \n",
    "    job_id = int(os.environ.get('SLURM_ARRAY_TASK_ID', 0)) #this is the current SBATCH job id\n",
    "    if job_id==0: job_id=1\n",
    "    start_job, end_job = get_job_range(job_id)\n",
    "    index_adjust=start_job\n",
    "    # print(f'start_job = {start_job}, end_job = {end_job}')\n",
    "    return start_job,end_job,index_adjust,job_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61501f68-925f-4a6e-b305-ae30a441e367",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################################################\n",
    "#GENERAL FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee609b3-9a9a-473b-9335-818b3f14f225",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Data Functions\n",
    "def get_2dtime_data(data,varname,tlev,zlev):\n",
    "    cloud_var=data[varname].isel(time=tlev,zh=zlev).values\n",
    "    return cloud_var\n",
    "def get_3dtime_data(data,varname,tlev):\n",
    "    cloud_var=data[varname].isel(time=tlev).values\n",
    "    return cloud_var\n",
    "\n",
    "def get_conv(t):\n",
    "    import h5py\n",
    "    # print('calculating convergence and taking mean')\n",
    "    if res=='1km':\n",
    "        dir2='/mnt/lustre/koa/koastore/torri_group/air_directory/DCI-Project/'\n",
    "    elif res=='250m':\n",
    "        dir2='/home/air673/koa_scratch/'\n",
    "    file_path = dir2 + 'Variable_Calculation/' + 'Convergence' + f'_{res}_{t_res}.h5'\n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "        Conv = f['conv'][t+index_adjust] #*#*#* For JobArray\n",
    "    return Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8487c5fc-e03c-4a03-af50-fd1c8c42b609",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################################################\n",
    "#ALGORITHM FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289c262e-108b-442b-bb57-cfee87490dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for taking x and y derivatives (Gradient)\n",
    "def cd2d(f,dx,dy): #size not compatible, cant calculate adjacent gradient\n",
    "    ddx = (\n",
    "            f[:,:, 1:  ]\n",
    "            -\n",
    "            f[:,:, 0:-1]\n",
    "        ) / (\n",
    "        2 * dx\n",
    "    )\n",
    "    \n",
    "    ddy = (\n",
    "        f[:,1:, :]\n",
    "        -\n",
    "        f[:,0:-1, :]\n",
    "    ) / (\n",
    "        2 * dy\n",
    "    )\n",
    "    \n",
    "    return ddx, ddy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7276b41b-5527-4d71-9772-42669b80c85d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def find_SBZ_xmaxs():\n",
    "    # Define the directory and file path\n",
    "    if res=='1km':\n",
    "        dir2='/mnt/lustre/koa/koastore/torri_group/air_directory/DCI-Project/'\n",
    "    elif res=='250m':\n",
    "        dir2='/home/air673/koa_scratch/'\n",
    "    file_path = dir2 + 'Variable_Calculation/' + 'Convergence' + f'_{res}_{t_res}.h5'\n",
    "    \n",
    "    # Open the HDF5 file in read mode\n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "        # Access the 'conv' dataset\n",
    "        conv_dataset = f['conv']\n",
    "        \n",
    "        # Define the vertical level you are interested in\n",
    "        if res=='1km':\n",
    "            zlev = 4 #534m\n",
    "        elif res=='250m':\n",
    "            zlev= 10 #525m\n",
    "        \n",
    "        # Initialize a list to store the xmaxs for each time step\n",
    "        xmaxs_list = []\n",
    "\n",
    "        # Loop over each time step (axis=0 corresponds to time)\n",
    "        for t in range(conv_dataset.shape[0]):  # conv_dataset.shape[0] is the time dimension size\n",
    "            if t % 60 ==0: print(f\"current time {t}\")\n",
    "            # Read the relevant slice for this time step and vertical level\n",
    "            Conv_t_zlev = conv_dataset[t, zlev, :, :]  # Shape should be (y_size, x_size)\n",
    "            \n",
    "            # Calculate the mean across the y-axis\n",
    "            Conv_ymean = np.mean(Conv_t_zlev, axis=0)  # Mean across the y-axis\n",
    "            \n",
    "            # Find the index of the maximum value along the x-axis\n",
    "            xmax = np.argmax(Conv_ymean)\n",
    "            \n",
    "            # Append the result for this time step\n",
    "            xmaxs_list.append(xmax)\n",
    "    \n",
    "    # Convert the list of xmaxs to a numpy array (optional)\n",
    "    xmaxs = np.array(xmaxs_list)\n",
    "\n",
    "    return xmaxs #returns SBZ x location for each timestep\n",
    "SBZ_MAXS=find_SBZ_xmaxs()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1375ae1f-9aad-404f-bba7-34133bbe9e71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SBZ_MAXS #X-level where SBZ is maximum at each timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0709efcf-c03e-4a84-bcf0-fd12825aed85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finds all local maximums (from Calculus) along each y level for a specific z level (~0.28km in this case)\n",
    "def find_local_maxes(conv_z,t,yind,conv_thresh,ONLY_SBZ):\n",
    "    xf=data['xf'].values\n",
    "    dx=np.round(data['xf'][1]-data['xf'][0],2).item() #grid resolution (in km) (can also be set to meters, since this function only finds the inflection points)\n",
    "\n",
    "    #indexes convergence in y\n",
    "    yconv=conv_z[yind,:]\n",
    "    \n",
    "    #takes dconv/dx\n",
    "    f=yconv\n",
    "    ddx = (\n",
    "            f[1:  ]\n",
    "            -\n",
    "            f[0:-1]\n",
    "        ) / (\n",
    "        2 * dx\n",
    "    )\n",
    "\n",
    "    ########################################################\n",
    "    #RUNNING\n",
    "    ########################################################\n",
    "    \n",
    "    #finds local max where dconv/dx sign changes\n",
    "    signs = np.sign(ddx)\n",
    "    signs_diff=np.diff(signs)\n",
    "    local_maxes=np.where((signs_diff != 0) & (signs_diff < 0))[0]+1 #make sure +1 is here (it corrects the location of the derivative)\n",
    "    local_maxes=local_maxes[np.where(yconv[local_maxes]>conv_thresh)] #check if convergence is greater than convergence threshold (1s-1)\n",
    "    local_maxes=local_maxes[(local_maxes>50*kms)&(local_maxes<len(xf)-50*kms)] #removes maxes that are with 50 km of y boundary\n",
    "    # local_maxes=local_maxes[local_maxes>int(len(xf)*ocean_fraction)] #restricts to right land side\n",
    "    if ONLY_SBZ==True:\n",
    "        local_maxes=local_maxes[(local_maxes>=SBZ_MAXS[t]-10*kms)&(local_maxes<=SBZ_MAXS[t]+10*kms)] #removes maxes that are with 50 km of y boundary\n",
    "\n",
    "    # ################################################################################\n",
    "    # #second round maxes (not 100% necessary, only if missing many convergence maximums that are visually there)\n",
    "    # yconv2=yconv.copy()\n",
    "    # yconv2[local_maxes]=0\n",
    "    # #takes dconv/dx\n",
    "    # f=yconv2\n",
    "    # ddx = (\n",
    "    #         f[1:  ]\n",
    "    #         -\n",
    "    #         f[0:-1]\n",
    "    #     ) / (\n",
    "    #     2 * dx\n",
    "    # )\n",
    "    # signs = np.sign(ddx)\n",
    "    # signs_diff=np.diff(signs)\n",
    "    # local_maxes2=np.where((signs_diff != 0) & (signs_diff < 0))[0]+1 #make sure +1 is here\n",
    "    # local_maxes2=local_maxes2[np.where(yconv2[local_maxes2]>conv_thresh)] #remove local maxes less than zero\n",
    "    # local_maxes2=local_maxes2[(local_maxes2>50*kms)&(local_maxes2<len(xf)-50*kms)] #removes maxes that are with 50 km of y boundary\n",
    "    # local_maxes2=local_maxes2[local_maxes2>int(len(xf)/2)] #restricts to right land side\n",
    "    # local_maxes=np.concatenate((local_maxes,local_maxes2))\n",
    "    # ################################################################################\n",
    "    return ddx,local_maxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a21482-5da9-43d8-83eb-5b0c0684d35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################################################\n",
    "#Calculation Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241f9b09-ed1e-4cc5-9e42-a227eaeccf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find_Local_Maxes Function\n",
    "#(1) At a single time and z level, runs through each y-level\n",
    "#(2) At each y-level, takes the x-derivative\n",
    "#(3) Take sign(x_derivative)\n",
    "#(4) Take diff(x_derivative)\n",
    "#(5) Max is located one index to the right of where derivative changes from positive to negative or diff is +1\n",
    "#[(6) Optional: the algorithm can run a second time over the leftover maxes after removing previous maxes from temporary variable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe7f568-51fa-4f85-8463-ad445e0deaa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#SBZ Convergence Line Search Algorithm (levels are seperate) (python version 3.10.9) (All Max Algorithm)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr; import time as time\n",
    "\n",
    "def layermax(t,ONLY_SBZ): #finds max convergence along y for multiple z location (5 is good)\n",
    "    num_zlevs=np.where(data['zh'].data<=0.775)[0][-1] #number of zlevels from surface to 775m\n",
    "\n",
    "    #making data to fill\n",
    "    maxconv_x=np.full((num_zlevs+1,len(data['yh']),len(data['xh'])), -1, dtype=int)\n",
    "    #RUNNING AGAIN FOR ALL LEVELS\n",
    "    for zlev in range(0,num_zlevs+1):\n",
    "        #Taking Convergence of current timesftep\n",
    "        conv=get_conv(t)\n",
    "        conv_z=conv[zlev,:,:] #current z level for convergence\n",
    "\n",
    "        for yind in range(0,len(data['yh'])): #plot maximums for each row\n",
    "            #setting convergence threshold\n",
    "            if res=='1km':\n",
    "                conv_thresh=1.0/1000\n",
    "            elif res==\"250m\":\n",
    "                conv_thresh=1.0/1000 #previously = 3.0/1000, may need to increase back later #*#*#\n",
    "\n",
    "            #finds all local maxes\n",
    "                [ddx,local_maxes]=find_local_maxes(conv_z,t,yind,conv_thresh,ONLY_SBZ) #convergence threshold (in 1/s)\n",
    "            \n",
    "            #storing data\n",
    "            maxconv_x[zlev,yind,local_maxes] = local_maxes\n",
    "    return maxconv_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffd3426-8d1b-4947-81c2-cf8dc6bc45e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUNNING ALGORITHM\n",
    "ONLY_SBZ=False\n",
    "# ONLY_SBZ=True\n",
    "def RunAlgorithm(data):\n",
    "    maxconv_x=layermax(0,ONLY_SBZ)\n",
    "    ds1= xr.Dataset({'maxconv_x': (['z','y','x'], maxconv_x)})\n",
    "    for t in range(1,len(data['time'])): #starts from timestep 1 to end\n",
    "        if np.mod(t,2)==0: print(f'current time step: {t}/{len(data[\"time\"])}')\n",
    "            \n",
    "        maxconv_x=layermax(t,ONLY_SBZ)\n",
    "        ds2= xr.Dataset({'maxconv_x': (['z','y','x'], maxconv_x)})\n",
    "        ds1=xr.concat([ds1, ds2], dim='time')\n",
    "    return ds1\n",
    "\n",
    "#SAVING DATA\n",
    "def SaveData(ds1,job_array):\n",
    "    print('saving')\n",
    "    output_folder = '/mnt/lustre/koa/koastore/torri_group/air_directory/DCI-Project/Project_Algorithms/Tracking_Algorithms/trackout/CL_tracking_plots/'\n",
    "    if ONLY_SBZ==False:\n",
    "        output_folder += 'ALL_CLS/'\n",
    "    elif ONLY_SBZ==True:\n",
    "        output_folder += 'ONLY_SBZS'\n",
    "    if job_array==False:\n",
    "        output_folder2 = '/mnt/lustre/koa/koastore/torri_group/air_directory/DCI-Project/Project_Algorithms/Tracking_Algorithms/'\n",
    "    elif job_array==True:\n",
    "        output_folder2 = '/mnt/lustre/koa/koastore/torri_group/air_directory/DCI-Project/Project_Algorithms/Tracking_Algorithms/CL_Tracking_Out/'\n",
    "    \n",
    "    if ONLY_SBZ==False:\n",
    "        out_name=output_folder2+f'whereCL_{res}_{t_res}_ALL_CLS'    \n",
    "    elif ONLY_SBZ==True:\n",
    "        out_name=output_folder2+f'whereCL_{res}_{t_res}_ONLY_SBZS'\n",
    "    if job_array==True:\n",
    "        out_name+=f'_{job_id}'\n",
    "    out_name+=f'.nc'\n",
    "    ds1.to_netcdf(out_name) \n",
    "    print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2b08e1-3501-46ac-a798-82d31763327f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#JOB_ARRAY SETUP\n",
    "########################################\n",
    "# job_array=False\n",
    "job_array=True \n",
    "num_jobs=150\n",
    "########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c63948-f8dc-4dc5-a49e-ef770787661f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "#RUNNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f5ea5e-6297-41cf-9685-fb486f31f0af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time=time.time()\n",
    "if job_array==True:\n",
    "    [start_job,end_job,index_adjust,job_id]=StartJobArray(num_jobs=num_jobs)\n",
    "    print(f\"job_id = {job_id} ==> Running for t = [{start_job},{end_job}]\")\n",
    "    data=data1.isel(time=slice(start_job,end_job))\n",
    "else:\n",
    "    index_adjust=0; data=data1.copy()\n",
    "ds1=RunAlgorithm(data)\n",
    "SaveData(ds1,job_array) \n",
    "\n",
    "end_time = time.time(); elapsed_time = end_time - start_time; print(f\"Total Elapsed Time: {elapsed_time} seconds\")\n",
    "\n",
    "# #PLOTTING TEST\n",
    "# ds1['maxconv_x'].isel(time=0,z=7).plot(figsize=(15, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6205fe12-e68d-4f54-9aa8-633d30761fc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0d02ec-ee91-44bd-b3fc-29ef5af5b123",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RECOMBINING\n",
    "recombine=False\n",
    "# recombine=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84799891-c9ab-44c4-9fd7-d67565c544ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "if recombine == True:\n",
    "    def RecombineDask(ONLY_SBZ, num_jobs):\n",
    "        base_path = '/mnt/lustre/koa/koastore/torri_group/air_directory/DCI-Project/Project_Algorithms/Tracking_Algorithms/CL_Tracking_Out/' #*#*\n",
    "        varname = 'ALL_CLS' if not ONLY_SBZ else 'ONLY_SBZS'\n",
    "\n",
    "        filepaths = [f'{base_path}whereCL_{res}_{t_res}_{varname}_{job_id}.nc'\n",
    "                     for job_id in range(1, num_jobs + 1)]\n",
    "        \n",
    "        ds = xr.open_mfdataset(\n",
    "            filepaths,\n",
    "            concat_dim='time',\n",
    "            combine='nested',\n",
    "            parallel=True,\n",
    "            engine='netcdf4'\n",
    "        )\n",
    "\n",
    "        # Save lazily to avoid loading into memory\n",
    "        out_path = f'{base_path}../whereCL_{res}_{t_res}_{varname}.nc'\n",
    "        print(f\"Saving combined dataset to: {out_path}\")\n",
    "\n",
    "        from dask.diagnostics import ProgressBar\n",
    "        with ProgressBar():\n",
    "            ds.to_netcdf(out_path, engine='netcdf4', compute=True)\n",
    "\n",
    "    RecombineDask(ONLY_SBZ, num_jobs=num_jobs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75cce72-a316-4012-8da2-dba19b049926",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d221ac9f-bfb2-47b4-acc1-aa6196b7bd88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de768e0-a680-4fce-aa4c-83354e9b2c85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77ee748-7b30-495d-99e4-0ae611bd0b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #TESTING\n",
    "#################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1f1bf2-7e57-4cc9-9513-216a2ee3e338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #TESTING COMPARING TO VERSION2\n",
    "# ######\n",
    "# load_dir = '/mnt/lustre/koa/koastore/torri_group/air_directory/DCI-Project/Project_Algorithms/Tracking_Algorithms/CL_Tracking_Out/'\n",
    "# open_name = load_dir+f'whereCL_{res}_{t_res}_ALL_CLS_50.nc'\n",
    "# hey=xr.open_dataset(open_name)['maxconv_x']\n",
    "# print(np.where(hey!=-1))\n",
    "# hey.isel(time=0,z=7).plot()\n",
    "\n",
    "# ######\n",
    "# #TESTING COMPARING TO VERSION2\n",
    "# load_dir = '/mnt/lustre/koa/koastore/torri_group/air_directory/DCI-Project/Project_Algorithms/Tracking_Algorithms/'\n",
    "# open_name = load_dir+f'whereCL_{res}_{t_res}_ALL_CLS.nc'\n",
    "# out=xr.open_dataset(open_name)['maxconv_x']\n",
    "# print(np.all(hey==out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5a71a2-ab9a-496f-9ee7-fc7f381db6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #TESTING COMPARING TO VERSION2 (FULL DATA)\n",
    "# ######\n",
    "# #TESTING COMPARING TO VERSION2\n",
    "# load_dir = '/mnt/lustre/koa/koastore/torri_group/air_directory/DCI-Project/Project_Algorithms/Tracking_Algorithms/'\n",
    "# open_name = load_dir+f'whereCL_{res}_{t_res}_ALL_CLS.nc'\n",
    "# out1=xr.open_dataset(open_name)['maxconv_x']\n",
    "# ######\n",
    "# #TESTING COMPARING TO VERSION2\n",
    "# load_dir = '/mnt/lustre/koa/koastore/torri_group/air_directory/DCI-Project/Project_Algorithms/Tracking_Algorithms/CL_Tracking_Out/'\n",
    "# open_name = load_dir+f'whereCL_{res}_{t_res}_ALL_CLS.nc'\n",
    "# out2=xr.open_dataset(open_name)['maxconv_x']\n",
    "\n",
    "# #####\n",
    "# t=10\n",
    "# for t in np.arange(1,661,5):\n",
    "#     print(np.all(out1[t]==out2[t]).data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b262e6bf-25f4-4434-b640-2ae1863618ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
