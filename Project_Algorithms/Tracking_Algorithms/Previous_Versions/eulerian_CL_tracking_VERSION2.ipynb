{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e661fd2-d578-41ef-b048-a4b882a9ba28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading in Packages and Data\n",
    "\n",
    "#Importing Packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "import matplotlib.gridspec as gridspec\n",
    "import xarray as xr\n",
    "import os; import time\n",
    "import pickle\n",
    "import h5py\n",
    "###############################################################\n",
    "def coefs(coefficients,degree):\n",
    "    coef=coefficients\n",
    "    coefs=\"\"\n",
    "    for n in range(degree, -1, -1):\n",
    "        string=f\"({coefficients[len(coef)-(n+1)]:.1e})\"\n",
    "        coefs+=string + f\"x^{n}\"\n",
    "        if n != 0:\n",
    "            coefs+=\" + \"\n",
    "    return coefs\n",
    "###############################################################\n",
    "start_time = time.time();\n",
    "\n",
    "#Importing Model Data\n",
    "check=False\n",
    "dir='/mnt/lustre/koa/koastore/torri_group/air_directory/DCI-Project/'\n",
    "job_array=False;index_adjust=0\n",
    "ocean_fraction=2/8\n",
    "\n",
    "# # dx = 1 km; Np = 1M; Nt = 5 min\n",
    "# data=xr.open_dataset(dir+'../cm1r20.3/run/cm1out_1km_5min.nc') #***\n",
    "# parcel=xr.open_dataset(dir+'../cm1r20.3/run/cm1out_pdata_1km_5min_1e6.nc') #***\n",
    "# res='1km';t_res='5min'\n",
    "# Np_str='1e6'\n",
    "\n",
    "# # dx = 1km; Np = 50M\n",
    "# #Importing Model Data\n",
    "# dir2='/home/air673/koa_scratch/'\n",
    "# data=xr.open_dataset(dir2+'cm1out_1km_1min.nc') #***\n",
    "# parcel=xr.open_dataset(dir2+'cm1out_pdata_1km_1min_50M.nc') #***\n",
    "# res='1km'; t_res='1min'; Np_str='50e6'\n",
    "\n",
    "# dx = 1km; Np = 50M; Nz = 95\n",
    "#Importing Model Data\n",
    "dir2='/home/air673/koa_scratch/'\n",
    "data=xr.open_dataset(dir2+'cm1out_1km_1min_95nz.nc') #***\n",
    "parcel=xr.open_dataset(dir2+'cm1out_pdata_1km_1min_95nz.nc') #***\n",
    "res='1km'; t_res='1min_95nz'; Np_str='50e6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d759de-8dc1-428e-8d11-01d4da2e92a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################\n",
    "times=data['time'].values/(1e9 * 60); times=times.astype(float);\n",
    "minutes=1/times[1] #1 / minutes per timestep = timesteps per minute\n",
    "kms=np.argmax(data['xh'].values-data['xh'][0].values >= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f759a2a1-cd92-4b97-953a-443424b74f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #JOB ARRAY SETUP\n",
    "# job_array=True\n",
    "# if job_array==True:\n",
    "\n",
    "#     num_jobs=60 #how many total jobs are being run? i.e. array=1-100 ==> num_jobs=100 #***\n",
    "#     total_elements=len(parcel['xh']) #total num of variables\n",
    "\n",
    "#     if num_jobs >= total_elements:\n",
    "#         raise ValueError(\"Number of jobs cannot be greater than or equal to total elements.\")\n",
    "    \n",
    "#     job_range = total_elements // num_jobs  # Base size for each chunk\n",
    "#     remaining = total_elements % num_jobs   # Number of chunks with 1 extra \n",
    "    \n",
    "#     # Function to compute the start and end for each job_id\n",
    "#     def get_job_range(job_id):\n",
    "#         job_id-=1\n",
    "#         # Add one extra element to the first 'remaining' chunks\n",
    "#         start_job = job_id * job_range + min(job_id, remaining)\n",
    "#         end_job = start_job + job_range + (1 if job_id < remaining else 0)\n",
    "    \n",
    "#         if job_id == num_jobs - 1: \n",
    "#             end_job = total_elements #- 1\n",
    "#         return start_job, end_job\n",
    "#     # def job_testing():\n",
    "#     #     #TESTING\n",
    "#     #     start=[];end=[]\n",
    "#     #     for job_id in range(1,num_jobs+1):\n",
    "#     #         start_job, end_job = get_job_range(job_id)\n",
    "#     #         print(start_job,end_job)\n",
    "#     #         start.append(start_job)\n",
    "#     #         end.append(end_job)\n",
    "#     #     print(np.all(start!=end))\n",
    "#     #     print(len(np.unique(start))==len(start))\n",
    "#     #     print(len(np.unique(end))==len(end))\n",
    "#     # job_testing()\n",
    "    \n",
    "#     job_id = int(os.environ.get('SLURM_ARRAY_TASK_ID', 0)) #this is the current SBATCH job id\n",
    "#     if job_id==0: job_id=1\n",
    "#     start_job, end_job = get_job_range(job_id)\n",
    "#     job_adjust=start_job\n",
    "#     print(f'start_job = {start_job}, end_job = {end_job}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61501f68-925f-4a6e-b305-ae30a441e367",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################################################\n",
    "#GENERAL FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee609b3-9a9a-473b-9335-818b3f14f225",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Data Functions\n",
    "def get_2dtime_data(data,varname,tlev,zlev):\n",
    "    cloud_var=data[varname].isel(time=tlev,zh=zlev).values\n",
    "    return cloud_var\n",
    "def get_3dtime_data(data,varname,tlev):\n",
    "    cloud_var=data[varname].isel(time=tlev).values\n",
    "    return cloud_var\n",
    "\n",
    "def get_conv(t):\n",
    "    import h5py\n",
    "    # print('calculating convergence and taking mean')\n",
    "    dir2='/mnt/lustre/koa/koastore/torri_group/air_directory/DCI-Project/'\n",
    "    # file_path = dir2 + 'Variable_Calculation/' + 'Convergence' + f'_{res}_{t_res}' + '.h5'\n",
    "    file_path = dir2 + 'Variable_Calculation/' + 'Convergence' + f'_{res}_{t_res}.h5'\n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "        Conv = f['conv'][t]\n",
    "    return Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbf9b54-5a29-4ebe-a321-b23bf659c544",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TIME 00:00:00 Function\n",
    "#Gets the realtime for the current timestep\n",
    "def get_time(t):\n",
    "    # init_day,init_hour,init_min=0,0,0\n",
    "    init_day,init_hour,init_min=0,6,0\n",
    "    times=data['time'].values/(1e9 * 60); time_inc=times.astype(int)[1]-times.astype(int)[0]\n",
    "    current_min=init_hour*60+init_min+time_inc*t;\n",
    "    \n",
    "    days = init_day + (current_min // (24 * 60))\n",
    "    \n",
    "    remain_min = (init_min+time_inc*t) % (24 * 60); \n",
    "    hours = (init_hour + (remain_min // 60)) % 24\n",
    "    mins = remain_min % 60\n",
    "\n",
    "    ##############################################\n",
    "    days=str(days);hours=str(hours);mins=str(mins)\n",
    "    if len(days)==1:days='0'+days\n",
    "    if len(hours)==1:hours='0'+hours\n",
    "    if len(mins)==1:mins='0'+mins\n",
    "    ##############################################\n",
    "\n",
    "    combo=days+\":\"+hours+\":\"+mins\n",
    "    return days,hours,mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8487c5fc-e03c-4a03-af50-fd1c8c42b609",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################################################\n",
    "#ALGORITHM FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289c262e-108b-442b-bb57-cfee87490dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for taking x and y derivatives (Gradient)\n",
    "def cd2d(f,dx,dy): #size not compatible, cant calculate adjacent gradient\n",
    "    ddx = (\n",
    "            f[:,:, 1:  ]\n",
    "            -\n",
    "            f[:,:, 0:-1]\n",
    "        ) / (\n",
    "        2 * dx\n",
    "    )\n",
    "    \n",
    "    ddy = (\n",
    "        f[:,1:, :]\n",
    "        -\n",
    "        f[:,0:-1, :]\n",
    "    ) / (\n",
    "        2 * dy\n",
    "    )\n",
    "    \n",
    "    return ddx, ddy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a26eff-61b6-4131-88f7-052fa5197efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr; import time as time\n",
    "start_time=time.time()\n",
    "folder_path = '/mnt/lustre/koa/koastore/torri_group/air_directory/DCI-Project/Project_Algorithms/Tracking_Algorithms/trackout/CL_tracking_plots/' #*** plot image output foldername\n",
    "import os; os.makedirs(folder_path, exist_ok=True)\n",
    "####################################################################################################################################\n",
    "def user_deletion():\n",
    "    #reads user input for timesteps to forget as instructed by teh user in the usersbz.txt file\n",
    "    filename='usersbz_1km.txt' #*** timestep deletion filename\n",
    "    # filename='usersbz_250m.txt' #*** timestep deletion filename\n",
    "    a,b,c,d=[],[],[],[]\n",
    "    try:\n",
    "        with open(folder_path+filename, 'r') as file: #*switch to lbz for land breezes \n",
    "            for line in file:\n",
    "                line = line.strip()  # Remove leading/trailing whitespace\n",
    "                if ',' in line:\n",
    "                    if '-' not in line: #single case correction\n",
    "                        # For rows with commas, split and append to a, b, and c lists\n",
    "                        values = line.split(',')\n",
    "                        a.append(int(values[0]))\n",
    "                        b.append(int(values[1]))\n",
    "                        c.append(int(values[2]))\n",
    "                    elif '-' in line: #multiple case correction\n",
    "                        values = line.split(',')   \n",
    "                        start, end = map(int, values[0].split('-'))\n",
    "                        a.extend(range(start, end + 1))\n",
    "                        b=b+[int(values[1])]*((end-start)+1)\n",
    "                        c=c+[int(values[2])]*((end-start)+1)\n",
    "                elif '-' in line and ',' not in line: #ignore these\n",
    "                    # For rows with hyphen, append the range to d list\n",
    "                    start, end = map(int, line.split('-'))\n",
    "                    d.extend(range(start, end + 1))\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(f'The file {filename} does not exist. Add if needed.')\n",
    "    forget = d #needed for single and all max algorithm\n",
    "    return forget\n",
    "####################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7276b41b-5527-4d71-9772-42669b80c85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_SBZ_xmaxs():\n",
    "    # Define the directory and file path\n",
    "    dir2 = '/mnt/lustre/koa/koastore/torri_group/air_directory/DCI-Project/'\n",
    "    file_path = dir2 + 'Variable_Calculation/' + 'Convergence' + f'_{res}_{t_res}.h5'\n",
    "    \n",
    "    # Open the HDF5 file in read mode\n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "        # Access the 'conv' dataset\n",
    "        conv_dataset = f['conv']\n",
    "        \n",
    "        # Define the vertical level you are interested in\n",
    "        zlev = 4\n",
    "        \n",
    "        # Initialize a list to store the xmaxs for each time step\n",
    "        xmaxs_list = []\n",
    "\n",
    "        # Loop over each time step (axis=0 corresponds to time)\n",
    "        for t in range(conv_dataset.shape[0]):  # conv_dataset.shape[0] is the time dimension size\n",
    "            # Read the relevant slice for this time step and vertical level\n",
    "            Conv_t_zlev = conv_dataset[t, zlev, :, :]  # Shape should be (y_size, x_size)\n",
    "            \n",
    "            # Calculate the mean across the y-axis\n",
    "            Conv_ymean = np.mean(Conv_t_zlev, axis=0)  # Mean across the y-axis\n",
    "            \n",
    "            # Find the index of the maximum value along the x-axis\n",
    "            xmax = np.argmax(Conv_ymean)\n",
    "            \n",
    "            # Append the result for this time step\n",
    "            xmaxs_list.append(xmax)\n",
    "    \n",
    "    # Convert the list of xmaxs to a numpy array (optional)\n",
    "    xmaxs = np.array(xmaxs_list)\n",
    "\n",
    "    return xmaxs #returns SBZ x location for each timestep\n",
    "SBZ_MAXS=find_SBZ_xmaxs()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0709efcf-c03e-4a84-bcf0-fd12825aed85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finds all local maximums (from Calculus) along each y level for a specific z level (~0.28km in this case)\n",
    "def find_local_maxes(conv_z,t,yind,conv_thresh,ONLY_SBZ):\n",
    "    yconv=conv_z[yind,:]\n",
    "    xf=data['xf'].values.astype(int);\n",
    "    kms=np.argmax(data['xh'].values-data['xh'][0].values >= 1) #finds how many x grids is 1 km\n",
    "    dx=np.round(data['xf'][1]-data['xf'][0],1).item()\n",
    "    \n",
    "    #takes dconv/dx\n",
    "    f=yconv\n",
    "    ddx = (\n",
    "            f[1:  ]\n",
    "            -\n",
    "            f[0:-1]\n",
    "        ) / (\n",
    "        2 * dx\n",
    "    )\n",
    "\n",
    "    if np.any(np.isin(forget,t)): \n",
    "        local_maxes=np.full_like(local_maxes,np.nan,dtype=float); #forget timestep if in forget variable\n",
    "    else:\n",
    "        #finds local max where dconv/dx sign changes\n",
    "        signs = np.sign(ddx)\n",
    "        signs_diff=np.diff(signs)\n",
    "        local_maxes=np.where((signs_diff != 0) & (signs_diff < 0))[0]+1 #make sure +1 is here (it corrects the location of the derivative)\n",
    "        local_maxes=local_maxes[np.where(yconv[local_maxes]>conv_thresh)] #check if convergence is greater than convergence threshold (0.9s-1)\n",
    "        local_maxes=local_maxes[(local_maxes>50*kms)&(local_maxes<len(xf)-50*kms)] #removes maxes that are with 50 km of y boundary\n",
    "        # local_maxes=local_maxes[local_maxes>int(len(xf)*ocean_fraction)] #restricts to right land side\n",
    "        if ONLY_SBZ==True:\n",
    "            local_maxes=local_maxes[(local_maxes>=SBZ_MAXS[t]-10*kms)&(local_maxes<=SBZ_MAXS[t]+10*kms)] #removes maxes that are with 50 km of y boundary\n",
    "            # print(SBZ_MAXS[t]) #TESTING\n",
    "        # ################################################################################\n",
    "        # #second round maxes (not 100% necessary, only if missing many convergence maximums that are visually there)\n",
    "        # yconv2=yconv.copy()\n",
    "        # yconv2[local_maxes]=0\n",
    "        # #takes dconv/dx\n",
    "        # f=yconv2\n",
    "        # ddx = (\n",
    "        #         f[1:  ]\n",
    "        #         -\n",
    "        #         f[0:-1]\n",
    "        #     ) / (\n",
    "        #     2 * dx\n",
    "        # )\n",
    "        # signs = np.sign(ddx)\n",
    "        # signs_diff=np.diff(signs)\n",
    "        # local_maxes2=np.where((signs_diff != 0) & (signs_diff < 0))[0]+1 #make sure +1 is here\n",
    "        # local_maxes2=local_maxes2[np.where(yconv2[local_maxes2]>conv_thresh)] #remove local maxes less than zero\n",
    "        # local_maxes2=local_maxes2[(local_maxes2>50*kms)&(local_maxes2<len(xf)-50*kms)] #removes maxes that are with 50 km of y boundary\n",
    "        # local_maxes2=local_maxes2[local_maxes2>int(len(xf)/2)] #restricts to right land side\n",
    "        # local_maxes=np.concatenate((local_maxes,local_maxes2))\n",
    "        # ################################################################################\n",
    "    return ddx,local_maxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a21482-5da9-43d8-83eb-5b0c0684d35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################################################\n",
    "#Calculation Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241f9b09-ed1e-4cc5-9e42-a227eaeccf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find_Local_Maxes Function\n",
    "#(1) At a single time and z level, runs through each y-level\n",
    "#(2) At each y-level, takes the x-derivative\n",
    "#(3) Take sign(x_derivative)\n",
    "#(4) Take diff(x_derivative)\n",
    "#(5) Max is located one index to the right of where derivative changes from positive to negative or diff is +1\n",
    "#[(6) Optional: the algorithm can run a second time over the leftover maxes after removing previous maxes from temporary variable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe7f568-51fa-4f85-8463-ad445e0deaa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#SBZ Convergence Line Search Algorithm (levels are seperate) (python version 3.10.9) (All Max Algorithm)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr; import time as time\n",
    "start_time=time.time()\n",
    "####################################################################################################################################\n",
    "forget=user_deletion() #get forget variable for user specified timesteps to forget\n",
    "####################################################################################################################################\n",
    "\n",
    "def layermax(t,ONLY_SBZ): #finds max convergence along y for multiple z location (5 is good)\n",
    "    num_zlevs=16 #5\n",
    "    maxconv_x=np.full((num_zlevs+1,len(data['yh']),len(data['xh'])), -1, dtype=int)\n",
    "    #running again for all levels \n",
    "    for zlev in range(0,num_zlevs+1):\n",
    "        #Taking Convergence of current timestep\n",
    "        dx=np.round(data['xf'][1]-data['xf'][0],2).item();dy=dx #gets the dx,dy in meters (0.25m in this case)\n",
    "        conv=get_conv(t)\n",
    "    \n",
    "        conv_z=conv[zlev,:,:] #current z level for convergence\n",
    "\n",
    "        for yind in range(0,len(data['yh'])): #plot maximums for each row\n",
    "            #finds all local maxes\n",
    "            if res=='1km':\n",
    "                [ddx,local_maxes]=find_local_maxes(conv_z,t,yind,0.9/1000,ONLY_SBZ) #finds all local maxes with threshold 1km:0.9 250m:3.0\n",
    "            elif res=='250m':\n",
    "                [ddx,local_maxes]=find_local_maxes(conv_zt,yind,3.0/1000,ONLY_SBZ) #finds all local maxes with threshold 1km:0.9 250m:3.0\n",
    "            \n",
    "            #storing data\n",
    "            maxconv_x[zlev,yind,local_maxes] = local_maxes\n",
    "    return maxconv_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f5ea5e-6297-41cf-9685-fb486f31f0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "ONLY_SBZ=False\n",
    "# ONLY_SBZ=True\n",
    "#RUNNING ALGORITHM\n",
    "def RunAlgorithm():\n",
    "\n",
    "    maxconv_x=layermax(0,ONLY_SBZ)\n",
    "    ds1= xr.Dataset({'maxconv_x': (['z','y','x'], maxconv_x)})\n",
    "    for t in range(1,len(data['time'])): #starts from timestep 1 to end\n",
    "        if np.mod(t,10)==0: print(f'current time step: {t}/{len(data[\"time\"])}')\n",
    "            \n",
    "        maxconv_x=layermax(t,ONLY_SBZ)\n",
    "        ds2= xr.Dataset({'maxconv_x': (['z','y','x'], maxconv_x)})\n",
    "        ds1=xr.concat([ds1, ds2], dim='time')\n",
    "    return ds1\n",
    "RunAlgorithm()\n",
    "    \n",
    "\n",
    "#SAVING DATA\n",
    "def SaveData(ds1):\n",
    "    print('saving')\n",
    "    output_folder = '/mnt/lustre/koa/koastore/torri_group/air_directory/DCI-Project/Project_Algorithms/Tracking_Algorithms/trackout/CL_tracking_plots/'\n",
    "    if ONLY_SBZ==False:\n",
    "        output_folder += 'ALL_CLS/'\n",
    "    elif ONLY_SBZ==True:\n",
    "        output_folder += 'ONLY_SBZS'\n",
    "    \n",
    "    # if job_array==True: #USING JOB ARRAY (NO NEED CURRENTLY)\n",
    "    #     if ONLY_SBZ==False:\n",
    "    #         out_name=output_folder2+f'whereCL_{res}_{t_res}_ALL_CLS_{job_id}.nc'\n",
    "    #     elif ONLY_SBZ==True:\n",
    "    #         out_name=output_folder2+f'whereCL_{res}_{t_res}_ONLY_SBZS_{job_id}.nc'\n",
    "    #     ds1.to_netcdf(out_name)  \n",
    "    # elif job_array==False: #NOT USING JOB ARRAY\n",
    "    output_folder2 = '/mnt/lustre/koa/koastore/torri_group/air_directory/DCI-Project/Project_Algorithms/Tracking_Algorithms/'\n",
    "    if ONLY_SBZ==False:\n",
    "        out_name=output_folder2+f'whereCL_{res}_{t_res}_ALL_CLS.nc'\n",
    "        ds1.to_netcdf(out_name) \n",
    "    elif ONLY_SBZ==True:\n",
    "        out_name=output_folder2+f'whereCL_{res}_{t_res}_ONLY_SBZS.nc'\n",
    "        ds1.to_netcdf(out_name) \n",
    "    print('done')\n",
    "SaveData(ds1)\n",
    "\n",
    "end_time = time.time(); elapsed_time = end_time - start_time; print(f\"Total Elapsed Time: {elapsed_time} seconds\")\n",
    "#Nt=650,Nx=500,Ny=200 ==> * minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e1faf4-effa-4f71-be74-338ffa6bcffb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a580aec-4d6a-41ab-b2d6-c96459ed2e19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6c0077-3b4b-46ac-93ef-5dce3643d738",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847a377f-9108-4e0f-bb10-74a6a83968d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################################################\n",
    "#PLOTTING\n",
    "plotting=False #KEEP FALSE WHEN RUNNING\n",
    "# plotting=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3115451e-e5aa-48a3-9ca9-297e00852ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '/mnt/lustre/koa/koastore/torri_group/air_directory/DCI-Project/Project_Algorithms/Tracking_Algorithms/trackout/CL_tracking_plots/' #plot image output foldername\n",
    "\n",
    "load_dir = '/mnt/lustre/koa/koastore/torri_group/air_directory/DCI-Project/Project_Algorithms/Tracking_Algorithms/'\n",
    "\n",
    "open_name = load_dir+f'whereCL_{res}_{t_res}_ALL_CLS.nc'\n",
    "whereCL_ALL_CLS=xr.open_dataset(open_name)['maxconv_x'].data\n",
    "\n",
    "# open_name = load_dir+f'whereCL_{res}_{t_res}_{Np_str}_ONLY_SBZS.nc'\n",
    "# whereCL_ONLY_SBZS=xr.open_dataset(open_name)['maxconv_x'].data\n",
    "\n",
    "def CL_plotting(t,ONLY_SBZ,SAVING):\n",
    "    if np.mod(t,10)==0: print(f'current time step: {t}/{len(data[\"time\"])}')\n",
    "\n",
    "    #Taking Convergence of current timestep\n",
    "    dx=np.round(data['xf'][1]-data['xf'][0],2).item();dy=dx #gets the dx,dy in meters (0.25m in this case)\n",
    "    conv=get_conv(t)\n",
    "\n",
    "    #Plotting horizontal layer at ~0.28 km \n",
    "    zlev=3 #(zf level ~0.28 km)\n",
    "    channel_aspect_ratio = 5\n",
    "    figwidth=20\n",
    "    plt.figure(figsize=(figwidth, figwidth/channel_aspect_ratio)) \n",
    "    contour=plt.contourf(conv[zlev]*1000)#,levels=np.arange(-1.5,1.5,.01),vmin=vmin,vmax=vmax)\n",
    "    \n",
    "    colorbar = plt.colorbar(contour,label=f'{dx*1000:.0f}'+r'$\\ s^{-1}$')# ,pad=pad)\n",
    "    #####################################################################\n",
    "    #Gets time for Plot Label\n",
    "    [days,hours,mins]=get_time(t+index_adjust)\n",
    "    value=data['zf'][zlev].values; \n",
    "    plt.title(f'Convergence at t={t+index_adjust}={days}:{hours}:{mins}, z={value:.2f} km')\n",
    "    plt.xlabel('x (km)')\n",
    "    plt.ylabel('y (km)')\n",
    "    #####################################################################\n",
    "\n",
    "    # plt.contourf(data['pwat'].isel(time=t),alpha=0.3,cmap='Reds') #rain, prate, pwat #TESTING\n",
    "\n",
    "    #ADDING TRACKED LOCATION SCATTER\n",
    "    #for each ylevel, apply FindLocalMaxes Function\n",
    "    zlev=3;conv_z=conv[zlev,:,:] #only look at 3rd level of convergence field\n",
    "    maxconv_x=np.array([],dtype='int'); \n",
    "    for yind in range(0,len(data['yh'])): #plot maximums for each row\n",
    "        if ONLY_SBZ==False:\n",
    "            local_maxes=whereCL_ALL_CLS[t,3,yind]\n",
    "            local_maxes=local_maxes[local_maxes != -1]\n",
    "        elif ONLY_SBZ==True:\n",
    "            local_maxes=whereCL_ONLY_SBZS[t,3,yind]\n",
    "            local_maxes=local_maxes[local_maxes != -1]\n",
    "        plt.scatter(local_maxes,np.array([yind]*len(local_maxes)),color='red',s=1)\n",
    "\n",
    "    # SAVING PLOT\n",
    "    if SAVING==True:\n",
    "        if ONLY_SBZ==False:\n",
    "            plt.savefig(os.path.join(folder_path, f\"ALL_CLS/plot_{t+index_adjust}.png\"),dpi=72) #save the plot\n",
    "        if ONLY_SBZ==True:\n",
    "            plt.savefig(os.path.join(folder_path, f\"ONLY_SBZS/plot_{t+index_adjust}.png\"),dpi=72) #save the plot\n",
    "        # print('finished saving plot') #TESTING\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e287d81-b1f8-40a0-85f0-11d72d043c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if plotting==True:\n",
    "    #TESTING INDIVIDUAL PLOTS\n",
    "    #########################\n",
    "    t=200\n",
    "    t+=20\n",
    "    CL_plotting(t=t,ONLY_SBZ=False,SAVING=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5876cd41-d2cf-4bb6-8afb-ea1b893affde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if plotting==True:\n",
    "    #OUTPUTTING ALL PLOTS\n",
    "    #####################\n",
    "    for t in np.arange(len(data['time'])):\n",
    "        CL_plotting(t=t,ONLY_SBZ=False,SAVING=True)\n",
    "        # CL_plotting(t=t,ONLY_SBZ=True,SAVING=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb94b48c-53b1-43e2-b6cc-db089d5036ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "if plotting==True:\n",
    "    #MAKE A GIF OF ALL TRACKED IMAGES\n",
    "    #####################\n",
    "    from PIL import Image\n",
    "    import os\n",
    "    \n",
    "    ONLY_SBZ=False\n",
    "    # ONLY_SBZ=True\n",
    "    # Folder containing the pictures\n",
    "    if ONLY_SBZ==False:\n",
    "        input_folder = '/mnt/lustre/koa/koastore/torri_group/air_directory/DCI-Project/Project_Algorithms/Tracking_Algorithms/trackout/CL_tracking_plots/ALL_CLS/'\n",
    "    if ONLY_SBZ==True:\n",
    "        input_folder = '/mnt/lustre/koa/koastore/torri_group/air_directory/DCI-Project/Project_Algorithms/Tracking_Algorithms/trackout/CL_tracking_plots/ONLY_SBZS/'\n",
    "    \n",
    "    image_filenames = sorted([filename for filename in os.listdir(input_folder) if filename.endswith((\".jpg\", \".png\"))], \n",
    "                             key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
    "    \n",
    "    # List to store image objects\n",
    "    images = []\n",
    "    \n",
    "    # Iterate over all files in the folder\n",
    "    for filename in image_filenames:\n",
    "        # Check if the file is an image\n",
    "        if (filename.endswith(\".jpg\") or filename.endswith(\".png\")):\n",
    "            # Open the image and append it to the list\n",
    "            images.append(Image.open(os.path.join(input_folder, filename)))\n",
    "    \n",
    "    # Save images as a GIF\n",
    "    if ONLY_SBZ==False:\n",
    "        output_path = input_folder+f'CL_plots_{res}_{t_res}_ALL_CLS.gif'\n",
    "    if ONLY_SBZ==True:\n",
    "        output_path = input_folder+f'CL_plots_{res}_{t_res}_ONLY_SBZS.gif'\n",
    "    images[0].save(output_path,\n",
    "                   save_all=True,\n",
    "                   append_images=images[1:],\n",
    "                   duration=100,  # Specify duration for each frame in milliseconds\n",
    "                   loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c5b723-2a91-4656-88b4-f1602aa29102",
   "metadata": {},
   "outputs": [],
   "source": [
    "if plotting==True:\n",
    "    def convert_gif_to_mp4(input_file, output_file, fps,speed,bitrate='750k'):\n",
    "        from moviepy.editor import VideoFileClip, vfx\n",
    "        # Load the GIF file\n",
    "        gif_clip = VideoFileClip(input_file)\n",
    "    \n",
    "        # Set the desired framerate if provided\n",
    "        if fps:\n",
    "            gif_clip = gif_clip.set_fps(fps)\n",
    "        if speed != 1.0:\n",
    "            gif_clip = gif_clip.fx(vfx.speedx, speed)\n",
    "    \n",
    "        # Write the GIF as an MP4 file\n",
    "        gif_clip.write_videofile(output_file, codec=\"libx264\",bitrate=bitrate)\n",
    "    \n",
    "    ONLY_SBZ=False\n",
    "    # ONLY_SBZ=True\n",
    "    input_folder = '/mnt/lustre/koa/koastore/torri_group/air_directory/DCI-Project/Project_Algorithms/Tracking_Algorithms/trackout/CL_tracking_plots/'\n",
    "    if ONLY_SBZ==False:\n",
    "        input_folder += 'ALL_CLS/'\n",
    "    elif ONLY_SBZ==True:\n",
    "        input_folder += 'ONLY_SBZS/'\n",
    "    input_file = input_folder+f'CL_plots_{res}_{t_res}_ALL_CLS.gif'\n",
    "    \n",
    "    if ONLY_SBZ==False:\n",
    "        output_file = f'/mnt/lustre/koa/koastore/torri_group/air_directory/DCI-Project/Project_Algorithms/Tracking_Algorithms/CL_plots_{res}_{t_res}_ALL_CLS.mp4'\n",
    "    if ONLY_SBZ==True:\n",
    "            output_file = f'/mnt/lustre/koa/koastore/torri_group/air_directory/DCI-Project/Project_Algorithms/Tracking_Algorithms/CL_plots_{res}_{t_res}_ONLY_SBZS.mp4'\n",
    "        \n",
    "    convert_gif_to_mp4(input_file, output_file, speed=0.25,fps=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
