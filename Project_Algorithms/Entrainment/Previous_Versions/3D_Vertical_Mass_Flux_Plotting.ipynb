{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a13b10a-9f17-40ec-b1f5-1e56aa532b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading in Packages and Data\n",
    "\n",
    "#Importing Packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "import matplotlib.gridspec as gridspec\n",
    "import xarray as xr\n",
    "import os; import time\n",
    "import pickle\n",
    "import h5py\n",
    "###############################################################\n",
    "def coefs(coefficients,degree):\n",
    "    coef=coefficients\n",
    "    coefs=\"\"\n",
    "    for n in range(degree, -1, -1):\n",
    "        string=f\"({coefficients[len(coef)-(n+1)]:.1e})\"\n",
    "        coefs+=string + f\"x^{n}\"\n",
    "        if n != 0:\n",
    "            coefs+=\" + \"\n",
    "    return coefs\n",
    "###############################################################\n",
    "\n",
    "#Importing Model Data\n",
    "check=False\n",
    "dir='/mnt/lustre/koa/koastore/torri_group/air_directory/DCI-Project/'\n",
    "\n",
    "# # dx = 1 km; Np = 1M; Nt = 5 min\n",
    "# data=xr.open_dataset(dir+'../cm1r20.3/run/cm1out_1km_1e6.nc') #***\n",
    "# parcel=xr.open_dataset(dir+'../cm1r20.3/run/cm1out_pdata_1km_1e6.nc') #***\n",
    "# res='1km'\n",
    "# Np_str='1e6'\n",
    "\n",
    "# dx = 1km; Np = 50M\n",
    "#Importing Model Data\n",
    "check=False\n",
    "dir2='/home/air673/koa_scratch/'\n",
    "data=xr.open_dataset(dir2+'cm1out_1km_1min.nc') #***\n",
    "parcel=xr.open_dataset(dir2+'cm1out_pdata_1km_1min_50M.nc') #***\n",
    "res='1km'; t_res='1min'; Np_str='50e6'\n",
    "\n",
    "# # dx = 1km; Np = 100M\n",
    "# #Importing Model Data\n",
    "# check=False\n",
    "# dir2='/home/air673/koa_scratch/'\n",
    "# data=xr.open_dataset(dir2+'cm1out_1km_1min.nc') #***\n",
    "# parcel=xr.open_dataset(dir2+'cm1out_pdata_1km_1min_100M.nc') #***\n",
    "# res='1km'; t_res='1min'; Np_str='100e6'\n",
    "\n",
    "\n",
    "# dx = 250 m\n",
    "# #Importing Model Data\n",
    "# check=False\n",
    "# dir2='/home/air673/koa_scratch/'\n",
    "# data=xr.open_dataset(dir2+'cm1out_250m.nc') #***\n",
    "# parcel=xr.open_dataset(dir2+'cm1out_pdata_250m.nc') #***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39ebce7-dfdb-4f49-9b0b-1dc0d7ab6913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "dir2='/mnt/lustre/koa/koastore/torri_group/air_directory/DCI-Project/'\n",
    "path=dir2+'../Functions/'\n",
    "sys.path.append(path)\n",
    "\n",
    "import NumericalFunctions\n",
    "from NumericalFunctions import * # import NumericalFunctions \n",
    "import PlottingFunctions\n",
    "from PlottingFunctions import * # import PlottingFunctions\n",
    "\n",
    "\n",
    "# # Get all functions in NumericalFunctions\n",
    "# import inspect\n",
    "# functions = [f[0] for f in inspect.getmembers(NumericalFunctions, inspect.isfunction)]\n",
    "# functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb27a0c-9e8e-4e03-8b86-c059b8e8b348",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # #TESTING W (T,Z) PLOT\n",
    "# # w_tz=data['winterp'].mean(dim=(\"xh\",'yh'))\n",
    "\n",
    "# # w_masked = data['winterp'].where((data['winterp'] >= 0.1) & (data['qc'] + data['qi'] >= 1e-6))\n",
    "# # w_tz_A = w_masked.mean(dim=(\"xh\", \"yh\"))  # Compute horizontal mean ignoring NaNs\n",
    "\n",
    "# # New Subplots for Contour Plots\n",
    "# fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# # First contour plot\n",
    "# cf1 = axes[0].contourf(w_tz.T)\n",
    "# plt.colorbar(cf1, ax=axes[0],label='m/s')\n",
    "# axes[0].set_ylabel('zgrid')\n",
    "# axes[0].set_xlabel('time')\n",
    "# axes[0].set_title('W(z,t) Horizontal Average for Eulerian Data')\n",
    "\n",
    "# # Second contour plot\n",
    "# cf2 = axes[1].contourf(w_tz_A.T)\n",
    "# plt.colorbar(cf2, ax=axes[1],label='m/s')\n",
    "# axes[1].set_ylabel('zgrid')\n",
    "# axes[1].set_xlabel('time')\n",
    "# axes[1].set_title('W(z,t) Horizontal Average for Eulerian Data (w ≥ 0.1) & (qc+qi ≥ 1e-6)')\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357cbdf5-b2f4-4899-bcf4-50dac35156d9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# #TESTING W (T,Z) PLOT\n",
    "\n",
    "# z_lev=10\n",
    "# #GETTING W AND A AT Z LEVEL\n",
    "# W_z = W[np.where(Z==15)]\n",
    "# A_z = A_c[np.where(Z==15)]\n",
    "\n",
    "# #REMOVING ZERO\n",
    "# W_z = W_z[np.where(A_z!=0)]\n",
    "# A_z = A_z[np.where(A_z!=0)]\n",
    "\n",
    "# fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "# # First subplot\n",
    "# axes[0].hist(W_z, bins=30, color='blue', alpha=0.7)\n",
    "# axes[0].set_title(f\"W (z = {data['zh'][z_lev].values*1e3:.0f} m)\")\n",
    "# # Second subplot\n",
    "# axes[1].hist([a * w for a, w in zip(A_z, W_z)], bins=30, color='blue', alpha=0.7)\n",
    "# axes[1].set_title(f\"W * A (z = {data['zh'][z_lev].values*1e3:.0f} m)\")\n",
    "\n",
    "# axes[0].set_ylabel('count');axes[1].set_ylabel('count')\n",
    "# axes[0].set_xlabel('W (m/s)');axes[1].set_xlabel('W*A (m/s)')\n",
    "# plt.suptitle('Plotting W array as well as W*A_c for eulerian W for lagrangian parcel at a specific time')\n",
    "# plt.tight_layout()\n",
    "# # Lx=512*1000;Ly=200*1000\n",
    "# # np.sum(A_z*W_z)*np.mean(m_arr)/Lx/Ly/(data['zh'][z_lev].values-data['zh'][z_lev-1].values)/1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4313054e-e374-43af-9d85-7ac9f4b073b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "#PLOTTING\n",
    "plotting=False #KEEP FALSE WHEN JOB ARRAY IS RUNNING\n",
    "plotting=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4c38c2-d978-489b-8666-34b2ba431926",
   "metadata": {},
   "outputs": [],
   "source": [
    "if plotting==True:\n",
    "    #constants\n",
    "    Cp=1004 #Jkg-1K-1\n",
    "    Cv=717 #Jkg-1K-1\n",
    "    Rd=Cp-Cv #Jkg-1K-1\n",
    "    eps=0.608\n",
    "    \n",
    "    Lx=(data['xf'][-1].item()-data['xf'][0].item())*1000 #x length (m)\n",
    "    Ly=(data['yf'][-1].item()-data['yf'][0].item())*1000 #y length (m)\n",
    "    Np=len(parcel['xh']) #number of lagrangian parcles\n",
    "    dt=(data['time'][1]-data['time'][0]).item()/1e9 #sec\n",
    "    dx=(data['xf'][1].item()-data['xf'][0].item())*1e3 #meters\n",
    "    dy=(data['yf'][1].item()-data['yf'][0].item())*1e3 #meters\n",
    "    xs=data['xf'].values*1000\n",
    "    ys=data['yf'].values*1000\n",
    "    zs=data['zf'].values*1000\n",
    "    \n",
    "    def zf(z):\n",
    "        k=z #z is the # level of z\n",
    "        out=data['zf'].values[k]*1000\n",
    "        \n",
    "        return out\n",
    "    # def rho(x,y,z,t):\n",
    "    #     p=data['prs'].isel(xh=x,yh=y,zh=z,time=t).item()\n",
    "    #     p0=101325 #Pa\n",
    "    #     theta=data['th'].isel(xh=x,yh=y,zh=z,time=t).item()\n",
    "    #     T=theta*(p/p0)**(Rd/Cp)\n",
    "    #     qv=data['qv'].isel(xh=x,yh=y,zh=z,time=t).item()\n",
    "    #     # Tv=T*(1+eps*qv)\n",
    "    #     Tv=T*(eps+qv)/(eps*(1+qv))\n",
    "    #     rho = p/(Rd*Tv)\n",
    "    #     out=rho\n",
    "    #     return out\n",
    "    \n",
    "    def rho(x,y,z,rho_data_t):\n",
    "        out=rho_data_t[z,y,x]\n",
    "        return out\n",
    "    def m(t):\n",
    "        rho_data_t=data['rho'].isel(time=t).data\n",
    "        \n",
    "        m=0\n",
    "        #triple sum\n",
    "        for k in range(len(data['zh'])):\n",
    "            dz=(zf(k+1)-zf(k))\n",
    "            for j in range(len(data['yh'])):\n",
    "                for i in range(len(data['xh'])):\n",
    "                    rho_out=rho(i,j,k,rho_data_t)\n",
    "                    m+=rho_out*dz\n",
    "                    \n",
    "        #triple sum\n",
    "        out=m*dx*dy/Np\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e4c270-67b5-47ab-8f4e-ee28c8254b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if plotting==True:\n",
    "    #Calculate Mass Constant\n",
    "    # calculate='single_time'\n",
    "    # calculate=True\n",
    "    calculate=False\n",
    "    \n",
    "    if calculate==True:\n",
    "        Nt=len(data['time'])\n",
    "        m_arr=np.zeros((Nt))\n",
    "        for t in np.arange(Nt):\n",
    "            if np.mod(t,25)==0: print(t)\n",
    "            m_arr[t]=m(t)\n",
    "        dir3=dir+f'Project_Algorithms/Entrainment/'\n",
    "        np.save(dir3+f'Mass_Array_{res}_{t_res}_{Np_str}.npy', m_arr)\n",
    "    elif calculate=='single_time':\n",
    "        Nt=len(data['time'])\n",
    "        m_arr=np.zeros((Nt))\n",
    "    \n",
    "        t=0 #len(data['time'])//2 #Pick some middle time\n",
    "        m_300=m(t)\n",
    "        for t in np.arange(Nt):\n",
    "            m_arr[t]=m_300 #UNCOMMENT FOR FULL CALCULATION\n",
    "        dir3=dir+f'Project_Algorithms/Entrainment/'\n",
    "        np.save(dir3+f'Mass_Array_{res}_{t_res}_{Np_str}.npy', m_arr)\n",
    "    else:\n",
    "        dir3=dir+f'Project_Algorithms/Entrainment/'\n",
    "        m_arr = np.load(dir3+f'Mass_Array_{res}_{t_res}_{Np_str}.npy')\n",
    "    \n",
    "    # # TESTING\n",
    "    # lst=[]\n",
    "    # for t in np.arange(133):\n",
    "    #     lst.append(m_arr[t])\n",
    "    \n",
    "    # plt.plot(lst)\n",
    "    # (np.max(lst)-np.min(lst))*100/np.mean(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb358da-7fa5-45c9-b689-4bef5f595f67",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# #NONOPTIMIZED LOADING AND AVERAGING (NOT RECOMMENDED)\n",
    "# PROCESSING=False\n",
    "# # PROCESSING=True\n",
    "\n",
    "# if PROCESSING==False:\n",
    "#     dir3=dir+f'Project_Algorithms/Entrainment/3D_VMF_profiles_{res}_{t_res}_{Np_str}.h5'\n",
    "# if PROCESSING==True:\n",
    "#     dir3=dir+f'Project_Algorithms/Entrainment/3D_VMF_profiles_PREPROCESSING_{res}_{t_res}_{Np_str}.h5'\n",
    "# with h5py.File(dir3, \"r\") as h5f:\n",
    "#     profile_array_VMF_g = h5f[\"profile_array_VMF_g\"][:]\n",
    "#     profile_array_VMF_c = h5f[\"profile_array_VMF_c\"][:]\n",
    "\n",
    "# def apply_constant(profile_array,apply):\n",
    "#     if apply==True:\n",
    "#         Nt=profile_array.shape[0]\n",
    "#         Nz=profile_array.shape[1]\n",
    "    \n",
    "#         profile_array/=(dx*dy)\n",
    "#         for t in np.arange(Nt):\n",
    "#             profile_array[t]*=m_arr[t]\n",
    "#         for z in np.arange(Nz):\n",
    "#             dz=zf(z+1)-zf(z)\n",
    "#             profile_array[:,z]/=dz\n",
    "#     return profile_array\n",
    "\n",
    "# profile_array_VMF_g=apply_constant(profile_array_VMF_g,apply=True)\n",
    "# profile_array_VMF_c=apply_constant(profile_array_VMF_c,apply=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd59f05a-fe72-42f9-93b6-f23cbffcfa74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if plotting==True:\n",
    "    #OPTIMIZED LOADING AND AVERAGING\n",
    "    def apply_constant_tbyt(profile_array,t,apply):\n",
    "        if apply==True:\n",
    "            Nt=len(data['time'])\n",
    "            Nz=len(data['zh'])\n",
    "        \n",
    "            profile_array/=(dx*dy)\n",
    "            profile_array*=m_arr[t]\n",
    "            for z in np.arange(Nz):\n",
    "                dz=zf(z+1)-zf(z)\n",
    "                profile_array[z]/=dz\n",
    "        return profile_array\n",
    "    \n",
    "    \n",
    "    PROCESSING=False\n",
    "    # PROCESSING=True\n",
    "    \n",
    "    if PROCESSING==False:\n",
    "        dir3=dir+f'Project_Algorithms/Entrainment/3D_VMF_profiles_{res}_{t_res}_{Np_str}.h5'\n",
    "    if PROCESSING==True:\n",
    "        dir3=dir+f'Project_Algorithms/Entrainment/3D_VMF_profiles_PREPROCESSING_{res}_{t_res}_{Np_str}.h5'\n",
    "    \n",
    "    def load_get_mean(type):\n",
    "        Nt=len(data['time']); Nz=len(data['zh']); \n",
    "        VMF_output_array = np.zeros((Nt, Nz))\n",
    "    \n",
    "        if type=='general':\n",
    "            var_string=\"profile_array_VMF_g\"\n",
    "        elif type=='cloudy':\n",
    "            var_string=\"profile_array_VMF_c\"\n",
    "    \n",
    "        \n",
    "        with h5py.File(dir3, \"r\") as h5f:\n",
    "            #Reading\n",
    "    \n",
    "            for t in np.arange(Nt):\n",
    "                if np.mod(t,50)==0: print(t)\n",
    "                profile_array_VMF = h5f[var_string][t]\n",
    "        \n",
    "                #Applying Constants\n",
    "                profile_array_VMF=apply_constant_tbyt(profile_array_VMF,t,apply=True)\n",
    "        \n",
    "    \n",
    "                VMF_mean_yx=np.mean(profile_array_VMF, axis = (1,2))\n",
    "        \n",
    "    \n",
    "                VMF_output_array[t]=VMF_mean_yx\n",
    "        \n",
    "        return VMF_output_array\n",
    "    \n",
    "    \n",
    "    # type='general'\n",
    "    type='cloudy'\n",
    "    \n",
    "    profile_array_VMF_c = load_get_mean(type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056cb0f6-7fcf-4fb8-a210-3ea5b6625249",
   "metadata": {},
   "outputs": [],
   "source": [
    "if plotting==True:\n",
    "    # type='general'\n",
    "    type='cloudy'\n",
    "    \n",
    "    print('taking horizontal mean')\n",
    "    profile_array=profile_array_VMF_c.copy()\n",
    "    \n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib.gridspec import GridSpec\n",
    "    import numpy as np\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    gs = GridSpec(2, 2, figure=fig)\n",
    "    \n",
    "    ######\n",
    "    cmap1 = plt.cm.viridis\n",
    "    cmap2 = plt.cm.seismic \n",
    "    n_levels=29\n",
    "    ######\n",
    "    \n",
    "    # ######\n",
    "    # vmax_shared = np.max([np.max(profile_array_e), np.max(profile_array_d)])\n",
    "    # norm_shared = mcolors.Normalize(vmin=0, vmax=vmax_shared)\n",
    "    # ######\n",
    "    \n",
    "    # First subplot: VMF\n",
    "    ########################################\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    # contour1 = ax1.contourf(profile_array_e.T, cmap=cmap1)\n",
    "    contour1 = ax1.contourf(profile_array.T, cmap=cmap1)\n",
    "    cbar1=fig.colorbar(contour1, ax=ax1)\n",
    "    apply_scientific_notation_colorbar([cbar1])\n",
    "    Nz = len(data['zh'])\n",
    "    ax1.set_yticks(np.arange(Nz))\n",
    "    new_ytick_labels = np.round(data['zf'].values[:Nz], 2)\n",
    "    ax1.set_yticklabels(new_ytick_labels, fontsize=8, rotation=0)\n",
    "    ax1.set_ylabel('z (km)');ax1.set_xlabel('t (timesteps)')\n",
    "    ax1.set_title('Entrainment using Lagrangian Binary Array',fontsize=8)\n",
    "    \n",
    "    # #FIXING TICKS\n",
    "    # ax3.set_yticks(np.arange(Nz))\n",
    "    # new_ytick_labels = np.round(data['zf'].values[:Nz], 2)\n",
    "    # ax3.set_yticklabels(new_ytick_labels, fontsize=8, rotation=0)\n",
    "    # ax3.set_ylabel('z (km)');ax3.set_xlabel('t (timesteps)')\n",
    "    # ax3.set_title('Entrainment - Detrainment')\n",
    "    \n",
    "    # #FIXING SCIENTIFIC NOTATION\n",
    "    # from matplotlib.ticker import ScalarFormatter\n",
    "    # formatter = ScalarFormatter(useMathText=True)\n",
    "    # formatter.set_powerlimits((-2, 2))  # Adjust the range for scientific notation\n",
    "    # for cbar in (cbar1,cbar2, cbar3):  # These must be Colorbar instances\n",
    "    #     cbar.formatter = formatter\n",
    "    #     cbar.update_ticks()\n",
    "    \n",
    "    # Display the plot\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded37ad5-7624-4d84-be0c-6ae7eb6703f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if plotting==True:\n",
    "    plt.plot(np.mean(profile_array,axis=(0)),data['zh'],label='VMF')\n",
    "    \n",
    "    plt.legend(); plt.title('2D Vertical Mass Flux Using Lagrangian Binary Array')\n",
    "    \n",
    "    from matplotlib.ticker import ScalarFormatter\n",
    "    formatter = ScalarFormatter(useMathText=True)\n",
    "    formatter.set_scientific(True)\n",
    "    formatter.set_powerlimits((-1, 1))\n",
    "    plt.gca().xaxis.set_major_formatter(formatter)\n",
    "    \n",
    "    plt.ylabel('z (km)');plt.xlabel('Vertical Mass Flux, M(t,z) ' + r'$(kg m^{-2} s^{-1})$')\n",
    "    \n",
    "    # #COMPARING MAXIMUM WITH ROMPS 2012\n",
    "    # (1.4e-2)/(4e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a61037-86bf-4a9d-a0a3-4f32add684d6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# #TESTING DISTRIBUTION\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# fig, axes = plt.subplots(1, 3, figsize=(15, 5))  # Create a 1-row, 3-column subplot\n",
    "\n",
    "# array_z=np.mean(profile_array,axis=(0)); where=np.where(array_z==np.max(array_z))[0] #12\n",
    "# profile_array_z=profile_array.copy()[:,where]\n",
    "\n",
    "# # Plot the first histogram for all values\n",
    "# axes[0].hist(profile_array_z)\n",
    "# axes[0].set_ylabel('Count')\n",
    "# axes[0].set_xlabel('Vertical Mass Flux, M(z) ' + r'$(kg m^{-2} s^{-1})$')\n",
    "# axes[0].set_title('Histogram of VMF(t,z)')\n",
    "\n",
    "# # Threshold-based filtering\n",
    "# threshold = 0.01  \n",
    "# filtered_data_below = profile_array_z[profile_array_z < threshold]\n",
    "# filtered_data_above = profile_array_z[profile_array_z > threshold]\n",
    "\n",
    "# # Plot the second histogram for values < 0.01\n",
    "# axes[1].hist(filtered_data_below)\n",
    "# axes[1].set_ylabel('Count')\n",
    "# axes[1].set_xlabel('Vertical Mass Flux, M(z) ' + r'$(kg m^{-2} s^{-1})$')\n",
    "# axes[1].set_title('Histogram of VMF(t,z) for values < 0.01')\n",
    "\n",
    "# # Plot the third histogram for values > 0.01\n",
    "# axes[2].hist(filtered_data_above)\n",
    "# axes[2].set_ylabel('Count')\n",
    "# axes[2].set_xlabel('Vertical Mass Flux, M(z) ' + r'$(kg m^{-2} s^{-1})$')\n",
    "# axes[2].set_title('Histogram of VMF(t,z) for values > 0.01')\n",
    "\n",
    "# plt.suptitle(f\"Histograms of VMF at z = {data['zh'].values[where]} km (the location of the peak in VMF(t,z)\")\n",
    "# plt.tight_layout()  # Adjust layout to prevent overlap\n",
    "\n",
    "# f\"{(0.0005*50)*100/(0.03*14):.2f}% contribution for the values below 0.001\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
