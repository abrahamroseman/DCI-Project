{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea60562-c790-4305-9459-d4d1e4fda244",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading in Packages and Data\n",
    "\n",
    "#Importing Packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "import matplotlib.gridspec as gridspec\n",
    "import xarray as xr\n",
    "import os; import time\n",
    "import pickle\n",
    "import h5py\n",
    "###############################################################\n",
    "def coefs(coefficients,degree):\n",
    "    coef=coefficients\n",
    "    coefs=\"\"\n",
    "    for n in range(degree, -1, -1):\n",
    "        string=f\"({coefficients[len(coef)-(n+1)]:.1e})\"\n",
    "        coefs+=string + f\"x^{n}\"\n",
    "        if n != 0:\n",
    "            coefs+=\" + \"\n",
    "    return coefs\n",
    "###############################################################\n",
    "\n",
    "#Importing Model Data\n",
    "check=False\n",
    "dir='/mnt/lustre/koa/koastore/torri_group/air_directory/DCI-Project/'\n",
    "\n",
    "# dx = 1 km; Np = 1M; Nt = 5 min\n",
    "data=xr.open_dataset(dir+'../cm1r20.3/run/cm1out_1km_5min.nc') #***\n",
    "parcel=xr.open_dataset(dir+'../cm1r20.3/run/cm1out_pdata_1km_5min_1e6.nc') #***\n",
    "res='1km';t_res='5min'\n",
    "Np_str='1e6'\n",
    "\n",
    "# # dx = 1km; Np = 50M\n",
    "# #Importing Model Data\n",
    "# check=False\n",
    "# dir2='/home/air673/koa_scratch/'\n",
    "# data=xr.open_dataset(dir2+'cm1out_1km_1min.nc') #***\n",
    "# parcel=xr.open_dataset(dir2+'cm1out_pdata_1km_1min_50M.nc') #***\n",
    "# res='1km'; t_res='1min'; Np_str='50e6'\n",
    "\n",
    "# # dx = 1km; Np = 100M\n",
    "# #Importing Model Data\n",
    "# check=False\n",
    "# dir2='/home/air673/koa_scratch/'\n",
    "# data=xr.open_dataset(dir2+'cm1out_1km_1min.nc') #***\n",
    "# parcel=xr.open_dataset(dir2+'cm1out_pdata_1km_1min_100M.nc') #***\n",
    "# res='1km'; t_res='1min'; Np_str='100e6'\n",
    "\n",
    "\n",
    "# dx = 250 m\n",
    "# #Importing Model Data\n",
    "# check=False\n",
    "# dir2='/home/air673/koa_scratch/'\n",
    "# data=xr.open_dataset(dir2+'cm1out_250m.nc') #***\n",
    "# parcel=xr.open_dataset(dir2+'cm1out_pdata_250m.nc') #***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506b952a-76c0-4625-a9f0-8457335b0fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "dir2='/mnt/lustre/koa/koastore/torri_group/air_directory/DCI-Project/'\n",
    "path=dir2+'../Functions/'\n",
    "sys.path.append(path)\n",
    "\n",
    "import NumericalFunctions\n",
    "from NumericalFunctions import * # import NumericalFunctions \n",
    "import PlottingFunctions\n",
    "from PlottingFunctions import * # import PlottingFunctions\n",
    "\n",
    "\n",
    "# # Get all functions in NumericalFunctions\n",
    "# import inspect\n",
    "# functions = [f[0] for f in inspect.getmembers(NumericalFunctions, inspect.isfunction)]\n",
    "# functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38291f1-169f-4fe1-be13-2af7abd5b0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#JOB ARRAY SETUP\n",
    "job_array=True\n",
    "if job_array==True:\n",
    "\n",
    "    num_jobs=60 #how many total jobs are being run? i.e. array=1-100 ==> num_jobs=100 #***\n",
    "    total_elements=len(data['time']) #total num of variables\n",
    "\n",
    "    if num_jobs >= total_elements:\n",
    "        raise ValueError(\"Number of jobs cannot be greater than or equal to total elements.\")\n",
    "    \n",
    "    job_range = total_elements // num_jobs  # Base size for each chunk\n",
    "    remaining = total_elements % num_jobs   # Number of chunks with 1 extra \n",
    "    \n",
    "    # Function to compute the start and end for each job_id\n",
    "    def get_job_range(job_id, num_jobs):\n",
    "        job_id-=1\n",
    "        # Add one extra element to the first 'remaining' chunks\n",
    "        start_job = job_id * job_range + min(job_id, remaining)\n",
    "        end_job = start_job + job_range + (1 if job_id < remaining else 0)\n",
    "    \n",
    "        if job_id == num_jobs - 1: \n",
    "            end_job = total_elements #- 1\n",
    "        return start_job, end_job\n",
    "    # def job_testing():\n",
    "    #     #TESTING\n",
    "    #     start=[];end=[]\n",
    "    #     for job_id in range(1,num_jobs+1):\n",
    "    #         start_job, end_job = get_job_range(job_id)\n",
    "    #         print(start_job,end_job)\n",
    "    #         start.append(start_job)\n",
    "    #         end.append(end_job)\n",
    "    #     print(np.all(start!=end))\n",
    "    #     print(len(np.unique(start))==len(start))\n",
    "    #     print(len(np.unique(end))==len(end))\n",
    "    # job_testing()\n",
    "    \n",
    "    job_id = int(os.environ.get('SLURM_ARRAY_TASK_ID', 0)) #this is the current SBATCH job id\n",
    "    if job_id==0: job_id=46\n",
    "    start_job, end_job = get_job_range(job_id, num_jobs)\n",
    "    index_adjust=start_job\n",
    "    print(f'start_job = {start_job}, end_job = {end_job}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d77403e-a491-4a71-9aa4-5e0f2166abc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Indexing Array with JobArray\n",
    "data=data.isel(time=slice(start_job,end_job))\n",
    "parcel=parcel.isel(time=slice(start_job,end_job))\n",
    "#(for 150_000_000 parcels use 500-1000 jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23057e69-23b0-427f-b7ed-67db542e7c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#constants\n",
    "Cp=1004 #Jkg-1K-1\n",
    "Cv=717 #Jkg-1K-1\n",
    "Rd=Cp-Cv #Jkg-1K-1\n",
    "eps=0.608\n",
    "\n",
    "Lx=(data['xf'][-1].item()-data['xf'][0].item())*1000 #x length (m)\n",
    "Ly=(data['yf'][-1].item()-data['yf'][0].item())*1000 #y length (m)\n",
    "Np=len(parcel['xh']) #number of lagrangian parcles\n",
    "dt=(data['time'][1]-data['time'][0]).item()/1e9 #sec\n",
    "dx=(data['xf'][1].item()-data['xf'][0].item())*1e3 #meters\n",
    "dy=(data['yf'][1].item()-data['yf'][0].item())*1e3 #meters\n",
    "xs=data['xf'].values*1000\n",
    "ys=data['yf'].values*1000\n",
    "zs=data['zf'].values*1000\n",
    "\n",
    "def zf(z):\n",
    "    k=z #z is the # level of z\n",
    "    out=data['zf'].values[k]*1000\n",
    "    \n",
    "    return out\n",
    "# def rho(x,y,z,t):\n",
    "#     p=data['prs'].isel(xh=x,yh=y,zh=z,time=t).item()\n",
    "#     p0=101325 #Pa\n",
    "#     theta=data['th'].isel(xh=x,yh=y,zh=z,time=t).item()\n",
    "#     T=theta*(p/p0)**(Rd/Cp)\n",
    "#     qv=data['qv'].isel(xh=x,yh=y,zh=z,time=t).item()\n",
    "#     # Tv=T*(1+eps*qv)\n",
    "#     Tv=T*(eps+qv)/(eps*(1+qv))\n",
    "#     rho = p/(Rd*Tv)\n",
    "#     out=rho\n",
    "#     return out\n",
    "\n",
    "def rho(x,y,z,rho_data_t):\n",
    "    out=rho_data_t[z,y,x]\n",
    "    return out\n",
    "def m(t):\n",
    "    rho_data_t=data['rho'].isel(time=t).data\n",
    "    \n",
    "    m=0\n",
    "    #triple sum\n",
    "    for k in range(len(data['zh'])):\n",
    "        dz=(zf(k+1)-zf(k))\n",
    "        for j in range(len(data['yh'])):\n",
    "            for i in range(len(data['xh'])):\n",
    "                rho_out=rho(i,j,k,rho_data_t)\n",
    "                m+=rho_out*dz\n",
    "                \n",
    "    #triple sum\n",
    "    out=m*dx*dy/Np\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0827e669-dae3-4911-a66f-1b4126ac1720",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Calculate Mass Constant\n",
    "# calculate='single_time'\n",
    "# calculate=True\n",
    "calculate=False\n",
    "\n",
    "if calculate==True:\n",
    "    Nt=len(data['time'])\n",
    "    m_arr=np.zeros((Nt))\n",
    "    for t in np.arange(Nt):\n",
    "        if np.mod(t,25)==0: print(t)\n",
    "        m_arr[t]=m(t)\n",
    "    np.save(f'Mass_Array_{res}_{t_res}_{Np_str}.npy', m_arr)\n",
    "elif calculate=='single_time':\n",
    "    Nt=len(data['time'])\n",
    "    m_arr=np.zeros((Nt))\n",
    "\n",
    "    t=len(data['time'])//2 #Pick some middle time\n",
    "    m_300=m(t)\n",
    "    for t in np.arange(Nt):\n",
    "        m_arr[t]=m_300 #UNCOMMENT FOR FULL CALCULATION\n",
    "    np.save(f'Mass_Array_{res}_{t_res}_{Np_str}.npy', m_arr)\n",
    "else:\n",
    "    dir3=dir+f'Project_Algorithms/Entrainment/'\n",
    "    m_arr = np.load(f'Mass_Array_{res}_{t_res}_{Np_str}.npy')\n",
    "\n",
    "# # TESTING\n",
    "# lst=[]\n",
    "# for t in np.arange(133):\n",
    "#     lst.append(m_arr[t])\n",
    "\n",
    "# plt.plot(lst)\n",
    "# (np.max(lst)-np.min(lst))*100/np.mean(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109b6433-faf4-4a72-82dc-5c82d2e15e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#READING BACK IN\n",
    "PROCESSING=False\n",
    "PROCESSING=True\n",
    "\n",
    "print('loading vars')\n",
    "if PROCESSING==False:\n",
    "    dir3=dir+f'Project_Algorithms/Entrainment/3D_VMF_profiles_{res}_{t_res}_{Np_str}.h5'\n",
    "if PROCESSING==True:\n",
    "    dir3=dir+f'Project_Algorithms/Entrainment/3D_VMF_profiles_PREPROCESSING_{res}_{t_res}_{Np_str}.h5'\n",
    "with h5py.File(dir3, \"r\") as h5f:\n",
    "    profile_array_VMF_g = h5f[\"profile_array_VMF_g\"][start_job:end_job]\n",
    "    profile_array_VMF_c = h5f[\"profile_array_VMF_c\"][start_job:end_job]\n",
    "\n",
    "\n",
    "def apply_constant(profile_array,apply):\n",
    "    if apply==True:\n",
    "        Nt=profile_array.shape[0]\n",
    "        Nz=profile_array.shape[1]\n",
    "    \n",
    "        profile_array/=(dx*dy)\n",
    "        for t in np.arange(Nt):\n",
    "            profile_array[t]*=m_arr[t+index_adjust]\n",
    "        for z in np.arange(Nz):\n",
    "            dz=zf(z+1)-zf(z)\n",
    "            profile_array[:,z]/=dz\n",
    "    return profile_array\n",
    "\n",
    "#APPLY CONSTANTS TO VMF VALUE\n",
    "##################################################\n",
    "profile_array_VMF_g=apply_constant(profile_array_VMF_g,apply=True)\n",
    "profile_array_VMF_c=apply_constant(profile_array_VMF_c,apply=True)\n",
    "##################################################\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2c323f-131e-4444-84ef-8100e837c31d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc32077-7abd-43ab-92c1-eb85dbd6bd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_variables(): #***\n",
    "    variable='winterp'; w_data=data[variable].data\n",
    "    variable='qv'; qv_data=data[variable].data # get qc data\n",
    "    variable='qc'; qc_data=data[variable].data # get qc data\n",
    "    variable='qi'; qi_data=data[variable].data # get qc data\n",
    "    qc_plus_qi=qc_data+qi_data\n",
    "    return w_data,qv_data,qc_data,qi_data,qc_plus_qi\n",
    "\n",
    "print('calling variables')\n",
    "[w_data,qv_data,qc_data,qi_data,qc_plus_qi]=call_variables()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a988fd-d39c-4eb9-8889-4a80f909c6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################\n",
    "#Functions\n",
    "# Full Profile function makes profile together for all timesteps. AveragedProfiles funciton takes the final mean of the combined profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7851e769-c67c-493f-a84c-7d7ed1cd37a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thresholds\n",
    "w_thresh1 = 0.1\n",
    "w_thresh2 = 0.5\n",
    "qcqi_thresh = 1e-6\n",
    "\n",
    "def final_profile(vars_list, type):\n",
    "    zhs = data['zh'].values\n",
    "    profiles = {}  # Store profiles for all variables\n",
    "\n",
    "    # Initialize profiles for each variable\n",
    "    for var in vars_list:\n",
    "        profiles[var] = np.zeros((len(zhs), 3))  # column 1: var, column 2: counter, column 3: list of zhs\n",
    "        profiles[var][:, 2] = zhs\n",
    "\n",
    "    # Threshold mask\n",
    "    if type == \"general\":\n",
    "        where_updraft = (w_data >= w_thresh1) & (qc_plus_qi < qcqi_thresh)\n",
    "    elif type == \"cloudy\":\n",
    "        where_updraft = (w_data >= w_thresh2) & (qc_plus_qi >= qcqi_thresh)\n",
    "        \n",
    "    t_ind, z_ind, y_ind, x_ind = np.where(where_updraft)\n",
    "\n",
    "    # Variable selection dictionary\n",
    "    var_data = {\n",
    "        'VMF_g': profile_array_VMF_g, 'VMF_c': profile_array_VMF_c, \n",
    "    }\n",
    "    \n",
    "    # Iterate over each variable in vars_list and bin the data\n",
    "    for var in vars_list:\n",
    "        masked_data = var_data[var][where_updraft]\n",
    "        np.add.at(profiles[var][:, 0], z_ind, masked_data)\n",
    "        np.add.at(profiles[var][:, 1], z_ind, 1)\n",
    "\n",
    "    return profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ef7e90-4686-45ae-b163-bcb92ff3bc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################\n",
    "#Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9104e1c0-741a-49fd-a3f2-db2b0992c49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir2=dir+'Project_Algorithms/Domain_Profiles/'\n",
    "\n",
    "print(f\"job_id = {job_id}\")\n",
    "for type in [\"general\",\"cloudy\"]:\n",
    "    print(f\"working on {type} type\\n\")\n",
    "    \n",
    "    vars_list = ['VMF_g', 'VMF_c']\n",
    "    profiles = final_profile(vars_list, type)\n",
    "    \n",
    "    #Saving eulerian_profiles\n",
    "    import h5py\n",
    "    \n",
    "    if type == \"general\":\n",
    "        output_file = dir2+f'job_out/general_eulerian_VMF_profiles_{res}_{t_res}_{Np_str}_{job_id}.h5' \n",
    "    elif type == \"cloudy\":\n",
    "        output_file = dir2+f'job_out/cloudy_eulerian_VMF_profiles_{res}_{t_res}_{Np_str}_{job_id}.h5'\n",
    "    \n",
    "    with h5py.File(output_file, 'w') as f:\n",
    "        for var in profiles:\n",
    "            profile_var = profiles[var]\n",
    "            f.create_dataset(f'profile_{var}', data=profile_var, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9f83bc-91fe-4564-8a13-c7dafe46db7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "#RECOMBINE SEPERATE JOB_ARRAYS AFTER\n",
    "recombine=False #KEEP FALSE WHEN JOB_ARRAYS IS RUNNING\n",
    "# recombine=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c248898-04d4-44e8-8286-afb2a03986a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if recombine==True:\n",
    "    dir2=dir+'Project_Algorithms/Domain_Profiles/'\n",
    "    \n",
    "    types=['general','cloudy']\n",
    "    for type in types:\n",
    "        #MAKING OUTPUT FILE PATH\n",
    "        if type == \"general\":\n",
    "            output_file =dir2+f'job_out/general_eulerian_VMF_profiles_{res}_{t_res}_{Np_str}.h5'\n",
    "        elif type == \"cloudy\":\n",
    "            output_file = dir2+f'job_out/cloudy_eulerian_VMF_profiles_{res}_{t_res}_{Np_str}.h5'\n",
    "        \n",
    "        #MAKING PROFILES DICTIONARY\n",
    "        zhs = data['zh'].values\n",
    "        profiles = {}  # Store profiles for all variables\n",
    "        vars_list = ['VMF_g', 'VMF_c']\n",
    "        for var in vars_list:\n",
    "            profiles[var] = np.zeros((len(zhs), 3))  # column 1: var, column 2: counter, column 3: list of zhs\n",
    "            profiles[var][:, 2] = zhs \n",
    "        \n",
    "        num_jobs=60\n",
    "        for job_id in np.arange(1,num_jobs+1):\n",
    "            if np.mod(job_id,10)==0: print(f\"job_id = {job_id}\")\n",
    "    \n",
    "            #CALLING IN DATA\n",
    "            if type == \"general\":\n",
    "                input_file = dir2+f'job_out/general_eulerian_VMF_profiles_{res}_{t_res}_{Np_str}_{job_id}.h5' \n",
    "            elif type == \"cloudy\":\n",
    "                input_file = dir2+f'job_out/cloudy_eulerian_VMF_profiles_{res}_{t_res}_{Np_str}_{job_id}.h5' \n",
    "    \n",
    "            #COMPILING PROFILES\n",
    "            with h5py.File(input_file, 'r') as f:\n",
    "                for var in vars_list:  \n",
    "                    profiles[var][:,0:1+1]+=f[f'profile_{var}'][:,0:1+1]\n",
    "        \n",
    "        #SAVING INTO FINAL FORM\n",
    "        with h5py.File(output_file, 'w') as f:\n",
    "            for var in profiles:\n",
    "                profile_var = profiles[var]\n",
    "                f.create_dataset(f'profile_{var}', data=profile_var, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddbb158-45a9-4441-a291-b49c0f08e943",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################\n",
    "#Plotting\n",
    "plotting=False #KEEP FALSE WHEN JOB_ARRAYS IS RUNNING\n",
    "# plotting=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd563c7-4e42-4150-b84d-aa10e360db18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def averaged_profiles(profile):\n",
    "    out_var = profile[(profile[:, 1] != 0)]  # gets rid of rows that have no data\n",
    "    out_var = np.array([out_var[:, 0] / out_var[:, 1], out_var[:, 2]]).T  # divides the data column by the counter column\n",
    "    return out_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bf2166-990c-4dd2-8af1-2201cdd4e94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if plotting==True:\n",
    "    for type in [\"general\",\"cloudy\"]:\n",
    "        print(f'currently on type {type}')\n",
    "        dir2=dir+'Project_Algorithms/Domain_Profiles/'\n",
    "        if type == \"general\":\n",
    "            input_file =dir2+f'job_out/general_eulerian_VMF_profiles_{res}_{Np_str}_5min.h5'#_{46}.h5'\n",
    "        elif type == \"cloudy\":\n",
    "            input_file =dir2+f'job_out/cloudy_eulerian_VMF_profiles_{res}_{Np_str}_5min.h5'#_{46}.h5'\n",
    "        \n",
    "        with h5py.File(input_file, 'r') as f:\n",
    "            if type == \"general\":\n",
    "                VMF = np.array(f['profile_VMF_g'])\n",
    "            elif type == \"cloudy\":\n",
    "                VMF = np.array(f['profile_VMF_c'])\n",
    "        \n",
    "        \n",
    "        #Uses Averaged_Profiles Function\n",
    "        vars = ['VMF'] \n",
    "        \n",
    "        for var in vars:\n",
    "            globals()[f\"out_{var}\"] = averaged_profiles(globals()[f\"{var}\"])\n",
    "        \n",
    "        if type=='general':\n",
    "            color='black'\n",
    "        elif type=='cloudy':\n",
    "            color='blue'\n",
    "    \n",
    "        plt.plot(out_VMF[:,0],out_VMF[:,1],color=color,label=type)\n",
    "        plt.axvline(0,color='k')\n",
    "        ax = plt.gca()\n",
    "        apply_scientific_notation([ax])\n",
    "        \n",
    "        plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7d1a9c-3ed1-4ec9-a62b-e6c499dd9d23",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# #DOUBLE CHECKING\n",
    "# w=data['winterp'].data\n",
    "# qc=data['qc'].data\n",
    "# qi=data['qi'].data\n",
    "# qcqi=qc+qi\n",
    "# mask = (w >= 0.5) & (qcqi >= 1e-6)\n",
    "# profile_array_VMF_c[~mask] = np.nan\n",
    "# out=np.nanmean(profile_array_VMF_c,axis=(0,2,3))\n",
    "# plt.plot(out,data['zh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8d0085-1e36-40f1-b08b-600d2e0145f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if plotting==True:\n",
    "    def average_difference(array1, array2):\n",
    "        out_var_one=averaged_profiles(array1)\n",
    "        out_var_two=averaged_profiles(array2)\n",
    "    \n",
    "        #masking out non matches\n",
    "        second_col_one = out_var_one[:, 1]\n",
    "        second_col_two = out_var_two[:, 1]\n",
    "        mask_one = np.isin(second_col_one, second_col_two)\n",
    "        mask_two = np.isin(second_col_two, second_col_one)\n",
    "        \n",
    "        out_var_one = out_var_one.copy()[mask_one]\n",
    "        out_var_two = out_var_two.copy()[mask_two]\n",
    "        \n",
    "        diff=(out_var_one[:,0]-out_var_two[:,0])\n",
    "        zs=out_var_one[:,1]\n",
    "    \n",
    "        out_profile=np.zeros((len(diff),2))\n",
    "    \n",
    "        out_profile[:,0]=diff;out_profile[:,1]=zs;\n",
    "        return out_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb146da2-d48d-47e3-a1ca-b90e51059033",
   "metadata": {},
   "outputs": [],
   "source": [
    "if plotting==True:\n",
    "    #Plotting Differences\n",
    "    def averaged_profiles(profile):\n",
    "        out_var = profile[(profile[:, 1] != 0)]  # gets rid of rows that have no data\n",
    "        # out_var = np.array([out_var[:, 0] / out_var[:, 1], out_var[:, 2]]).T  # divides the data column by the counter column\n",
    "        Nt=len(data['time']);Ny=len(data['yh']);Nx=len(data['xh'])\n",
    "        out_var[:,0]/=(Ny*Nx*Nt)\n",
    "        out_var = np.array([out_var[:, 0], out_var[:, 2]]).T  # divides the data column by the counter column\n",
    "        return out_var\n",
    "    label=1\n",
    "    \n",
    "        \n",
    "    def get_data(type):\n",
    "        dir2=dir+'Project_Algorithms/Domain_Profiles/'\n",
    "        if type == \"general\":\n",
    "            input_file = dir2+f'job_out/general_eulerian_VMF_profiles_{res}_{Np_str}_5min.h5' \n",
    "        elif type == \"cloudy\":\n",
    "            input_file = dir2+f'job_out/cloudy_eulerian_VMF_profiles_{res}_{Np_str}_5min.h5' \n",
    "    \n",
    "        with h5py.File(input_file, 'r') as f:\n",
    "            if type == \"general\":\n",
    "                VMF = np.array(f['profile_VMF_g'])\n",
    "            elif type == \"cloudy\":\n",
    "                VMF = np.array(f['profile_VMF_c'])\n",
    "    \n",
    "        return VMF\n",
    "    \n",
    "        \n",
    "    def diff_plotting():\n",
    "        #setting up figure\n",
    "        fig, axis = plt.subplots(1, 1, figsize=(8, 6))\n",
    "        # fig.suptitle(\"\")\n",
    "        # ax1= axs.flatten()\n",
    "    \n",
    "        #the plotting\n",
    "        vars = ['VMF'] \n",
    "        xlabels = ['VMF'] \n",
    "        for xlabel,var in zip(xlabels,vars):\n",
    "    \n",
    "            #get profile\n",
    "            types=['cloudy','general']\n",
    "            out_var_one=get_data(types[0])\n",
    "            out_var_two=get_data(types[1])\n",
    "    \n",
    "            #finding where cloudy updraft count goes below 10\n",
    "            cutofflow=np.where(out_var_one[:,1]>10)[0][0]\n",
    "            cutoffhigh=np.where(out_var_one[:,1]>10)[0][-1]\n",
    "           \n",
    "            #averaging\n",
    "            out_var_diff=average_difference(out_var_one,out_var_two)\n",
    "            \n",
    "            axis.plot(out_var_diff[:,0],out_var_diff[:,-1],color='k')\n",
    "            axis.axvline(0,color='k',linestyle='dashed')\n",
    "            # axis.set_ylim(bottom=0,top=20)\n",
    "            ## axis.set_ylim(bottom=data['zh'][cutofflow],top=data['zh'][cutoffhigh])\n",
    "            #labeling\n",
    "            axis.set_ylabel('z (km)');axis.set_xlabel(xlabel);\n",
    "            axis.grid(True)\n",
    "            # axis.legend(fontsize='small') #only adds legend at final variable\n",
    "    \n",
    "            if axis==axis:\n",
    "                apply_scientific_notation([axis])\n",
    "    \n",
    "            # axis.set_yticks(list(axis.get_yticks()) + [data['zh'][cutofflow]]) #TESTING\n",
    "        plt.tight_layout()\n",
    "    \n",
    "    diff_plotting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05d4c33-2686-40d7-b97f-389e9cde3cb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbaabbf-2176-4550-be7a-7e9258210ced",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
