{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3411e523-2126-4767-aae1-fbef4b65f0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading in Packages and Data\n",
    "\n",
    "#Importing Packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "import matplotlib.gridspec as gridspec\n",
    "import xarray as xr\n",
    "import os; import time\n",
    "import pickle\n",
    "import h5py\n",
    "###############################################################\n",
    "def coefs(coefficients,degree):\n",
    "    coef=coefficients\n",
    "    coefs=\"\"\n",
    "    for n in range(degree, -1, -1):\n",
    "        string=f\"({coefficients[len(coef)-(n+1)]:.1e})\"\n",
    "        coefs+=string + f\"x^{n}\"\n",
    "        if n != 0:\n",
    "            coefs+=\" + \"\n",
    "    return coefs\n",
    "###############################################################\n",
    "\n",
    "# Importing Model Data\n",
    "check=False\n",
    "dir='/mnt/lustre/koa/koastore/torri_group/air_directory/DCI-Project/'\n",
    "\n",
    "# dx = 1 km; Np = 1M; Nt = 5 min\n",
    "data=xr.open_dataset(dir+'../cm1r20.3/run/cm1out_1km_5min.nc', decode_timedelta=True) #***\n",
    "parcel=xr.open_dataset(dir+'../cm1r20.3/run/cm1out_pdata_1km_5min_1e6.nc', decode_timedelta=True) #***\n",
    "res='1km';t_res='5min'\n",
    "Np_str='1e6'\n",
    "\n",
    "# # dx = 1km; Np = 50M; Nz = 95\n",
    "# #Importing Model Data\n",
    "# dir2='/home/air673/koa_scratch/'\n",
    "# data=xr.open_dataset(dir2+'cm1out_1km_1min_95nz.nc') #***\n",
    "# parcel=xr.open_dataset(dir2+'cm1out_pdata_1km_1min_95nz.nc') #***\n",
    "# res='1km'; t_res='1min_95nz'; Np_str='50e6'\n",
    "\n",
    "# # dx = 250m; Np = 50M\n",
    "# #Importing Model Data\n",
    "# dir2='/home/air673/koa_scratch/'\n",
    "# data=xr.open_dataset(dir2+'cm1out_250m_1min_50M.nc') #***\n",
    "# parcel=xr.open_dataset(dir2+'cm1out_pdata_250m_1min_50M.nc') #***\n",
    "# res='250m'; t_res='1min'; Np_str='50e6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3133df4-2cfe-42bc-9df1-42577c476900",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "dir2='/mnt/lustre/koa/koastore/torri_group/air_directory/DCI-Project/'\n",
    "path=dir2+'../Functions/'\n",
    "sys.path.append(path)\n",
    "\n",
    "import NumericalFunctions\n",
    "from NumericalFunctions import * # import NumericalFunctions \n",
    "import PlottingFunctions\n",
    "from PlottingFunctions import * # import PlottingFunctions\n",
    "\n",
    "# # Get all functions in NumericalFunctions\n",
    "# import inspect\n",
    "# functions = [f[0] for f in inspect.getmembers(NumericalFunctions, inspect.isfunction)]\n",
    "# functions\n",
    "\n",
    "#####\n",
    "\n",
    "#Import StatisticalFunctions \n",
    "import sys\n",
    "dir2='/mnt/lustre/koa/koastore/torri_group/air_directory/DCI-Project/'\n",
    "path=dir2+'../Functions/'\n",
    "sys.path.append(path)\n",
    "\n",
    "import StatisticalFunctions\n",
    "from StatisticalFunctions import * # import NumericalFunctions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad276cc-dc75-47db-be8e-c92f3dacd076",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "#PLOTTING\n",
    "plotting=False #KEEP FALSE IF JOB ARRAY IS RUNNING\n",
    "plotting=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e435dec9-638e-41d9-9f34-049fe62a6f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#READING BACK IN\n",
    "# import pickle\n",
    "# dir2 = dir + f'Project_Algorithms/Domain_Profiles/'\n",
    "# input_file = dir2 + f'MeanLFC_{res}_{t_res}_{Np_str}.pkl'\n",
    "\n",
    "# with open(input_file, 'rb') as f:\n",
    "#     MeanLFC = pickle.load(f)\n",
    "# print(MeanLFC)\n",
    "\n",
    "def LoadMeanLFC():\n",
    "    dir2 = dir + f'Project_Algorithms/Tracking_Algorithms/OUTPUT/'\n",
    "    in_file = dir2 + f\"MeanLFC_{res}_{t_res}_{Np_str}.pkl\"\n",
    "    with open(in_file, 'rb') as f:\n",
    "        MeanLFC = pickle.load(f)\n",
    "    return MeanLFC\n",
    "MeanLFC=LoadMeanLFC()\n",
    "print(f\"Mean LFC is: {MeanLFC}\\n\")\n",
    "\n",
    "\n",
    "def LoadAllCloudBase():\n",
    "    dir2 = dir + f'Project_Algorithms/Tracking_Algorithms/OUTPUT/'\n",
    "    in_file = dir2 + f\"all_cloudbase_{res}_{t_res}_{Np_str}.pkl\"\n",
    "    with open(in_file, 'rb') as f:\n",
    "        all_cloudbase = pickle.load(f)\n",
    "    return(all_cloudbase)\n",
    "min_all_cloudbase=np.nanmin(LoadAllCloudBase())\n",
    "cloudbase=min_all_cloudbase\n",
    "print(f\"Minimum Cloudbase is: {cloudbase}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fc1167-2e2f-4996-ad32-7a0f4bbbcba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if plotting==True:\n",
    "    #constants\n",
    "    Cp=1004 #Jkg-1K-1\n",
    "    Cv=717 #Jkg-1K-1\n",
    "    Rd=Cp-Cv #Jkg-1K-1\n",
    "    eps=0.608\n",
    "    \n",
    "    Lx=(data['xf'][-1].item()-data['xf'][0].item())*1000 #x length (m)\n",
    "    Ly=(data['yf'][-1].item()-data['yf'][0].item())*1000 #y length (m)\n",
    "    Np=len(parcel['xh']) #number of lagrangian parcles\n",
    "    dt=(data['time'][1]-data['time'][0]).item()/1e9 #sec\n",
    "    dx=(data['xf'][1].item()-data['xf'][0].item())*1e3 #meters\n",
    "    dy=(data['yf'][1].item()-data['yf'][0].item())*1e3 #meters\n",
    "    xs=data['xf'].values*1000\n",
    "    ys=data['yf'].values*1000\n",
    "    zs=data['zf'].values*1000\n",
    "    \n",
    "    def zf(z):\n",
    "        k=z #z is the # level of z\n",
    "        out=data['zf'].values[k]*1000\n",
    "        \n",
    "        return out\n",
    "    # def rho(x,y,z,t):\n",
    "    #     p=data['prs'].isel(xh=x,yh=y,zh=z,time=t).item()\n",
    "    #     p0=101325 #Pa\n",
    "    #     theta=data['th'].isel(xh=x,yh=y,zh=z,time=t).item()\n",
    "    #     T=theta*(p/p0)**(Rd/Cp)\n",
    "    #     qv=data['qv'].isel(xh=x,yh=y,zh=z,time=t).item()\n",
    "    #     # Tv=T*(1+eps*qv)\n",
    "    #     Tv=T*(eps+qv)/(eps*(1+qv))\n",
    "    #     rho = p/(Rd*Tv)\n",
    "    #     out=rho\n",
    "    #     return out\n",
    "    \n",
    "    def rho(x,y,z,rho_data_t):\n",
    "        out=rho_data_t[z,y,x]\n",
    "        return out\n",
    "    def m(t):\n",
    "        rho_data_t=data['rho'].isel(time=t).data\n",
    "        \n",
    "        m=0\n",
    "        #triple sum\n",
    "        for k in range(len(data['zh'])):\n",
    "            dz=(zf(k+1)-zf(k))\n",
    "            for j in range(len(data['yh'])):\n",
    "                for i in range(len(data['xh'])):\n",
    "                    rho_out=rho(i,j,k,rho_data_t)\n",
    "                    m+=rho_out*dz\n",
    "                    \n",
    "        #triple sum\n",
    "        out=m*dx*dy/Np\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a628b441-cb34-4625-98ea-756399604ffd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#SOME CALCULATIONS (TESTING)\n",
    "# # (Lx*Ly*(10**4))/1e6 #1M parcels ==> 1 billion kg/parcel\n",
    "# # (Lx*Ly*(10**4))/50e6 #50M parcels ==> 20 million kg/parcel\n",
    "# # (Lx*Ly*(10**4))/100e6 #100M parcels ==> 10 million kg/parcel\n",
    "\n",
    "# # 1e5 kg | 9.1125 e4 m^3\n",
    "# # x   kg | 1000*1000*62 = 6.2e7 m^3\n",
    "# (1000*1000*62)*(1e5/(9.1125e4))# ==> 68038408 ==> should have 68M kg in the bottom most layer \n",
    "\n",
    "# 68038408/19729158# (expected/calculated mass) ==> should have 3.5 parcels in each grid box on the bottom most layer\n",
    "# #we have 369e3 parcels on bottom layer ==> 369e3/(Nx*Ny) = 369e3/102400 = 3.6 parcels per layer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b876564-f013-44c3-918e-525b263f414d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if plotting==True:\n",
    "    #Calculate Mass Constant\n",
    "    # calculate='single_time'\n",
    "    # calculate=True\n",
    "    calculate=False\n",
    "    \n",
    "    if calculate==True:\n",
    "        Nt=len(data['time'])\n",
    "        m_arr=np.zeros((Nt))\n",
    "        for t in np.arange(Nt):\n",
    "            if np.mod(t,25)==0: print(t)\n",
    "            m_arr[t]=m(t)\n",
    "        dir3=dir+f'Project_Algorithms/Entrainment/OUTPUT/'\n",
    "        np.save(dir3+f'Mass_Array_{res}_{t_res}_{Np_str}.npy', m_arr)\n",
    "    elif calculate=='single_time':\n",
    "        Nt=len(data['time'])\n",
    "        m_arr=np.zeros((Nt))\n",
    "    \n",
    "        t=0 #len(data['time'])//2 #Pick some middle time\n",
    "        m_300=m(t)\n",
    "        for t in np.arange(Nt):\n",
    "            m_arr[t]=m_300 #UNCOMMENT FOR FULL CALCULATION\n",
    "        dir3=dir+f'Project_Algorithms/Entrainment/OUTPUT/'\n",
    "        np.save(dir3+f'Mass_Array_{res}_{t_res}_{Np_str}.npy', m_arr)\n",
    "    else:\n",
    "        dir3=dir+f'Project_Algorithms/Entrainment/OUTPUT/'\n",
    "        m_arr = np.load(dir3+f'Mass_Array_{res}_{t_res}_{Np_str}.npy')\n",
    "    \n",
    "    # # TESTING\n",
    "    # lst=[]\n",
    "    # for t in np.arange(133):\n",
    "    #     lst.append(m_arr[t])\n",
    "    \n",
    "    # plt.plot(lst)\n",
    "    # (np.max(lst)-np.min(lst))*100/np.mean(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be859db5-6d0c-41de-b16a-18534f0da7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if plotting==True:\n",
    "    PROCESSING=False\n",
    "    PROCESSING=True\n",
    "    \n",
    "    dir3=dir+'Project_Algorithms/Entrainment/OUTPUT/'\n",
    "    if PROCESSING==False:\n",
    "        open_file=dir3+f'2D_entrainmentdetrainment_profiles_{res}_{t_res}_{Np_str}.h5'\n",
    "    if PROCESSING==True:\n",
    "        open_file=dir3+f'2D_entrainmentdetrainment_profiles_PREPROCESSING_{res}_{t_res}_{Np_str}.h5'\n",
    "    with h5py.File(open_file, \"r\") as h5f:\n",
    "        profile_array_e_g = h5f[\"profile_array_e_g\"][:]\n",
    "        profile_array_e_c = h5f[\"profile_array_e_c\"][:]\n",
    "        profile_array_d_g = h5f[\"profile_array_d_g\"][:]\n",
    "        profile_array_d_c = h5f[\"profile_array_d_c\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ab09eb-7984-4c57-b28d-50896e4800bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if plotting==True:\n",
    "    def apply_constant(profile_array,apply):\n",
    "        if apply==True:\n",
    "            Nt=profile_array.shape[0]\n",
    "            Nz=profile_array.shape[1]\n",
    "        \n",
    "            profile_array/=(Lx*Ly*dt)\n",
    "            for t in np.arange(Nt):\n",
    "                profile_array[t]*=m_arr[t]\n",
    "            for z in np.arange(Nz):\n",
    "                dz=zf(z+1)-zf(z)\n",
    "                profile_array[:,z]/=dz\n",
    "        return profile_array\n",
    "    #APPLY CONSTANTS TO ENTRAINMENT VALUE\n",
    "    ##################################################\n",
    "    profile_array_e_g=apply_constant(profile_array_e_g,apply=True)\n",
    "    profile_array_e_c=apply_constant(profile_array_e_c,apply=True)\n",
    "    profile_array_d_g=-apply_constant(profile_array_d_g,apply=True)\n",
    "    profile_array_d_c=-apply_constant(profile_array_d_c,apply=True)\n",
    "    ##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad56556e-1887-44d8-bb2e-c3da8c2a22ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "if plotting==True:\n",
    "    PROCESSING=False\n",
    "    PROCESSING=True\n",
    "    \n",
    "    dir3=dir+'Project_Algorithms/Entrainment/OUTPUT/'\n",
    "    if PROCESSING==False:\n",
    "        open_file=dir3+f'2D_entrainmentdetrainment_combined_profiles_{res}_{t_res}_{Np_str}.h5'\n",
    "    if PROCESSING==True:\n",
    "        open_file=dir3+f'2D_entrainmentdetrainment_combined_profiles_PREPROCESSING_{res}_{t_res}_{Np_str}.h5'\n",
    "    with h5py.File(open_file, \"r\") as h5f:\n",
    "        profile_array_c_to_g = h5f[\"profile_array_c_to_g\"][:]\n",
    "        profile_array_g_to_c = h5f[\"profile_array_g_to_c\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bddfee-5ef7-4077-a29f-95244f87e7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if plotting==True:\n",
    "    def apply_constant(profile_array,apply):\n",
    "        if apply==True:\n",
    "            Nt=profile_array.shape[0]\n",
    "            Nz=profile_array.shape[1]\n",
    "        \n",
    "            profile_array/=(Lx*Ly*dt)\n",
    "            for t in np.arange(Nt):\n",
    "                profile_array[t]*=m_arr[t]\n",
    "            for z in np.arange(Nz):\n",
    "                dz=zf(z+1)-zf(z)\n",
    "                profile_array[:,z]/=dz\n",
    "        return profile_array\n",
    "    #APPLY CONSTANTS TO ENTRAINMENT VALUE\n",
    "    ##################################################\n",
    "    profile_array_c_to_g=apply_constant(profile_array_c_to_g,apply=True)\n",
    "    profile_array_g_to_c=apply_constant(profile_array_g_to_c,apply=True)\n",
    "    ##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f5def1-878d-42f2-8bcd-c1695c70c42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetData(type):\n",
    "    if type=='general':\n",
    "        profile_array_e=profile_array_e_g\n",
    "        profile_array_d=profile_array_d_g\n",
    "        profile_array_net=profile_array_e-profile_array_d\n",
    "    if type=='cloudy':\n",
    "        profile_array_e=profile_array_e_c\n",
    "        profile_array_d=profile_array_d_c\n",
    "        profile_array_net=profile_array_e-profile_array_d\n",
    "\n",
    "    return profile_array_e,profile_array_d,profile_array_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfe285d-9acf-4196-a3c2-b6d1085de6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean_entrainment(ax, profile_array_e, profile_array_d, title, linestyle='solid'):\n",
    "    zh=data['zh'].data\n",
    "\n",
    "    # Compute mean profiles\n",
    "    e = np.mean(profile_array_e, axis=0)\n",
    "    d = np.mean(profile_array_d, axis=0)\n",
    "    net = np.mean(profile_array_e - profile_array_d, axis=0)\n",
    "\n",
    "    # Plot\n",
    "    ax.plot(e, zh, linestyle=linestyle, color='blue', label='Entrainment')\n",
    "    ax.plot(d, zh, linestyle=linestyle, color='red', label='Detrainment')\n",
    "    ax.plot(net, zh, linestyle=linestyle, color='black', label='Net Entrainment')\n",
    "    ax.axvline(0, color='black')\n",
    "\n",
    "    ax.axhline(cloudbase, color='purple', linestyle='dashed', lw=1.2)\n",
    "    ax.axhline(MeanLFC / 1000, color='green', linestyle='dashed', lw=1.2)\n",
    "    \n",
    "    ax.set_title(f\"{title}\",fontsize=10.5)\n",
    "    ax.set_xlabel(r\"($kg\\ m^{-3}\\ s^{-1}$)\")  \n",
    "    ax.set_ylabel('z (km)')\n",
    "    ax.legend()\n",
    "\n",
    "    # Format x-axis in scientific notation\n",
    "    apply_scientific_notation([ax])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e223af2-4540-41a1-8ab9-4f51e9e1b905",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SaveFigure(fig,filename):\n",
    "    save_dir = f\"PLOTS/{res}_{t_res}_{Np_str}\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    fig.savefig(f\"{save_dir}/{filename}_{res}_{t_res}_{Np_str}.jpg\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ad0554-7937-470a-9b31-332c7d9afb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "zh=data['zh'].data\n",
    "def Plot_EntrainmentDetrainmentRows(data, array_triplets, type_labels, plotting=True):\n",
    "    if not plotting:\n",
    "        return\n",
    "        \n",
    "    cmap1 = plt.cm.viridis\n",
    "    cmap2 = plt.cm.seismic \n",
    "    n_levels = 29\n",
    "    z_lim=20\n",
    "\n",
    "    num_rows = len(array_triplets)\n",
    "\n",
    "    fig = plt.figure(figsize=(18, 4 * num_rows))\n",
    "    gs = GridSpec(num_rows, 4, figure=fig)\n",
    "    all_ax1, all_ax2, all_ax3 = [], [], []\n",
    "    \n",
    "    for row_idx, ((profile_array_e, profile_array_d, profile_array_net), type_label) in enumerate(zip(array_triplets, type_labels)):\n",
    "        vmax_shared = np.max([np.max(profile_array_e), np.max(profile_array_d)])\n",
    "        norm_shared = mcolors.Normalize(vmin=0, vmax=vmax_shared)\n",
    "        norm_shared = None\n",
    "\n",
    "        y = data['zh'].data\n",
    "        x = np.arange(profile_array_e.shape[0])\n",
    "\n",
    "        mins=(data['time'].data[1].astype(int)/1e9/60)\n",
    "        plot_kwargs = {\n",
    "            'PlotData': None,\n",
    "            'xTickLabels': x, 'yTickLabels': y,\n",
    "            'contour_type': 'line',#'fill',\n",
    "            'num_xticks': 11, 'round_xticks': None, 'xTickInterval': 60/mins,\n",
    "            'num_yticks': 15, 'round_yticks': 2, 'yTickInterval': None,\n",
    "            'add_colorbar': True, 'fig': fig, 'levels': 29, 'colorbar_label_rotation': 0, 'colorbar_label': None,\n",
    "            'xlabel': \"t (hours)\", 'ylabel': \"z (km)\",\n",
    "            'solid_contour_labels': False, 'solid_contour_round': None,\n",
    "            'xtick_rotation': 0, 'ytick_rotation': 0, 'cbar_rotation': 0,\n",
    "            'save_path': None, 'save_dpi': 300,\n",
    "            'colorbar_kwargs': {\n",
    "                'extend': 'both'\n",
    "            },\n",
    "            'norm': norm_shared\n",
    "        }\n",
    "\n",
    "        ax1 = fig.add_subplot(gs[row_idx, 0])\n",
    "        ax2 = fig.add_subplot(gs[row_idx, 1])\n",
    "        ax3 = fig.add_subplot(gs[row_idx, 2])\n",
    "\n",
    "        all_ax1.append(ax1)\n",
    "        all_ax2.append(ax2)\n",
    "        all_ax3.append(ax3)\n",
    "\n",
    "        plot_kwargs1 = plot_kwargs.copy()\n",
    "        plot_kwargs1['PlotData'] = profile_array_e.copy().T\n",
    "        plot_kwargs1['cmap'] = cmap1\n",
    "        [contour1, cbar1] = UltimateContourPlot(ax1, **plot_kwargs1)\n",
    "        ax1.set_ylim(0, z_lim)\n",
    "        ax1.set_title(f'Entrainment {type_label}',fontsize=10.5)\n",
    "\n",
    "        plot_kwargs2 = plot_kwargs.copy()\n",
    "        plot_kwargs2['PlotData'] = profile_array_d.copy().T\n",
    "        plot_kwargs2['cmap'] = cmap1\n",
    "        [contour2, cbar2] = UltimateContourPlot(ax2, **plot_kwargs2)\n",
    "        ax2.set_ylim(0, z_lim)\n",
    "        ax2.set_title(f'Detrainment {type_label}',fontsize=10.5)\n",
    "\n",
    "        plot_data3 = profile_array_net.copy().T\n",
    "        vmin = -np.max(abs(profile_array_net)) / 2\n",
    "        vmax = +np.max(abs(profile_array_net))\n",
    "        levels = np.linspace(vmin, vmax, n_levels)\n",
    "        norm = mcolors.BoundaryNorm(boundaries=levels, ncolors=256)\n",
    "\n",
    "        plot_kwargs3 = plot_kwargs.copy()\n",
    "        plot_kwargs3['PlotData'] = plot_data3\n",
    "        plot_kwargs3['cmap'] = cmap2\n",
    "        plot_kwargs3['norm'] = norm\n",
    "        plot_kwargs3['levels'] = levels\n",
    "        [contour3, cbar3] = UltimateContourPlot(ax3, **plot_kwargs3)\n",
    "        ax3.set_ylim(0, 19)\n",
    "        ax3.set_title(f'Net Entrainment {type_label}',fontsize=10.5)\n",
    "        # fig.suptitle(f\"{type_labels[row_idx][0].upper() + type_labels[row_idx][1:]} Updraft Entrainment/Detrainment\")\n",
    "\n",
    "        def apply_scientific_notation_colorbar(cbars):\n",
    "            from matplotlib.ticker import ScalarFormatter\n",
    "            formatter = ScalarFormatter(useMathText=True)\n",
    "            formatter.set_powerlimits((-2, 2))\n",
    "            for cbar in cbars:\n",
    "                cbar.formatter = formatter\n",
    "                cbar.update_ticks()\n",
    "\n",
    "        apply_scientific_notation_colorbar([cbar1, cbar2, cbar3])\n",
    "\n",
    "        #FIXING CONTOUR COLORBAR LINES THICKNESS\n",
    "        for cbar in [cbar1, cbar2, cbar3]:\n",
    "            for cbar_line in cbar.ax.collections:\n",
    "                cbar_line.set_linewidth(3)\n",
    "\n",
    "        for ax in [ax1,ax2,ax3]:\n",
    "            ax.axhline(cloudbase, color='purple', linestyle='dashed',lw=1.2)\n",
    "            ax.axhline(MeanLFC / 1000, color='green', linestyle='dashed',lw=1.2)\n",
    "            xticks = ax.get_xticks()\n",
    "            new_labels = [f\"{tick*mins/(60)+6:.0f}\" for tick in xticks]\n",
    "            ax.set_xticklabels(new_labels)\n",
    "            \n",
    "    ax4 = fig.add_subplot(gs[0, 3])\n",
    "    ax5 = fig.add_subplot(gs[1, 3])\n",
    "    plot_mean_entrainment(ax4, profile_array_e1, profile_array_d1, title='Mean Vertical Profile')\n",
    "    plot_mean_entrainment(ax5, profile_array_e2, profile_array_d2, title='Mean Vertical Profile')\n",
    "    ax4.set_ylim([zh[0], z_lim])\n",
    "    ax5.set_ylim([zh[0], z_lim])\n",
    "    ax4.yaxis.set_major_locator(MaxNLocator(nbins=10, prune=None))\n",
    "    ax5.yaxis.set_major_locator(MaxNLocator(nbins=10, prune=None))\n",
    "    fig.tight_layout()\n",
    "    ax4.set_ylim([0, z_lim])\n",
    "    ax5.set_ylim([0, z_lim])\n",
    "\n",
    "    ticks = np.linspace(0, z_lim, num=11)\n",
    "    for ax in all_ax1 + all_ax2 + all_ax3 + [ax4, ax5]:\n",
    "        ax.set_ylim([0, z_lim])\n",
    "        ax.set_yticks(ticks)\n",
    "        ax.yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "        ax.margins(y=0)\n",
    "\n",
    "    #SAVING\n",
    "    filename=f\"Entrainment_ContourPlot_DomainProfiles\"\n",
    "    SaveFigure(fig,filename)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc5b5e1-bf0e-49c0-95bd-21ed71940cd0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#LOAD DATA\n",
    "type1='general';type2='cloudy'\n",
    "[profile_array_e1,profile_array_d1,profile_array_net1]=GetData(type=type1)\n",
    "[profile_array_e2,profile_array_d2,profile_array_net2]=GetData(type=type2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3fea4a-3680-4f13-8b96-2edc2bea5c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "#PLOTTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22e5e49-5c7d-4c86-9142-0d9c318121c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONTOUR PLOTS\n",
    "array_triplets = [\n",
    "    (profile_array_e1, profile_array_d1, profile_array_net1),\n",
    "    (profile_array_e2, profile_array_d2, profile_array_net2)\n",
    "]\n",
    "type_labels = ['(General Updraft)', '(Cloudy Updraft)']\n",
    "\n",
    "Plot_EntrainmentDetrainmentRows(data, array_triplets, type_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac904a8f-69fb-4d89-87e1-9779308a2509",
   "metadata": {},
   "outputs": [],
   "source": [
    "#COMBINED ENTRAINMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7564afd-6d40-4b27-994a-f024bd695e63",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# #ENTRAINMENT TRANSFER CONTOUR PLOTS\n",
    "# if plotting==True:\n",
    "#     #Plotting\n",
    "#     ############################################################\n",
    "#     import matplotlib.pyplot as plt\n",
    "#     from matplotlib.gridspec import GridSpec\n",
    "#     import numpy as np\n",
    "    \n",
    "#     fig = plt.figure(figsize=(10, 8))\n",
    "#     gs = GridSpec(2, 2, figure=fig)\n",
    "    \n",
    "#     ######\n",
    "#     cmap1 = plt.cm.viridis\n",
    "#     cmap1 = plt.cm.seismic \n",
    "#     n_levels=30\n",
    "#     ######\n",
    "    \n",
    "#     ######\n",
    "#     vmax_shared = np.max([np.max(profile_array_c_to_g), np.max(profile_array_g_to_c)])\n",
    "#     norm_shared = mcolors.Normalize(vmin=0, vmax=vmax_shared)\n",
    "#     ######\n",
    "    \n",
    "#     # First subplot: Entrainment\n",
    "#     ########################################\n",
    "#     ax1 = fig.add_subplot(gs[0, 0])\n",
    "#     contour1 = ax1.contourf(profile_array_c_to_g.T, cmap=cmap1,levels=n_levels)\n",
    "#     # contour1 = ax1.contourf(profile_array_e_g.T, cmap=cmap1, norm=norm_shared, levels=n_levels)\n",
    "#     cbar1=fig.colorbar(contour1, ax=ax1)\n",
    "#     Nz = len(data['zh'])\n",
    "#     ax1.set_yticks(np.arange(Nz))\n",
    "#     new_ytick_labels = np.round(data['zh'].values[:Nz], 2)\n",
    "#     ax1.set_yticklabels(new_ytick_labels, fontsize=8, rotation=0)\n",
    "#     ax1.set_ylabel('z (km)');ax1.set_xlabel('t (timesteps)')\n",
    "#     ax1.set_title('Cloudy to General')\n",
    "    \n",
    "#     # Second subplot: Detrainment\n",
    "#     ########################################\n",
    "#     ax2 = fig.add_subplot(gs[0, 1])\n",
    "#     contour2 = ax2.contourf(profile_array_g_to_c.T, cmap=cmap1, levels=n_levels)\n",
    "#     # contour2 = ax2.contourf(profile_array_e_c.T, cmap=cmap1, norm=norm_shared, levels=n_levels)\n",
    "#     cbar2 = fig.colorbar(contour2, ax=ax2)\n",
    "#     ax2.set_yticks(np.arange(Nz))\n",
    "#     new_ytick_labels = np.round(data['zh'].values[:Nz], 2)\n",
    "#     ax2.set_yticklabels(new_ytick_labels, fontsize=8, rotation=0)\n",
    "#     ax2.set_ylabel('z (km)');ax2.set_xlabel('t (timesteps)')\n",
    "#     ax2.set_title('General to Cloudy')\n",
    "\n",
    "#     ###################### FIXING Y TICKS\n",
    "#     Nz = len(data['zh'])\n",
    "#     step = 4  # change to 2, 5, etc. depending on how spaced you want them\n",
    "#     ytick_pos = np.arange(0, Nz, step)\n",
    "#     ytick_labels = np.round(data['zh'].values[ytick_pos], 2)\n",
    "#     for axis in [ax1,ax2]:\n",
    "#         axis.set_yticks(ytick_pos)\n",
    "#         axis.set_yticklabels(ytick_labels, fontsize=8, rotation=0)\n",
    "\n",
    "#     ###################### SCIENTIFIC NOTATION\n",
    "#     apply_scientific_notation_colorbar([cbar1,cbar2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b6bfb8-429b-4801-90cb-037e4792d721",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_transfer_rate(ax, c_to_g, g_to_c,title):\n",
    "    zh=data['zh'].data\n",
    "\n",
    "    # Mean profiles\n",
    "    c_to_g_mean = np.mean(c_to_g, axis=0)\n",
    "    g_to_c_mean = np.mean(g_to_c, axis=0)\n",
    "\n",
    "    # Plot transfers\n",
    "    ax.plot(c_to_g_mean, zh, color='red', label='Cloudy → General')\n",
    "    ax.plot(g_to_c_mean, zh, color='blue', label='General → Cloudy')\n",
    "    ax.axvline(0, color='black', linewidth=1)\n",
    "\n",
    "    # Reference lines\n",
    "    ax.axhline(cloudbase, color='purple', linestyle='dashed',lw=1.2)\n",
    "    ax.axhline(MeanLFC / 1000, color='forestgreen', linestyle='dashed',lw=1.2)\n",
    "\n",
    "    # Labeling and formatting\n",
    "    ax.set_title(f\"{title}\")\n",
    "    ax.set_xlabel('Mass Transfer Rate')\n",
    "    ax.set_xlabel(r\"($kg m^{-3} s^{-1}$)\")  \n",
    "    ax.set_ylabel('z (km)')\n",
    "    # ax.set_xlim(left=0)\n",
    "    ax.legend()\n",
    "\n",
    "    apply_scientific_notation([ax])\n",
    "\n",
    "def plot_transfer_ratio(ax, profile_array_e_g, c_to_g, profile_array_e_c, g_to_c, title):\n",
    "    zh = data['zh'].data\n",
    "\n",
    "    # Compute mean profiles first\n",
    "    mean_c_to_g = np.mean(c_to_g, axis=0)\n",
    "    mean_g_to_c = np.mean(g_to_c, axis=0)\n",
    "    \n",
    "    mean_e_g = np.mean(profile_array_e_g, axis=0)\n",
    "    mean_e_c = np.mean(profile_array_e_c, axis=0)\n",
    "    mean_d_g = np.mean(profile_array_d_g, axis=0)\n",
    "    mean_d_c = np.mean(profile_array_d_c, axis=0)\n",
    "\n",
    "    # Mask ratios where denominator is too small\n",
    "    threshold = 0\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        ratio_1 = np.where(mean_e_c > threshold, mean_g_to_c / mean_e_c, np.nan)\n",
    "        ratio_2 = np.where(mean_d_g > threshold, mean_g_to_c / mean_d_g, np.nan)\n",
    "        ratio_3 = np.where(mean_e_g > threshold, mean_c_to_g / mean_e_g, np.nan)\n",
    "        ratio_4 = np.where(mean_d_c > threshold, mean_c_to_g / mean_d_c, np.nan)\n",
    "    \n",
    "    # Plot in specified order\n",
    "    ax.plot(ratio_1, zh, color='blue', label='General → Cloudy / Cloudy Entrainment')\n",
    "    ax.plot(ratio_2, zh, color='deepskyblue', label='General → Cloudy / General Detrainment')\n",
    "    ax.plot(ratio_3, zh, color='red', label='Cloudy → General / General Entrainment')\n",
    "    ax.plot(ratio_4, zh, color='orangered', label='Cloudy → General / Cloudy Detrainment')\n",
    "    \n",
    "    ax.axvline(1, color='black', linestyle='dashed', linewidth=1)\n",
    "\n",
    "    # Reference horizontal lines\n",
    "    ax.axhline(cloudbase, color='purple', linestyle='dashed', lw=1.2)\n",
    "    ax.axhline(MeanLFC / 1000, color='green', linestyle='dashed', lw=1.2)\n",
    "\n",
    "    # Labels and limits\n",
    "    ax.set_title(f\"{title}\")\n",
    "    ax.set_xlabel('Ratio')\n",
    "    ax.set_ylabel('z (km)')\n",
    "    pad_fraction = 10\n",
    "    pad_multiplier = (100 + pad_fraction) / 100\n",
    "    ax.set_xlim(0, 1 * pad_multiplier)\n",
    "\n",
    "    ax.legend(fontsize=10.5-2, loc='upper right')\n",
    "    apply_scientific_notation([ax])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210c930b-87cd-48a6-b86a-ad56cadcfe35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VERTICAL PROFILES\n",
    "fig = plt.figure(figsize=(18, 6))\n",
    "gs = gridspec.GridSpec(1, 4, wspace=0.2)\n",
    "\n",
    "ax1 = fig.add_subplot(gs[0])\n",
    "ax2 = fig.add_subplot(gs[1])\n",
    "ax3 = fig.add_subplot(gs[2])\n",
    "ax4 = fig.add_subplot(gs[3])\n",
    "\n",
    "# Call function for each subplot\n",
    "plot_mean_entrainment(ax1, profile_array_e1, profile_array_d1, title='')\n",
    "plot_mean_entrainment(ax2, profile_array_e2, profile_array_d2, title='')\n",
    "plot_transfer_rate(ax3, profile_array_c_to_g, profile_array_g_to_c, title='')\n",
    "plot_transfer_ratio(ax4, profile_array_e_g,profile_array_c_to_g, profile_array_e_c,profile_array_g_to_c, title='')\n",
    "fix_x_limits([ax2,ax3])\n",
    "\n",
    "\n",
    "#SAVING\n",
    "filename=f\"Combined_Entrainment_VerticalProfiles\"\n",
    "SaveFigure(fig,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9073a5-61b4-467e-880d-4d91f437171c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#contour plot\n",
    "# #Plotting\n",
    "# ############################################################\n",
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.gridspec import GridSpec\n",
    "# import numpy as np\n",
    "\n",
    "# fig = plt.figure(figsize=(10, 8))\n",
    "# gs = GridSpec(2, 2, figure=fig)\n",
    "\n",
    "# ######\n",
    "# cmap1 = plt.cm.viridis\n",
    "# cmap1 = plt.cm.seismic \n",
    "# n_levels=30\n",
    "# ######\n",
    "\n",
    "# ######\n",
    "# vmax_shared = np.max([np.max(profile_array_c_to_g), np.max(profile_array_g_to_c)])\n",
    "# norm_shared = mcolors.Normalize(vmin=0, vmax=vmax_shared)\n",
    "# ######\n",
    "\n",
    "# # First subplot: Entrainment\n",
    "# ########################################\n",
    "# ax1 = fig.add_subplot(gs[0, 0])\n",
    "# contour1 = ax1.contourf(profile_array_c_to_g.T, cmap=cmap1,levels=n_levels)\n",
    "# # contour1 = ax1.contourf(profile_array_e_g.T, cmap=cmap1, norm=norm_shared, levels=n_levels)\n",
    "# cbar1=fig.colorbar(contour1, ax=ax1)\n",
    "# Nz = len(data['zh'])\n",
    "# ax1.set_yticks(np.arange(Nz))\n",
    "# new_ytick_labels = np.round(data['zf'].values[:Nz], 2)\n",
    "# ax1.set_yticklabels(new_ytick_labels, fontsize=8, rotation=0)\n",
    "# ax1.set_ylabel('z (km)');ax1.set_xlabel('t (timesteps)')\n",
    "# ax1.set_title('Cloudy to General')\n",
    "\n",
    "# # Second subplot: Detrainment\n",
    "# ########################################\n",
    "# ax2 = fig.add_subplot(gs[0, 1])\n",
    "# contour2 = ax2.contourf(profile_array_g_to_c.T, cmap=cmap1, levels=n_levels)\n",
    "# # contour2 = ax2.contourf(profile_array_e_c.T, cmap=cmap1, norm=norm_shared, levels=n_levels)\n",
    "# cbar2 = fig.colorbar(contour2, ax=ax2)\n",
    "# ax2.set_yticks(np.arange(Nz))\n",
    "# new_ytick_labels = np.round(data['zf'].values[:Nz], 2)\n",
    "# ax2.set_yticklabels(new_ytick_labels, fontsize=8, rotation=0)\n",
    "# ax2.set_ylabel('z (km)');ax2.set_xlabel('t (timesteps)')\n",
    "# ax2.set_title('General to Cloudy')\n",
    "\n",
    "# ###################### FIXING Y TICKS\n",
    "# Nz = len(data['zh'])\n",
    "# step = 4  # change to 2, 5, etc. depending on how spaced you want them\n",
    "# ytick_pos = np.arange(0, Nz, step)\n",
    "# ytick_labels = np.round(data['zf'].values[ytick_pos], 2)\n",
    "# for axis in [ax1,ax2]:\n",
    "#     axis.set_yticks(ytick_pos)\n",
    "#     axis.set_yticklabels(ytick_labels, fontsize=8, rotation=0)\n",
    "\n",
    "# ###################### SCIENTIFIC NOTATION\n",
    "# apply_scientific_notation_colorbar([cbar1,cbar2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d84229-72f8-479f-a45c-94a860f0603b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841808bd-126a-470f-a15f-b0e82dab30e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c42887-0c3e-406b-b006-a2925598f053",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "#TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c035b4a1-2af4-4a20-8cc1-25bb6021fb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TESTING COMBINED ENTRAINMENT\n",
    "c_to_g=profile_array_c_to_g\n",
    "g_to_c=profile_array_g_to_c\n",
    "\n",
    "# Compute mean profiles first\n",
    "mean_c_to_g = np.mean(c_to_g, axis=0)\n",
    "mean_g_to_c = np.mean(g_to_c, axis=0)\n",
    "\n",
    "mean_e_g = np.mean(profile_array_e_g, axis=0)\n",
    "mean_e_c = np.mean(profile_array_e_c, axis=0)\n",
    "mean_d_g = np.mean(profile_array_d_g, axis=0)\n",
    "mean_d_c = np.mean(profile_array_d_c, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd2ae50-50ec-4f69-99c6-3a7bd35ab1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #TESTING ABOVE 17km\n",
    "# print(np.where(mean_c_to_g>mean_d_c))\n",
    "# print( mean_c_to_g[80:83+1] )\n",
    "# print( mean_d_c[80:83+1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fba6cb5-4d79-48bd-8b72-e51e80285bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio=g_to_c/profile_array_e_c\n",
    "np.where(ratio>1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6f8e77-9f76-41af-85df-fafd8a544ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 6))\n",
    "gs = gridspec.GridSpec(1, 2, figure=fig, wspace=0.3)\n",
    "\n",
    "# First subplot: direct entrainment/detrainment rates\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "ax1.plot(mean_c_to_g, data['zh'], label='c_to_g')\n",
    "ax1.plot(mean_d_c, data['zh'], label='d_c')\n",
    "ax1.legend()\n",
    "ax1.set_title(\"Entrainment Rates\")\n",
    "ax1.set_xlabel(rf\"$(kg/m^3/s)$\")\n",
    "ax1.set_ylabel(\"z (km)\")\n",
    "ax1.grid(True)\n",
    "\n",
    "# Second subplot: ratios\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "ax2.plot(mean_g_to_c / mean_e_c, data['zh'], label='g_to_c / e_c')\n",
    "ax2.plot(mean_c_to_g / mean_d_c, data['zh'], label='c_to_g / d_c', color='k')\n",
    "ax2.axvline(1,linestyle='dashed',color='gray')\n",
    "ax2.legend()\n",
    "ax2.set_title(\"Updraft Transfer Entrainment\")\n",
    "ax2.set_xlabel(\"Ratio\")\n",
    "ax2.set_ylabel(\"z (km)\")\n",
    "ax2.grid(True)\n",
    "\n",
    "#Conclusion: Transfer Rate calculations are not stored in the same time/space location as entrainment/detrainment rates.\n",
    "#this affects the result near cloud base and cloud top\n",
    "#Unsure about similar issue with cloudy entrainment at cloud top\n",
    "\n",
    "#Fix: For detrainment comparisons, need a seperate \"combined entrainment\" dataset stored at previous timestep\n",
    "#Unsure how to fix issue with e_c VS g_to_c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e14aee-9d1f-4fe6-b554-ddc493ff1ce6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # Assuming profile_array_e_g is already defined\n",
    "# Nt = profile_array_e.shape[0]  # Total number of time steps\n",
    "# Nz = profile_array_e.shape[1]\n",
    "# zhs = data['zh']\n",
    "\n",
    "# # Calculate the number of rows and columns needed for the subplots\n",
    "# cols = 4  # You can adjust this to change the number of columns\n",
    "# rows = int(np.ceil(Nt / 10 / cols))  # Calculate rows dynamically based on Nt (max 16 plots)\n",
    "\n",
    "# # Create a figure with a grid of subplots, adjust the figure size for better spacing\n",
    "# fig, axes = plt.subplots(rows, cols, figsize=(12, 3 * rows))\n",
    "# axes = axes.flatten()  # Flatten axes to make indexing easier\n",
    "\n",
    "# # Loop through time steps, creating a plot for each\n",
    "# for i, t in enumerate(np.arange(0, Nt, 10)):  # Use np.arange with step size 10\n",
    "#     plot_data = profile_array_net[t]\n",
    "    \n",
    "#     # Select the corresponding axis\n",
    "#     ax = axes[i]\n",
    "    \n",
    "#     # Plot the data for the current time step\n",
    "#     ax.plot(plot_data, zhs, color='black')  # Adjust to match your data's structure\n",
    "#     ax.axvline(0,linestyle='dashed',color='k')\n",
    "    \n",
    "#     # Set title for the subplot\n",
    "#     ax.set_title(f\"Time Step {t}\")\n",
    "\n",
    "#     apply_scientific_notation([ax])\n",
    "\n",
    "# # Remove any unused axes (if there are fewer plots than grid spaces)\n",
    "# for j in range(i + 1, len(axes)):\n",
    "#     axes[j].axis('off')\n",
    "\n",
    "# # Add global labels and title\n",
    "# plt.xlabel('X-axis label')  # Replace with actual x-axis label\n",
    "# plt.ylabel('Z (km)')  # Replace with your y-axis label\n",
    "\n",
    "# # Adjust layout for better spacing\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076a0a1c-9e35-4233-878f-d33ebba46652",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # Assuming profile_array_e_g is already defined\n",
    "# Nt = profile_array_e.shape[0]  # Total number of time steps\n",
    "# Nz = profile_array_e.shape[1]\n",
    "# zhs = data['zh']\n",
    "\n",
    "# # Calculate the number of rows and columns needed for the subplots\n",
    "# cols = 4  # You can adjust this to change the number of columns\n",
    "# rows = int(np.ceil(Nt / 10 / cols))  # Calculate rows dynamically based on Nt (max 16 plots)\n",
    "\n",
    "# # Create a figure with a grid of subplots, adjust the figure size for better spacing\n",
    "# fig, axes = plt.subplots(rows, cols, figsize=(12, 3 * rows))\n",
    "# axes = axes.flatten()  # Flatten axes to make indexing easier\n",
    "\n",
    "# # Loop through time steps, creating a plot for each\n",
    "# for i, t in enumerate(np.arange(55,67, 1)):  # Use np.arange with step size 10\n",
    "#     plot_data = profile_array_net[t]\n",
    "    \n",
    "#     # Select the corresponding axis\n",
    "#     ax = axes[i]\n",
    "    \n",
    "#     # Plot the data for the current time step\n",
    "#     ax.plot(plot_data, zhs, color='black')  # Adjust to match your data's structure\n",
    "#     ax.axvline(0,linestyle='dashed',color='k')\n",
    "    \n",
    "#     # Set title for the subplot\n",
    "#     ax.set_title(f\"Time Step {t}\")\n",
    "\n",
    "#     apply_scientific_notation([ax])\n",
    "\n",
    "# # Remove any unused axes (if there are fewer plots than grid spaces)\n",
    "# for j in range(i + 1, len(axes)):\n",
    "#     axes[j].axis('off')\n",
    "\n",
    "# # Add global labels and title\n",
    "# plt.xlabel('X-axis label')  # Replace with actual x-axis label\n",
    "# plt.ylabel('Z (km)')  # Replace with your y-axis label\n",
    "\n",
    "# # Adjust layout for better spacing\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83bcc8c-335b-4f48-8cbe-7b9ce609d863",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # w_tz=data['winterp'].mean(dim=('xh','yh'))\n",
    "# # qc_tz=data['qc'].mean(dim=('xh','yh'))\n",
    "# # # w_tz=data['winterp'].isel(yh=100).mean(dim=('xh'))\n",
    "# # # qc_tz=data['qc'].isel(yh=100).mean(dim=('xh'))\n",
    "\n",
    "# # def DdzStretch(f):\n",
    "# #     import numpy as np\n",
    "# #     #f must be interpolated to cell centers\n",
    "# #     dz=np.diff(data['zf'].values)\n",
    "# #     dz=dz.copy()[np.newaxis, :, np.newaxis, np.newaxis]\n",
    "    \n",
    "# #     ddz=np.zeros_like(f)\n",
    "# #     ddz[:, 1:-1] = (f[:, 2:] - f[:, :-2]) / (2 * dz[:, 1:-1])\n",
    "# #     ddz[:, 0] = (f[:, 1] - f[:, 0]) / dz[:, 0]  # Forward difference \n",
    "# #     ddz[:, -1] = (f[:, -1] - f[:, -2]) / dz[:, -1]  # Backward difference \n",
    "# #     return ddz\n",
    "\n",
    "# # u=data['uinterp'].data\n",
    "# # dudz=DdzStretch(u)\n",
    "# # dudz_tz=np.mean(dudz,axis=(2,3))\n",
    "# # # dudz_tz=np.mean(dudz[:,:,100],axis=(2))\n",
    "\n",
    "# # w=data['winterp'].data\n",
    "# # dwdz=DdzStretch(w)\n",
    "# # dwdz_tz=np.mean(dwdz,axis=(2,3))\n",
    "# # # dwdz_tz=np.mean(dwdz[:,:,100],axis=(2))\n",
    "\n",
    "# fig, axs = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "# # Plot the first contour plot for w_tz\n",
    "# ax1 = axs[0, 0]  # First subplot (top-left)\n",
    "# c1 = ax1.contourf(w_tz.T,levels=20)  # Transpose if necessary\n",
    "# fig.colorbar(c1, ax=ax1)\n",
    "# ax1.set_title('w')\n",
    "\n",
    "# # Plot the second contour plot for du/dz\n",
    "# ax2 = axs[0, 1]  # Second subplot (top-right)\n",
    "# c2 = ax2.contourf(dudz_tz.T,levels=20)  # Transpose if necessary\n",
    "# fig.colorbar(c2, ax=ax2)\n",
    "# ax2.set_title('du/dz')\n",
    "\n",
    "# # Plot the third contour plot for dw/dz\n",
    "# ax3 = axs[1, 0]  # Third subplot (bottom-left)\n",
    "# c3 = ax3.contourf(dwdz_tz.T,cmap='RdBu',levels=20,vmax=0.004)  # Transpose if necessary\n",
    "# fig.colorbar(c3, ax=ax3)\n",
    "# ax3.set_title('dw/dz')\n",
    "\n",
    "# # Plot the third contour plot for dw/dz\n",
    "# ax4 = axs[1, 1]  # Third subplot (bottom-left)\n",
    "# c4 = ax4.contourf(qc_tz.T,cmap='RdBu',levels=20)  # Transpose if necessary\n",
    "# fig.colorbar(c4, ax=ax4)\n",
    "# ax4.set_title('qc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
