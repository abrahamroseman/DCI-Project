{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db6b85b-2c5f-4818-9147-e225704d14e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading in Packages and Data\n",
    "\n",
    "#Importing Packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "import matplotlib.gridspec as gridspec\n",
    "import xarray as xr\n",
    "import os; import time\n",
    "import pickle\n",
    "import h5py\n",
    "###############################################################\n",
    "def coefs(coefficients,degree):\n",
    "    coef=coefficients\n",
    "    coefs=\"\"\n",
    "    for n in range(degree, -1, -1):\n",
    "        string=f\"({coefficients[len(coef)-(n+1)]:.1e})\"\n",
    "        coefs+=string + f\"x^{n}\"\n",
    "        if n != 0:\n",
    "            coefs+=\" + \"\n",
    "    return coefs\n",
    "###############################################################\n",
    "\n",
    "#Importing Model Data\n",
    "check=False\n",
    "dir='/mnt/lustre/koa/koastore/torri_group/air_directory/DCI-Project/'\n",
    "###############################################################\n",
    "\n",
    "# dx = 1 km; Np = 1M; Nt = 5 min\n",
    "data=xr.open_dataset(dir+'../cm1r20.3/run/cm1out_1km_5min.nc', decode_timedelta=True) #***\n",
    "parcel=xr.open_dataset(dir+'../cm1r20.3/run/cm1out_pdata_1km_5min_1e6.nc', decode_timedelta=True) #***\n",
    "res='1km';t_res='5min'\n",
    "Np_str='1e6'\n",
    "\n",
    "# # dx = 1km; Np = 50M\n",
    "# #Importing Model Data\n",
    "# check=False\n",
    "# dir2='/home/air673/koa_scratch/'\n",
    "# data=xr.open_dataset(dir2+'cm1out_1km_1min.nc', decode_timedelta=True) #***\n",
    "# parcel=xr.open_dataset(dir2+'cm1out_pdata_1km_1min_50M.nc', decode_timedelta=True) #***\n",
    "# res='1km'; t_res='1min'; Np_str='50e6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cf6491-bad5-4a6e-851a-7db2ec18da64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "dir2='/mnt/lustre/koa/koastore/torri_group/air_directory/DCI-Project/'\n",
    "path=dir2+'../Functions/'\n",
    "sys.path.append(path)\n",
    "\n",
    "import NumericalFunctions\n",
    "from NumericalFunctions import * # import NumericalFunctions \n",
    "import PlottingFunctions\n",
    "from PlottingFunctions import * # import PlottingFunctions\n",
    "\n",
    "\n",
    "# # Get all functions in NumericalFunctions\n",
    "# import inspect\n",
    "# functions = [f[0] for f in inspect.getmembers(NumericalFunctions, inspect.isfunction)]\n",
    "# functions\n",
    "\n",
    "# # Get all functions in NumericalFunctions\n",
    "# import inspect\n",
    "# functions = [f[0] for f in inspect.getmembers(PlottingFunctions, inspect.isfunction)]\n",
    "# functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6204cd-8fba-45d2-ba8c-7d95fb844786",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "#PLOTTING\n",
    "plotting=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cda036-e1cf-4516-ad5e-1ccd7d76511d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# #DOMAIN SUBSETTING\n",
    "# ocean_percent=2/8\n",
    "\n",
    "# left_to_coast=data['xh'][0]+(data['xh'][-1]-data['xh'][0])*ocean_percent\n",
    "# where_coast_xh=np.where(data['xh']>=left_to_coast)[0][0]#-25\n",
    "# where_coast_xf=np.where(data['xf']>=left_to_coast)[0][0]#-25\n",
    "# end_xh=len(data['xh'])-1-50\n",
    "# end_xf=len(data['xf'])-1-50\n",
    "\n",
    "# print(f'x in {0}:{where_coast_xh-1} FOR SEA')\n",
    "# print(f'x in {where_coast_xh}:{end_xh} FOR LAND')\n",
    "# # t_end=78 \n",
    "# # if res=='250m':t_end=410\n",
    "# # print(f't in {0}:{t_end} (6.5 hours)')\n",
    "# t_start=36 \n",
    "# print(f't in {t_start}:end (8 hours)')\n",
    "\n",
    "# profile_array_e_g=profile_array_e_g[slice(0,78+1),:,:,slice(where_coast_xh,end_xh+1)]\n",
    "# profile_array_d_g=profile_array_d_g[slice(0,78+1),:,:,slice(where_coast_xh,end_xh+1)]\n",
    "# profile_array_e_c=profile_array_e_c[slice(0,78+1),:,:,slice(where_coast_xh,end_xh+1)]\n",
    "# profile_array_d_c=profile_array_d_c[slice(0,78+1),:,:,slice(where_coast_xh,end_xh+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba98016-f98a-48d7-9ab5-b14c354263df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#constants\n",
    "Cp=1004 #Jkg-1K-1\n",
    "Cv=717 #Jkg-1K-1\n",
    "Rd=Cp-Cv #Jkg-1K-1\n",
    "eps=0.608\n",
    "\n",
    "Lx=(data['xf'][-1].item()-data['xf'][0].item())*1000 #x length (m)\n",
    "Ly=(data['yf'][-1].item()-data['yf'][0].item())*1000 #y length (m)\n",
    "Np=len(parcel['xh']) #number of lagrangian parcles\n",
    "dt=(data['time'][1]-data['time'][0]).item()/1e9 #sec\n",
    "dx=(data['xf'][1].item()-data['xf'][0].item())*1e3 #meters\n",
    "dy=(data['yf'][1].item()-data['yf'][0].item())*1e3 #meters\n",
    "xs=data['xf'].values*1000\n",
    "ys=data['yf'].values*1000\n",
    "zs=data['zf'].values*1000\n",
    "\n",
    "def zf(z):\n",
    "    k=z #z is the # level of z\n",
    "    out=data['zf'].values[k]*1000\n",
    "    \n",
    "    return out\n",
    "# def rho(x,y,z,t):\n",
    "#     p=data['prs'].isel(xh=x,yh=y,zh=z,time=t).item()\n",
    "#     p0=101325 #Pa\n",
    "#     theta=data['th'].isel(xh=x,yh=y,zh=z,time=t).item()\n",
    "#     T=theta*(p/p0)**(Rd/Cp)\n",
    "#     qv=data['qv'].isel(xh=x,yh=y,zh=z,time=t).item()\n",
    "#     # Tv=T*(1+eps*qv)\n",
    "#     Tv=T*(eps+qv)/(eps*(1+qv))\n",
    "#     rho = p/(Rd*Tv)\n",
    "#     out=rho\n",
    "#     return out\n",
    "\n",
    "def rho(x,y,z,rho_data_t):\n",
    "    out=rho_data_t[z,y,x]\n",
    "    return out\n",
    "def m(t):\n",
    "    rho_data_t=data['rho'].isel(time=t).data\n",
    "    \n",
    "    m=0\n",
    "    #triple sum\n",
    "    for k in range(len(data['zh'])):\n",
    "        dz=(zf(k+1)-zf(k))\n",
    "        for j in range(len(data['yh'])):\n",
    "            for i in range(len(data['xh'])):\n",
    "                rho_out=rho(i,j,k,rho_data_t)\n",
    "                m+=rho_out*dz\n",
    "\n",
    "    #triple sum\n",
    "    out=m*dx*dy/Np\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447270cc-d34c-4aa5-865e-8ec68664628a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if plotting==True:\n",
    "    #Calculate Mass Constant\n",
    "    # calculate='single_time'\n",
    "    # calculate=True\n",
    "    calculate=False\n",
    "    \n",
    "    if calculate==True:\n",
    "        Nt=len(data['time'])\n",
    "        m_arr=np.zeros((Nt))\n",
    "        for t in np.arange(Nt):\n",
    "            if np.mod(t,25)==0: print(t)\n",
    "            m_arr[t]=m(t)\n",
    "        dir3=dir+f'Project_Algorithms/Entrainment/OUTPUT/'\n",
    "        np.save(dir3+f'Mass_Array_{res}_{t_res}_{Np_str}.npy', m_arr)\n",
    "    elif calculate=='single_time':\n",
    "        Nt=len(data['time'])\n",
    "        m_arr=np.zeros((Nt))\n",
    "    \n",
    "        t=0 #len(data['time'])//2 #Pick some middle time\n",
    "        m_300=m(t)\n",
    "        for t in np.arange(Nt):\n",
    "            m_arr[t]=m_300 #UNCOMMENT FOR FULL CALCULATION\n",
    "        dir3=dir+f'Project_Algorithms/Entrainment/OUTPUT/'\n",
    "        np.save(dir3+f'Mass_Array_{res}_{t_res}_{Np_str}.npy', m_arr)\n",
    "    else:\n",
    "        dir3=dir+f'Project_Algorithms/Entrainment/OUTPUT/'\n",
    "        m_arr = np.load(dir3+f'Mass_Array_{res}_{t_res}_{Np_str}.npy')\n",
    "    \n",
    "    # # TESTING\n",
    "    # lst=[]\n",
    "    # for t in np.arange(133):\n",
    "    #     lst.append(m_arr[t])\n",
    "    \n",
    "    # plt.plot(lst)\n",
    "    # (np.max(lst)-np.min(lst))*100/np.mean(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf09bd9-097b-4b94-bf87-7d1c6cb39a51",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # NONOPTIMIZED LOADING AND AVERAGING (NOT RECOMMENDED)\n",
    "\n",
    "# PROCESSING=False\n",
    "# PROCESSING=True\n",
    "\n",
    "# if PROCESSING==False:\n",
    "#     dir3=dir+f'Project_Algorithms/Entrainment/3D_entrainmentdetrainment_profiles_{res}_{t_res}_{Np_str}.h5'\n",
    "# if PROCESSING==True:\n",
    "#     dir3=dir+f'Project_Algorithms/Entrainment/3D_entrainmentdetrainment_profiles_PREPROCESSING_{res}_{t_res}_{Np_str}.h5'\n",
    "# with h5py.File(dir3, \"r\") as h5f:\n",
    "#     profile_array_e_g = h5f[\"profile_array_e_g\"][:]\n",
    "#     profile_array_e_c = h5f[\"profile_array_e_c\"][:]\n",
    "#     profile_array_d_g = h5f[\"profile_array_d_g\"][:]\n",
    "#     profile_array_d_c = h5f[\"profile_array_d_c\"][:]\n",
    "\n",
    "# def apply_constant(profile_array,apply):\n",
    "#     if apply==True:\n",
    "#         Nt=profile_array.shape[0]\n",
    "#         Nz=profile_array.shape[1]\n",
    "    \n",
    "#         profile_array/=(dx*dy*dt)\n",
    "#         for t in np.arange(Nt):\n",
    "#             profile_array[t]*=m_arr[t]\n",
    "#         for z in np.arange(Nz):\n",
    "#             dz=zf(z+1)-zf(z)\n",
    "#             profile_array[:,z]/=dz\n",
    "#     return profile_array\n",
    "\n",
    "# #APPLY CONSTANTS TO ENTRAINMENT VALUE\n",
    "# ##################################################\n",
    "# profile_array_e_g=apply_constant(profile_array_e_g,apply=True)\n",
    "# profile_array_e_c=apply_constant(profile_array_e_c,apply=True)\n",
    "# profile_array_d_g=-apply_constant(profile_array_d_g,apply=True)\n",
    "# profile_array_d_c=-apply_constant(profile_array_d_c,apply=True)\n",
    "# ##################################################\n",
    "\n",
    "# # type='general'\n",
    "# type='cloudy'\n",
    "\n",
    "# if type=='general':\n",
    "#     profile_array_e=profile_array_e_g\n",
    "#     profile_array_d=profile_array_d_g\n",
    "#     profile_array_net=profile_array_e-profile_array_d\n",
    "# if type=='cloudy':\n",
    "#     profile_array_e=profile_array_e_c\n",
    "#     profile_array_d=profile_array_d_c\n",
    "#     profile_array_net=profile_array_e-profile_array_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d60ee7-daa6-492f-94c6-2621caedf9bc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #OPTIMIZED LOADING AND AVERAGING\n",
    "# def apply_constant_tbyt(profile_array,t,apply):\n",
    "#     if apply==True:\n",
    "#         Nt=len(data['time'])\n",
    "#         Nz=len(data['zh'])\n",
    "    \n",
    "#         profile_array/=(dx*dy*dt)\n",
    "#         profile_array*=m_arr[t]\n",
    "#         for z in np.arange(Nz):\n",
    "#             dz=zf(z+1)-zf(z)\n",
    "#             profile_array[z]/=dz\n",
    "#     return profile_array\n",
    "\n",
    "\n",
    "# PROCESSING=False\n",
    "# PROCESSING=True\n",
    "\n",
    "# if PROCESSING==False:\n",
    "#     dir3=dir+f'Project_Algorithms/Entrainment/3D_entrainmentdetrainment_profiles_{res}_{t_res}_{Np_str}.h5'\n",
    "# if PROCESSING==True:\n",
    "#     dir3=dir+f'Project_Algorithms/Entrainment/3D_entrainmentdetrainment_profiles_PREPROCESSING_{res}_{t_res}_{Np_str}.h5'\n",
    "\n",
    "# def load_get_mean(e_string,d_string,type):\n",
    "#     Nt=len(data['time']); Nz=len(data['zh']); \n",
    "#     e_output_array = np.zeros((Nt, Nz))\n",
    "#     d_output_array = np.zeros((Nt, Nz))\n",
    "#     net_output_array = np.zeros((Nt, Nz))\n",
    "\n",
    "    \n",
    "#     with h5py.File(dir3, \"r\") as h5f:\n",
    "#         #Reading\n",
    "\n",
    "#         for t in np.arange(Nt):\n",
    "#             print(t)\n",
    "#             profile_array_e = h5f[e_string][t]\n",
    "#             profile_array_d = h5f[d_string][t]\n",
    "    \n",
    "#             #Applying Constants\n",
    "#             profile_array_e=apply_constant_tbyt(profile_array_e,t,apply=True)\n",
    "#             profile_array_d=-apply_constant_tbyt(profile_array_d,t,apply=True)\n",
    "    \n",
    "#             profile_array_net=profile_array_e-profile_array_d\n",
    "\n",
    "#             e_mean_yx=np.mean(profile_array_e, axis = (1,2))\n",
    "#             d_mean_yx=np.mean(profile_array_d, axis = (1,2))\n",
    "#             net_mean_yx=np.mean(profile_array_net, axis = (1,2))\n",
    "\n",
    "#             e_output_array[t]=e_mean_yx\n",
    "#             d_output_array[t]=d_mean_yx\n",
    "#             net_output_array[t]=net_mean_yx\n",
    "\n",
    "    \n",
    "#     return e_output_array, d_output_array, net_output_array\n",
    "\n",
    "# # #TESTING\n",
    "# # test=np.random.random((2,4,4,4))\n",
    "# # one=np.mean(test[0],axis=(1,2))\n",
    "# # two=np.mean(test[1],axis=(1,2))\n",
    "# # full=np.mean(test,axis=(2,3))\n",
    "# # print(full[0]==one)\n",
    "# # print(full[1]==two)\n",
    "\n",
    "# type='general'\n",
    "# type='cloudy'\n",
    "\n",
    "# if type=='general':\n",
    "#     e_string=\"profile_array_e_g\"\n",
    "#     d_string=\"profile_array_d_g\"\n",
    "#     [profile_array_e,profile_array_d,profile_array_net] = load_get_mean(e_string,d_string,type)\n",
    "    \n",
    "# if type=='cloudy':\n",
    "#     e_string=\"profile_array_e_c\"\n",
    "#     d_string=\"profile_array_d_c\"\n",
    "#     [profile_array_e,profile_array_d,profile_array_net] = load_get_mean(e_string,d_string,type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ac98ca-9fd8-4476-8577-3b4456b57a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESSING=False\n",
    "# PROCESSING=True\n",
    "\n",
    "if PROCESSING==False:\n",
    "    dir3=dir+f'Project_Algorithms/Entrainment/OUTPUT/3D_entrainmentdetrainment_combined_profiles_{res}_{t_res}_{Np_str}.h5'\n",
    "if PROCESSING==True:\n",
    "    dir3=dir+f'Project_Algorithms/Entrainment/OUTPUT/3D_entrainmentdetrainment_combined_profiles_PREPROCESSING_{res}_{t_res}_{Np_str}.h5'\n",
    "\n",
    "import dask\n",
    "import dask.array as da\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "# Open the dataset with chunking\n",
    "ds = xr.open_dataset(\n",
    "    dir3,\n",
    "    engine='h5netcdf',  # Use the correct engine based on the file type\n",
    "    phony_dims='sort',\n",
    "    chunks = {'phony_dim_0': 100,\n",
    "              'phony_dim_1': 34,\n",
    "              'phony_dim_2': 100,\n",
    "              'phony_dim_3': 64#128\n",
    "}\n",
    ")\n",
    "\n",
    "# Rename the dimensions\n",
    "ds = ds.rename({\n",
    "    'phony_dim_0': 't',   # Rename phony_dim_0 to 't'\n",
    "    'phony_dim_1': 'z',   # Rename phony_dim_1 to 'z'\n",
    "    'phony_dim_2': 'y',   # Rename phony_dim_2 to 'y'\n",
    "    'phony_dim_3': 'x'    # Rename phony_dim_3 to 'x'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a467069-14c8-490a-bfa2-b4d3b47f87a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EVEN MORE OPTIMIZED WITH DASK\n",
    "\n",
    "def apply_constant(profile_array, apply, dx, dy, dt, m_arr, dz):\n",
    "    if apply:\n",
    "        # Step 1: Divide by dx * dy * dt (scalar)\n",
    "        profile_array = profile_array / (dx * dy * dt)\n",
    "\n",
    "        # Step 2: Multiply by m_arr[t] — shape (Nt,) needs to broadcast to (Nt, Nz, Ny, Nx)\n",
    "        m_arr_broadcasted = da.asarray(m_arr)[:, None, None, None]  # Shape: (Nt, 1, 1, 1)\n",
    "        profile_array = profile_array * m_arr_broadcasted\n",
    "\n",
    "        # Step 3: Divide by dz[z] — zf of shape (Nz + 1,), so dz is (Nz,)\n",
    "        dz = da.asarray(dz)  # Shape: (Nz,)\n",
    "        dz_broadcasted = dz[None, :, None, None]  # Shape: (1, Nz, 1, 1)\n",
    "        profile_array = profile_array / dz_broadcasted\n",
    "\n",
    "    return profile_array\n",
    "\n",
    "profile_vars = ['c_to_g','g_to_c']\n",
    "tz_profiles = {}\n",
    "zf2=data['zf'].data*1000\n",
    "dz=zf2[1:]-zf2[:-1]\n",
    "\n",
    "with ProgressBar():\n",
    "    for var in profile_vars:\n",
    "        profile_array = ds[f'profile_array_{var}']\n",
    "        # Apply the same transformation to each variable\n",
    "        profile_array_updated = apply_constant(profile_array, apply=True, dx=dx, dy=dy, dt=dt, m_arr=m_arr, dz=dz)\n",
    "        # Compute the zx mean\n",
    "        tz_profile = profile_array_updated.mean(dim=('y', 'x'))\n",
    "        tz_profiles[f'tz_profile_array_{var}'] = tz_profile#.compute()\n",
    "\n",
    "    # Persist the results (keep them in memory across workers)\n",
    "    tz_profiles_persisted = {k: v.persist() for k, v in tz_profiles.items()}\n",
    " \n",
    "    # Compute all profiles at once to avoid individual .compute() calls\n",
    "    computed_profiles = dask.compute(*tz_profiles_persisted.values())\n",
    "\n",
    "    # Map the computed results back to the dictionary\n",
    "    tz_profiles = dict(zip(tz_profiles_persisted.keys(), computed_profiles))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5726895-2590-4046-99a7-d0e7714becd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVING\n",
    "dir3=dir2+f'Project_Algorithms/Entrainment/OUTPUT/Entrainment_tz_combined_profiles_{res}_{t_res}_{Np_str}.npz'\n",
    "np.savez(dir3, **tz_profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f1238d-887b-4d80-abdb-81a677a70bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6b5b31-4cf0-4572-a738-24e885cb634a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOADING\n",
    "dir3=dir2+f'Project_Algorithms/Entrainment/OUTPUT/Entrainment_tz_combined_profiles_{res}_{t_res}_{Np_str}.npz'\n",
    "tz_profiles=np.load(dir3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ed48d3-a224-4fbb-b4dc-7ff006c3d217",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "type1='general'\n",
    "type1='cloudy'\n",
    "tz_profile_array_c_to_g = tz_profiles['tz_profile_array_c_to_g'].copy()\n",
    "tz_profile_array_g_to_c = tz_profiles['tz_profile_array_g_to_c'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f9b235-8971-49de-af2f-bd3e81be7d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrainment\n",
    "\n",
    "#Plotting\n",
    "############################################################\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import numpy as np\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "gs = GridSpec(2, 2, figure=fig)\n",
    "\n",
    "######\n",
    "cmap1 = plt.cm.viridis\n",
    "cmap2 = plt.cm.seismic \n",
    "n_levels=29\n",
    "######\n",
    "\n",
    "######\n",
    "vmax_shared = np.max([np.max(tz_profile_array_c_to_g), np.max(tz_profile_array_g_to_c)])\n",
    "print(np.max([np.max(tz_profile_array_c_to_g), np.max(tz_profile_array_g_to_c)]))\n",
    "norm_shared = mcolors.Normalize(vmin=0, vmax=vmax_shared)\n",
    "######\n",
    "\n",
    "# First subplot: Entrainment\n",
    "########################################\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "contour1 = ax1.contourf(tz_profile_array_c_to_g.T, cmap=cmap1)\n",
    "# contour1 = ax1.contourf(profile_array_e.T, cmap=cmap1, norm=norm_shared, levels=n_levels)\n",
    "cbar1=fig.colorbar(contour1, ax=ax1)\n",
    "Nz = len(data['zh'])\n",
    "ax1.set_yticks(np.arange(Nz))\n",
    "new_ytick_labels = np.round(data['zf'].values[:Nz], 2)\n",
    "ax1.set_yticklabels(new_ytick_labels, fontsize=8, rotation=0)\n",
    "ax1.set_ylabel('z (km)');ax1.set_xlabel('t (timesteps)')\n",
    "ax1.set_title('Cloudy to General Entrainment')\n",
    "\n",
    "# Second subplot: Detrainment\n",
    "########################################\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "contour2 = ax2.contourf(tz_profile_array_g_to_c.T, cmap=cmap1)\n",
    "# contour2 = ax2.contourf(profile_array_d.T, cmap=cmap1, norm=norm_shared, levels=n_levels)\n",
    "cbar2 = fig.colorbar(contour2, ax=ax2)\n",
    "ax2.set_yticks(np.arange(Nz))\n",
    "new_ytick_labels = np.round(data['zf'].values[:Nz], 2)\n",
    "ax2.set_yticklabels(new_ytick_labels, fontsize=8, rotation=0)\n",
    "ax2.set_ylabel('z (km)');ax2.set_xlabel('t (timesteps)')\n",
    "ax2.set_title('General to Cloudy Entrainment')\n",
    "\n",
    "#FIXING SCIENTIFIC NOTATION\n",
    "\n",
    "def apply_scientific_notation_colorbar(cbars):\n",
    "    from matplotlib.ticker import ScalarFormatter\n",
    "    formatter = ScalarFormatter(useMathText=True)\n",
    "    formatter.set_powerlimits((-2, 2))  # Adjust the range for scientific notation\n",
    "    for cbar in cbars:  # These must be Colorbar instances\n",
    "        cbar.formatter = formatter\n",
    "        cbar.update_ticks()\n",
    "apply_scientific_notation_colorbar([cbar1,cbar2])\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "\n",
    "#TESTING\n",
    "print(f\"Max of profile_array_c_to_g: {np.max(tz_profile_array_c_to_g)}\")\n",
    "print(f\"Max of profile_array_g_to_c: {np.max(tz_profile_array_g_to_c)}\")\n",
    "\n",
    "###################### FIXING Y TICKS\n",
    "Nz = len(data['zh'])\n",
    "step = 4  # change to 2, 5, etc. depending on how spaced you want them\n",
    "ytick_pos = np.arange(0, Nz, step)\n",
    "ytick_labels = np.round(data['zf'].values[ytick_pos], 2)\n",
    "for axis in [ax1,ax2]:#,ax3]:\n",
    "    axis.set_yticks(ytick_pos)\n",
    "    axis.set_yticklabels(ytick_labels, fontsize=8, rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c2eff4-9d3c-43f4-a756-69dd1bbc6c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "import numpy as np\n",
    "\n",
    "if plotting == True:\n",
    "    c_to_g = np.mean(tz_profile_array_c_to_g, axis=0)\n",
    "    g_to_c = np.mean(tz_profile_array_g_to_c, axis=0)\n",
    "\n",
    "    # Create a 2-row layout: top row with 2 plots, bottom row with 1 plot\n",
    "    fig = plt.figure(figsize=(12, 10))\n",
    "    gs = fig.add_gridspec(2, 2, height_ratios=[1, 1])\n",
    "\n",
    "    ax1 = fig.add_subplot(gs[0, 0])  # Cloudy to General\n",
    "    ax2 = fig.add_subplot(gs[0, 1])  # General to Cloudy\n",
    "    ax3 = fig.add_subplot(gs[1, 0])  # Difference plot spans both columns\n",
    "\n",
    "    # First subplot: cloudy to general\n",
    "    ax1.plot(c_to_g, data['zh'], color='blue', label='cloudy to general')\n",
    "    ax1.axvline(0, color='black')\n",
    "    ax1.set_title('Cloudy to General')\n",
    "    ax1.set_ylabel('Height (m)')\n",
    "    ax1.legend()\n",
    "    ax1.xaxis.set_major_formatter(ScalarFormatter(useMathText=True, useOffset=False))\n",
    "    ax1.xaxis.get_major_formatter().set_scientific(True)\n",
    "    ax1.xaxis.get_major_formatter().set_powerlimits((-1, 1))\n",
    "\n",
    "    # Second subplot: general to cloudy\n",
    "    ax2.plot(g_to_c, data['zh'], color='red', label='general to cloudy')\n",
    "    ax2.axvline(0, color='black')\n",
    "    ax2.set_title('General to Cloudy')\n",
    "    ax2.legend()\n",
    "    ax2.xaxis.set_major_formatter(ScalarFormatter(useMathText=True, useOffset=False))\n",
    "    ax2.xaxis.get_major_formatter().set_scientific(True)\n",
    "    ax2.xaxis.get_major_formatter().set_powerlimits((-1, 1))\n",
    "\n",
    "    # Third subplot: difference\n",
    "    ax3.plot(c_to_g - g_to_c, data['zh'], label='c→g minus g→c', color='green')\n",
    "    ax3.axvline(0, color='black')\n",
    "    ax3.axhline(1.24, color='purple', linestyle='dashed', label='avg cloud base')\n",
    "    ax3.set_title('Difference: Cloudy→General minus General→Cloudy')\n",
    "    ax3.set_ylabel('Height (m)')\n",
    "    ax3.legend()\n",
    "    ax3.xaxis.set_major_formatter(ScalarFormatter(useMathText=True, useOffset=False))\n",
    "    ax3.xaxis.get_major_formatter().set_scientific(True)\n",
    "    ax3.xaxis.get_major_formatter().set_powerlimits((-1, 1))\n",
    "\n",
    "    fig.suptitle('2D Entrainment Transfer Analysis')\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f434e648-3b27-435e-a352-12d6dcac33fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b21b73-3fbf-467f-a4e9-583c028ac74a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c252ac16-afd2-417b-98fd-d28d0997c648",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9d54f4-c29b-461e-b59d-d68957ed7592",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abf7435-6b54-477b-b49e-2230a8476f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "#Z-X Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ce4b54-15bc-46fd-a6e0-2d9a4ea53834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import dask.array as da\n",
    "\n",
    "def apply_constant(profile_array, apply, dx, dy, dt, m_arr, dz):\n",
    "    if apply:\n",
    "        # Step 1: Divide by dx * dy * dt (scalar)\n",
    "        profile_array = profile_array / (dx * dy * dt)\n",
    "\n",
    "        # Step 2: Multiply by m_arr[t] — shape (Nt,) needs to broadcast to (Nt, Nz, Ny, Nx)\n",
    "        m_arr_broadcasted = da.asarray(m_arr)[:, None, None, None]  # Shape: (Nt, 1, 1, 1)\n",
    "        profile_array = profile_array * m_arr_broadcasted\n",
    "\n",
    "        # Step 3: Divide by dz[z] — zf of shape (Nz + 1,), so dz is (Nz,)\n",
    "        dz = da.asarray(dz)  # Shape: (Nz,)\n",
    "        dz_broadcasted = dz[None, :, None, None]  # Shape: (1, Nz, 1, 1)\n",
    "        profile_array = profile_array / dz_broadcasted\n",
    "\n",
    "    return profile_array\n",
    "\n",
    "profile_vars = ['c_to_g','g_to_c']\n",
    "zx_profiles = {}\n",
    "zf2=data['zf'].data*1000\n",
    "dz=zf2[1:]-zf2[:-1]\n",
    "\n",
    "with ProgressBar():\n",
    "    for var in profile_vars:\n",
    "        profile_array = ds[f'profile_array_{var}']\n",
    "        # Apply the same transformation to each variable\n",
    "        profile_array_updated = apply_constant(profile_array, apply=True, dx=dx, dy=dy, dt=dt, m_arr=m_arr, dz=dz)\n",
    "        # Compute the zx mean\n",
    "        zx_profile = profile_array_updated.mean(dim=('t', 'y'))\n",
    "        zx_profiles[f'zx_profile_array_{var}'] = zx_profile#.compute()\n",
    "\n",
    "    # Persist the results (keep them in memory across workers)\n",
    "    zx_profiles_persisted = {k: v.persist() for k, v in zx_profiles.items()}\n",
    " \n",
    "    # Compute all profiles at once to avoid individual .compute() calls\n",
    "    computed_profiles = dask.compute(*zx_profiles_persisted.values())\n",
    "\n",
    "    # Map the computed results back to the dictionary\n",
    "    tz_profiles = dict(zip(zx_profiles_persisted.keys(), computed_profiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2942e84a-a8f8-4edc-b8eb-18d4bfd64356",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVING\n",
    "dir3=dir2+f'Project_Algorithms/Entrainment/Entrainment_zx_combined_profiles_{res}_{t_res}_{Np_str}.npz'\n",
    "np.savez(dir3, **tz_profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cc22c4-66af-4ce5-9ede-3d03bbf3845f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8c68b0-654f-48e6-834f-75cabab300bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOADING\n",
    "dir3=dir2+f'Project_Algorithms/Entrainment/Entrainment_zx_combined_profiles_{res}_{t_res}_{Np_str}.npz'\n",
    "zx_profiles=np.load(dir3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ad482f-c253-47de-90dd-c25ef5317721",
   "metadata": {},
   "outputs": [],
   "source": [
    "type1='general'\n",
    "type1='cloudy'\n",
    "zx_profile_array_c_to_g = tz_profiles['zx_profile_array_c_to_g'].copy()\n",
    "zx_profile_array_g_to_c = tz_profiles['zx_profile_array_g_to_c'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10364e8-cfe9-4c4a-a034-ac56d3b39dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrainment\n",
    "\n",
    "#Plotting\n",
    "############################################################\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import numpy as np\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "gs = GridSpec(2, 2, figure=fig)\n",
    "\n",
    "######\n",
    "cmap1 = plt.cm.viridis\n",
    "cmap2 = plt.cm.seismic \n",
    "n_levels=29\n",
    "######\n",
    "\n",
    "######\n",
    "vmax_shared = np.max([np.max(zx_profile_array_c_to_g), np.max(zx_profile_array_g_to_c)])\n",
    "print(np.max([np.max(zx_profile_array_c_to_g), np.max(zx_profile_array_g_to_c)]))\n",
    "norm_shared = mcolors.Normalize(vmin=0, vmax=vmax_shared)\n",
    "######\n",
    "\n",
    "# First subplot: Entrainment\n",
    "########################################\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "# contour1 = ax1.contourf(profile_array_e.T, cmap=cmap1)\n",
    "contour1 = ax1.contourf(zx_profile_array_c_to_g, cmap=cmap1, norm=norm_shared, levels=n_levels)\n",
    "cbar1=fig.colorbar(contour1, ax=ax1)\n",
    "Nz = len(data['zh'])\n",
    "ax1.set_yticks(np.arange(Nz))\n",
    "new_ytick_labels = np.round(data['zf'].values[:Nz], 2)\n",
    "ax1.set_yticklabels(new_ytick_labels, fontsize=8, rotation=0)\n",
    "ax1.set_ylabel('z (km)');ax1.set_xlabel('x (km)')\n",
    "ax1.set_title('Entrainment using Lagrangian Binary Array',fontsize=8)\n",
    "\n",
    "# Second subplot: Detrainment\n",
    "########################################\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "# contour2 = ax2.contourf(profile_array_d.T, cmap=cmap1)\n",
    "contour2 = ax2.contourf(zx_profile_array_g_to_c, cmap=cmap1, norm=norm_shared, levels=n_levels)\n",
    "cbar2 = fig.colorbar(contour2, ax=ax2)\n",
    "ax2.set_yticks(np.arange(Nz))\n",
    "new_ytick_labels = np.round(data['zf'].values[:Nz], 2)\n",
    "ax2.set_yticklabels(new_ytick_labels, fontsize=8, rotation=0)\n",
    "ax2.set_ylabel('z (km)');ax2.set_xlabel('x (km)')\n",
    "ax2.set_title('Detrainment')\n",
    "\n",
    "#FIXING YTICKS\n",
    "ax3.set_yticks(np.arange(Nz))\n",
    "new_ytick_labels = np.round(data['zf'].values[:Nz], 2)\n",
    "ax3.set_yticklabels(new_ytick_labels, fontsize=8, rotation=0)\n",
    "ax3.set_ylabel('z (km)');ax3.set_xlabel('x (km)')\n",
    "ax3.set_title('Entrainment - Detrainment')\n",
    "\n",
    "#FIXING XTICKS\n",
    "fix_tick_labels([ax1,ax2,ax3], data, data_dim='x', tick_axis='x', d_xtick=85, d_ytick=20, cell_loc='center',round=1,meters=False) \n",
    "\n",
    "\n",
    "#FIXING SCIENTIFIC NOTATION\n",
    "\n",
    "def apply_scientific_notation_colorbar(cbars):\n",
    "    from matplotlib.ticker import ScalarFormatter\n",
    "    formatter = ScalarFormatter(useMathText=True)\n",
    "    formatter.set_powerlimits((-2, 2))  # Adjust the range for scientific notation\n",
    "    for cbar in cbars:  # These must be Colorbar instances\n",
    "        cbar.formatter = formatter\n",
    "        cbar.update_ticks()\n",
    "apply_scientific_notation_colorbar([cbar1,cbar2])\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "work"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
