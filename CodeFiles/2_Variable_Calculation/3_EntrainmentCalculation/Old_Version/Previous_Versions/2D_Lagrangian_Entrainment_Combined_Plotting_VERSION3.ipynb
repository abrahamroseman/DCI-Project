{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3411e523-2126-4767-aae1-fbef4b65f0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading in Packages and Data\n",
    "\n",
    "#Importing Packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "import matplotlib.gridspec as gridspec\n",
    "import xarray as xr\n",
    "import os; import time\n",
    "import pickle\n",
    "import h5py\n",
    "###############################################################\n",
    "def coefs(coefficients,degree):\n",
    "    coef=coefficients\n",
    "    coefs=\"\"\n",
    "    for n in range(degree, -1, -1):\n",
    "        string=f\"({coefficients[len(coef)-(n+1)]:.1e})\"\n",
    "        coefs+=string + f\"x^{n}\"\n",
    "        if n != 0:\n",
    "            coefs+=\" + \"\n",
    "    return coefs\n",
    "###############################################################\n",
    "\n",
    "# Importing Model Data\n",
    "check=False\n",
    "dir='/mnt/lustre/koa/koastore/torri_group/air_directory/DCI-Project/'\n",
    "\n",
    "# dx = 1 km; Np = 1M; Nt = 5 min\n",
    "data=xr.open_dataset(dir+'../cm1r20.3/run/cm1out_1km_5min.nc', decode_timedelta=True) #***\n",
    "parcel=xr.open_dataset(dir+'../cm1r20.3/run/cm1out_pdata_1km_5min_1e6.nc', decode_timedelta=True) #***\n",
    "res='1km';t_res='5min'\n",
    "Np_str='1e6'\n",
    "\n",
    "# # dx = 1km; Np = 50M\n",
    "# #Importing Model Data\n",
    "# dir2='/home/air673/koa_scratch/'\n",
    "# data=xr.open_dataset(dir2+'cm1out_1km_1min.nc', decode_timedelta=True) #***\n",
    "# parcel=xr.open_dataset(dir2+'cm1out_pdata_1km_1min_50M.nc', decode_timedelta=True) #***\n",
    "# res='1km'; t_res='1min'; Np_str='50e6'\n",
    "\n",
    "# # dx = 1km; Np = 50M; Nz = 95\n",
    "# #Importing Model Data\n",
    "# dir2='/home/air673/koa_scratch/'\n",
    "# data=xr.open_dataset(dir2+'cm1out_1km_1min_95nz.nc', decode_timedelta=True) #***\n",
    "# parcel=xr.open_dataset(dir2+'cm1out_pdata_1km_1min_95nz.nc', decode_timedelta=True) #***\n",
    "# res='1km'; t_res='1min_95nz'; Np_str='50e6'\n",
    "\n",
    "# # dx = 250m; Np = 50M\n",
    "# #Importing Model Data\n",
    "# dir2='/home/air673/koa_scratch/'\n",
    "# data=xr.open_dataset(dir2+'cm1out_250m_1min_50M.nc', decode_timedelta=True) #***\n",
    "# parcel=xr.open_dataset(dir2+'cm1out_pdata_250m_1min_50M.nc', decode_timedelta=True) #***\n",
    "# res='250m'; t_res='1min'; Np_str='50e6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3133df4-2cfe-42bc-9df1-42577c476900",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "dir2='/mnt/lustre/koa/koastore/torri_group/air_directory/DCI-Project/'\n",
    "path=dir2+'../Functions/'\n",
    "sys.path.append(path)\n",
    "\n",
    "import NumericalFunctions\n",
    "from NumericalFunctions import * # import NumericalFunctions \n",
    "import PlottingFunctions\n",
    "from PlottingFunctions import * # import PlottingFunctions\n",
    "\n",
    "# # Get all functions in NumericalFunctions\n",
    "# import inspect\n",
    "# functions = [f[0] for f in inspect.getmembers(NumericalFunctions, inspect.isfunction)]\n",
    "# functions\n",
    "\n",
    "#####\n",
    "\n",
    "#Import StatisticalFunctions \n",
    "import sys\n",
    "dir2='/mnt/lustre/koa/koastore/torri_group/air_directory/DCI-Project/'\n",
    "path=dir2+'../Functions/'\n",
    "sys.path.append(path)\n",
    "\n",
    "import StatisticalFunctions\n",
    "from StatisticalFunctions import * # import NumericalFunctions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad276cc-dc75-47db-be8e-c92f3dacd076",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "#PLOTTING\n",
    "plotting=False #KEEP FALSE IF JOB ARRAY IS RUNNING\n",
    "plotting=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc60185c-414b-45da-b033-00a3b81a300d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#READING BACK IN\n",
    "# import pickle\n",
    "# dir2 = dir + f'Project_Algorithms/Domain_Profiles/'\n",
    "# input_file = dir2 + f'mean_lfc_{res}_{t_res}_{Np_str}.pkl'\n",
    "\n",
    "# with open(input_file, 'rb') as f:\n",
    "#     mean_LFC = pickle.load(f)\n",
    "# print(mean_LFC)\n",
    "\n",
    "def LoadMeanLFC():\n",
    "    dir2 = dir + f'Project_Algorithms/Tracking_Algorithms/OUTPUT/'\n",
    "    in_file = dir2 + f\"MeanLFC_{res}_{t_res}_{Np_str}.pkl\"\n",
    "    with open(in_file, 'rb') as f:\n",
    "        MeanLFC = pickle.load(f)\n",
    "    return MeanLFC\n",
    "MeanLFC=LoadMeanLFC()\n",
    "print(f\"Mean LFC is: {MeanLFC}\\n\")\n",
    "\n",
    "\n",
    "def LoadAllCloudBase():\n",
    "    dir2 = dir + f'Project_Algorithms/Tracking_Algorithms/OUTPUT/'\n",
    "    in_file = dir2 + f\"all_cloudbase_{res}_{t_res}_{Np_str}.pkl\"\n",
    "    with open(in_file, 'rb') as f:\n",
    "        all_cloudbase = pickle.load(f)\n",
    "    return(all_cloudbase)\n",
    "min_all_cloudbase=np.nanmin(LoadAllCloudBase())\n",
    "cloudbase=min_all_cloudbase\n",
    "print(f\"Minimum Cloudbase is: {cloudbase}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fc1167-2e2f-4996-ad32-7a0f4bbbcba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if plotting==True:\n",
    "    #constants\n",
    "    Cp=1004 #Jkg-1K-1\n",
    "    Cv=717 #Jkg-1K-1\n",
    "    Rd=Cp-Cv #Jkg-1K-1\n",
    "    eps=0.608\n",
    "    \n",
    "    Lx=(data['xf'][-1].item()-data['xf'][0].item())*1000 #x length (m)\n",
    "    Ly=(data['yf'][-1].item()-data['yf'][0].item())*1000 #y length (m)\n",
    "    Np=len(parcel['xh']) #number of lagrangian parcles\n",
    "    dt=(data['time'][1]-data['time'][0]).item()/1e9 #sec\n",
    "    dx=(data['xf'][1].item()-data['xf'][0].item())*1e3 #meters\n",
    "    dy=(data['yf'][1].item()-data['yf'][0].item())*1e3 #meters\n",
    "    xs=data['xf'].values*1000\n",
    "    ys=data['yf'].values*1000\n",
    "    zs=data['zf'].values*1000\n",
    "    \n",
    "    def zf(z):\n",
    "        k=z #z is the # level of z\n",
    "        out=data['zf'].values[k]*1000\n",
    "        \n",
    "        return out\n",
    "    # def rho(x,y,z,t):\n",
    "    #     p=data['prs'].isel(xh=x,yh=y,zh=z,time=t).item()\n",
    "    #     p0=101325 #Pa\n",
    "    #     theta=data['th'].isel(xh=x,yh=y,zh=z,time=t).item()\n",
    "    #     T=theta*(p/p0)**(Rd/Cp)\n",
    "    #     qv=data['qv'].isel(xh=x,yh=y,zh=z,time=t).item()\n",
    "    #     # Tv=T*(1+eps*qv)\n",
    "    #     Tv=T*(eps+qv)/(eps*(1+qv))\n",
    "    #     rho = p/(Rd*Tv)\n",
    "    #     out=rho\n",
    "    #     return out\n",
    "    \n",
    "    def rho(x,y,z,rho_data_t):\n",
    "        out=rho_data_t[z,y,x]\n",
    "        return out\n",
    "    def m(t):\n",
    "        rho_data_t=data['rho'].isel(time=t).data\n",
    "        \n",
    "        m=0\n",
    "        #triple sum\n",
    "        for k in range(len(data['zh'])):\n",
    "            dz=(zf(k+1)-zf(k))\n",
    "            for j in range(len(data['yh'])):\n",
    "                for i in range(len(data['xh'])):\n",
    "                    rho_out=rho(i,j,k,rho_data_t)\n",
    "                    m+=rho_out*dz\n",
    "                    \n",
    "        #triple sum\n",
    "        out=m*dx*dy/Np\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a628b441-cb34-4625-98ea-756399604ffd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#SOME CALCULATIONS (TESTING)\n",
    "# # (Lx*Ly*(10**4))/1e6 #1M parcels ==> 1 billion kg/parcel\n",
    "# # (Lx*Ly*(10**4))/50e6 #50M parcels ==> 20 million kg/parcel\n",
    "# # (Lx*Ly*(10**4))/100e6 #100M parcels ==> 10 million kg/parcel\n",
    "\n",
    "# # 1e5 kg | 9.1125 e4 m^3\n",
    "# # x   kg | 1000*1000*62 = 6.2e7 m^3\n",
    "# (1000*1000*62)*(1e5/(9.1125e4))# ==> 68038408 ==> should have 68M kg in the bottom most layer \n",
    "\n",
    "# 68038408/19729158# (expected/calculated mass) ==> should have 3.5 parcels in each grid box on the bottom most layer\n",
    "# #we have 369e3 parcels on bottom layer ==> 369e3/(Nx*Ny) = 369e3/102400 = 3.6 parcels per layer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b876564-f013-44c3-918e-525b263f414d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if plotting==True:\n",
    "    #Calculate Mass Constant\n",
    "    # calculate='single_time'\n",
    "    # calculate=True\n",
    "    calculate=False\n",
    "    \n",
    "    if calculate==True:\n",
    "        Nt=len(data['time'])\n",
    "        m_arr=np.zeros((Nt))\n",
    "        for t in np.arange(Nt):\n",
    "            if np.mod(t,25)==0: print(t)\n",
    "            m_arr[t]=m(t)\n",
    "        dir3=dir+f'Project_Algorithms/Entrainment/OUTPUT/'\n",
    "        np.save(dir3+f'Mass_Array_{res}_{t_res}_{Np_str}.npy', m_arr)\n",
    "    elif calculate=='single_time':\n",
    "        Nt=len(data['time'])\n",
    "        m_arr=np.zeros((Nt))\n",
    "    \n",
    "        t=0 #len(data['time'])//2 #Pick some middle time\n",
    "        m_300=m(t)\n",
    "        for t in np.arange(Nt):\n",
    "            m_arr[t]=m_300 #UNCOMMENT FOR FULL CALCULATION\n",
    "        dir3=dir+f'Project_Algorithms/Entrainment/OUTPUT/'\n",
    "        np.save(dir3+f'Mass_Array_{res}_{t_res}_{Np_str}.npy', m_arr)\n",
    "    else:\n",
    "        dir3=dir+f'Project_Algorithms/Entrainment/OUTPUT/'\n",
    "        m_arr = np.load(dir3+f'Mass_Array_{res}_{t_res}_{Np_str}.npy')\n",
    "    \n",
    "    # # TESTING\n",
    "    # lst=[]\n",
    "    # for t in np.arange(133):\n",
    "    #     lst.append(m_arr[t])\n",
    "    \n",
    "    # plt.plot(lst)\n",
    "    # (np.max(lst)-np.min(lst))*100/np.mean(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be859db5-6d0c-41de-b16a-18534f0da7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if plotting==True:\n",
    "    PROCESSING=False\n",
    "    PROCESSING=True\n",
    "    \n",
    "    dir3=dir+'Project_Algorithms/Entrainment/OUTPUT/'\n",
    "    if PROCESSING==False:\n",
    "        open_file=dir3+f'2D_entrainmentdetrainment_combined_profiles_{res}_{t_res}_{Np_str}.h5'\n",
    "    if PROCESSING==True:\n",
    "        open_file=dir3+f'2D_entrainmentdetrainment_combined_profiles_PREPROCESSING_{res}_{t_res}_{Np_str}.h5'\n",
    "    with h5py.File(open_file, \"r\") as h5f:\n",
    "        profile_array_c_to_g = h5f[\"profile_array_c_to_g\"][:]\n",
    "        profile_array_g_to_c = h5f[\"profile_array_g_to_c\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c287244-909e-4da7-92e5-17e9875b7acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if plotting==True:\n",
    "    def apply_constant(profile_array,apply):\n",
    "        if apply==True:\n",
    "            Nt=profile_array.shape[0]\n",
    "            Nz=profile_array.shape[1]\n",
    "        \n",
    "            profile_array/=(Lx*Ly*dt)\n",
    "            for t in np.arange(Nt):\n",
    "                profile_array[t]*=m_arr[t]\n",
    "            for z in np.arange(Nz):\n",
    "                dz=zf(z+1)-zf(z)\n",
    "                profile_array[:,z]/=dz\n",
    "        return profile_array\n",
    "    #APPLY CONSTANTS TO ENTRAINMENT VALUE\n",
    "    ##################################################\n",
    "    profile_array_c_to_g=apply_constant(profile_array_c_to_g,apply=True)\n",
    "    profile_array_g_to_c=apply_constant(profile_array_g_to_c,apply=True)\n",
    "    ##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2489adc0-6370-44e2-aeae-e0914fbee596",
   "metadata": {},
   "outputs": [],
   "source": [
    "if plotting==True:\n",
    "    #Plotting\n",
    "    ############################################################\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib.gridspec import GridSpec\n",
    "    import numpy as np\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    gs = GridSpec(2, 2, figure=fig)\n",
    "    \n",
    "    ######\n",
    "    cmap1 = plt.cm.viridis\n",
    "    cmap1 = plt.cm.seismic \n",
    "    n_levels=30\n",
    "    ######\n",
    "    \n",
    "    ######\n",
    "    vmax_shared = np.max([np.max(profile_array_c_to_g), np.max(profile_array_g_to_c)])\n",
    "    norm_shared = mcolors.Normalize(vmin=0, vmax=vmax_shared)\n",
    "    ######\n",
    "    \n",
    "    # First subplot: Entrainment\n",
    "    ########################################\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    contour1 = ax1.contourf(profile_array_c_to_g.T, cmap=cmap1,levels=n_levels)\n",
    "    # contour1 = ax1.contourf(profile_array_e_g.T, cmap=cmap1, norm=norm_shared, levels=n_levels)\n",
    "    cbar1=fig.colorbar(contour1, ax=ax1)\n",
    "    Nz = len(data['zh'])\n",
    "    ax1.set_yticks(np.arange(Nz))\n",
    "    new_ytick_labels = np.round(data['zf'].values[:Nz], 2)\n",
    "    ax1.set_yticklabels(new_ytick_labels, fontsize=8, rotation=0)\n",
    "    ax1.set_ylabel('z (km)');ax1.set_xlabel('t (timesteps)')\n",
    "    ax1.set_title('Cloudy to General')\n",
    "    \n",
    "    # Second subplot: Detrainment\n",
    "    ########################################\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    contour2 = ax2.contourf(profile_array_g_to_c.T, cmap=cmap1, levels=n_levels)\n",
    "    # contour2 = ax2.contourf(profile_array_e_c.T, cmap=cmap1, norm=norm_shared, levels=n_levels)\n",
    "    cbar2 = fig.colorbar(contour2, ax=ax2)\n",
    "    ax2.set_yticks(np.arange(Nz))\n",
    "    new_ytick_labels = np.round(data['zf'].values[:Nz], 2)\n",
    "    ax2.set_yticklabels(new_ytick_labels, fontsize=8, rotation=0)\n",
    "    ax2.set_ylabel('z (km)');ax2.set_xlabel('t (timesteps)')\n",
    "    ax2.set_title('General to Cloudy')\n",
    "\n",
    "    ###################### FIXING Y TICKS\n",
    "    Nz = len(data['zh'])\n",
    "    step = 4  # change to 2, 5, etc. depending on how spaced you want them\n",
    "    ytick_pos = np.arange(0, Nz, step)\n",
    "    ytick_labels = np.round(data['zf'].values[ytick_pos], 2)\n",
    "    for axis in [ax1,ax2]:\n",
    "        axis.set_yticks(ytick_pos)\n",
    "        axis.set_yticklabels(ytick_labels, fontsize=8, rotation=0)\n",
    "\n",
    "    ###################### SCIENTIFIC NOTATION\n",
    "    apply_scientific_notation_colorbar([cbar1,cbar2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666061ac-55e6-43d2-8849-c32a47684aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "import numpy as np\n",
    "\n",
    "if plotting == True:\n",
    "    c_to_g = np.mean(profile_array_c_to_g, axis=0)\n",
    "    g_to_c = np.mean(profile_array_g_to_c, axis=0)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 5))  # Single axis\n",
    "\n",
    "    # Plot both transfers\n",
    "    ax.plot(c_to_g, data['zh'], color='blue', label='Cloudy → General')\n",
    "    ax.plot(g_to_c, data['zh'], color='red', label='General → Cloudy')\n",
    "    ax.axvline(0, color='black', linewidth=1)\n",
    "\n",
    "    # Reference lines\n",
    "    ax.axhline(cloudbase, color='purple', linestyle='dashed')\n",
    "    ax.axhline(MeanLFC / 1000, color='green', linestyle='dashed')\n",
    "\n",
    "    # Labeling and formatting\n",
    "    ax.set_title('Entrainemnt Rate Transfer: Cloudy ↔ General')\n",
    "    ax.set_xlabel('Mass Transfer Rate')\n",
    "    ax.set_ylabel('Height (m)')\n",
    "    ax.legend()\n",
    "\n",
    "    formatter = ScalarFormatter(useMathText=True, useOffset=False)\n",
    "    formatter.set_scientific(True)\n",
    "    formatter.set_powerlimits((-1, 1))\n",
    "    ax.xaxis.set_major_formatter(formatter)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f114ee-e086-48c0-b6a4-da018c4a6e6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c029d0-9c54-4b41-914b-a8d1c62ea5f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "work"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
