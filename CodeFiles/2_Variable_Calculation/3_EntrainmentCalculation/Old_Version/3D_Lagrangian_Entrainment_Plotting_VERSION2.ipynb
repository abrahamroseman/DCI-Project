{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db6b85b-2c5f-4818-9147-e225704d14e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.lines import Line2D\n",
    "import xarray as xr\n",
    "import os; import time\n",
    "import pickle\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d744b1-49f5-4d29-a178-094a90affbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAIN DIRECTORIES\n",
    "mainDirectory='/mnt/lustre/koa/koastore/torri_group/air_directory/Projects/DCI-Project/'\n",
    "scratchDirectory='/home/air673/koa_scratch/'\n",
    "codeDirectory='/mnt/lustre/koa/koastore/torri_group/air_directory/Projects/DCI-Project/Project_Algorithms/Entrainment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1817a00-adf2-49f1-ae11-7281cbbd3ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOADING DATA\n",
    "def GetDataDirectories(simulationNumber):\n",
    "    if simulationNumber == 1:\n",
    "        Directory=os.path.join(mainDirectory,'Model/cm1r20.3/run')\n",
    "        res='1km'; t_res='5min'; Np_str='1e6'; Nz_str='34'\n",
    "    elif simulationNumber == 2:\n",
    "        Directory=scratchDirectory\n",
    "        res='1km'; t_res='1min'; Np_str='50e6'; Nz_str='95'\n",
    "    elif simulationNumber == 3:\n",
    "        Directory=scratchDirectory\n",
    "        res='250m'; t_res='1min'; Np_str='50e6'; Nz_str='95'\n",
    "        \n",
    "    dataDirectory = os.path.join(Directory, f\"cm1out_{res}_{t_res}_{Nz_str}nz.nc\")\n",
    "    parcelDirectory = os.path.join(Directory,f\"cm1out_pdata_{res}_{t_res}_{Np_str}np.nc\")\n",
    "    return dataDirectory, parcelDirectory, res,t_res,Np_str,Nz_str\n",
    "    \n",
    "def GetData(dataDirectory, parcelDirectory):\n",
    "    dataNC = xr.open_dataset(dataDirectory, decode_timedelta=True) \n",
    "    parcelNC = xr.open_dataset(parcelDirectory, decode_timedelta=True) \n",
    "    return dataNC,parcelNC\n",
    "\n",
    "def SubsetDataVars(dataNC):\n",
    "    varList = [\"thflux\", \"qvflux\", \"tsk\", \"cape\", \n",
    "               \"cin\", \"lcl\", \"lfc\", \"th\",\n",
    "               \"prs\", \"rho\", \"qv\", \"qc\",\n",
    "               \"qr\", \"qi\", \"qs\",\"qg\", \n",
    "               \"buoyancy\", \"uinterp\", \"vinterp\", \"winterp\",]\n",
    "    \n",
    "    varList += [\"ptb_hadv\", \"ptb_vadv\", \"ptb_hidiff\", \"ptb_vidiff\",\n",
    "                \"ptb_hturb\", \"ptb_vturb\", \"ptb_mp\", \"ptb_rdamp\", \n",
    "                \"ptb_rad\", \"ptb_div\", \"ptb_diss\",]\n",
    "    \n",
    "    varList += [\"qvb_hadv\", \"qvb_vadv\", \"qvb_hidiff\", \"qvb_vidiff\", \n",
    "                \"qvb_hturb\", \"qvb_vturb\", \"qvb_mp\",]\n",
    "    \n",
    "    varList += [\"wb_hadv\", \"wb_vadv\", \"wb_hidiff\", \"wb_vidiff\",\n",
    "                \"wb_hturb\", \"wb_vturb\", \"wb_pgrad\", \"wb_rdamp\", \"wb_buoy\",]\n",
    "\n",
    "    return dataNC[varList]\n",
    "\n",
    "[dataDirectory,parcelDirectory, res,t_res,Np_str,Nz_str] = GetDataDirectories(simulationNumber=1)\n",
    "[data,parcel] = GetData(dataDirectory, parcelDirectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a4191d-f3a6-492f-b6e6-00aa0a6bbbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir='/mnt/lustre/koa/koastore/torri_group/air_directory/Projects/DCI-Project/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7454ff55-7c85-40ac-a63c-0b7ee4376dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cf6491-bad5-4a6e-851a-7db2ec18da64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "dir2='/mnt/lustre/koa/koastore/torri_group/air_directory/DCI-Project/'\n",
    "path=dir2+'../Functions/'\n",
    "sys.path.append(path)\n",
    "\n",
    "import NumericalFunctions\n",
    "from NumericalFunctions import * # import NumericalFunctions \n",
    "import PlottingFunctions\n",
    "from PlottingFunctions import * # import PlottingFunctions\n",
    "\n",
    "\n",
    "# # Get all functions in NumericalFunctions\n",
    "# import inspect\n",
    "# functions = [f[0] for f in inspect.getmembers(NumericalFunctions, inspect.isfunction)]\n",
    "# functions\n",
    "\n",
    "# # Get all functions in NumericalFunctions\n",
    "# import inspect\n",
    "# functions = [f[0] for f in inspect.getmembers(PlottingFunctions, inspect.isfunction)]\n",
    "# functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6204cd-8fba-45d2-ba8c-7d95fb844786",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "#PLOTTING\n",
    "plotting=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cda036-e1cf-4516-ad5e-1ccd7d76511d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# #DOMAIN SUBSETTING\n",
    "# ocean_percent=2/8\n",
    "\n",
    "# left_to_coast=data['xh'][0]+(data['xh'][-1]-data['xh'][0])*ocean_percent\n",
    "# where_coast_xh=np.where(data['xh']>=left_to_coast)[0][0]#-25\n",
    "# where_coast_xf=np.where(data['xf']>=left_to_coast)[0][0]#-25\n",
    "# end_xh=len(data['xh'])-1-50\n",
    "# end_xf=len(data['xf'])-1-50\n",
    "\n",
    "# print(f'x in {0}:{where_coast_xh-1} FOR SEA')\n",
    "# print(f'x in {where_coast_xh}:{end_xh} FOR LAND')\n",
    "# # t_end=78 \n",
    "# # if res=='250m':t_end=410\n",
    "# # print(f't in {0}:{t_end} (6.5 hours)')\n",
    "# t_start=36 \n",
    "# print(f't in {t_start}:end (8 hours)')\n",
    "\n",
    "# profile_array_e_g=profile_array_e_g[slice(0,78+1),:,:,slice(where_coast_xh,end_xh+1)]\n",
    "# profile_array_d_g=profile_array_d_g[slice(0,78+1),:,:,slice(where_coast_xh,end_xh+1)]\n",
    "# profile_array_e_c=profile_array_e_c[slice(0,78+1),:,:,slice(where_coast_xh,end_xh+1)]\n",
    "# profile_array_d_c=profile_array_d_c[slice(0,78+1),:,:,slice(where_coast_xh,end_xh+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba98016-f98a-48d7-9ab5-b14c354263df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#constants\n",
    "Cp=1004 #Jkg-1K-1\n",
    "Cv=717 #Jkg-1K-1\n",
    "Rd=Cp-Cv #Jkg-1K-1\n",
    "eps=0.608\n",
    "\n",
    "Lx=(data['xf'][-1].item()-data['xf'][0].item())*1000 #x length (m)\n",
    "Ly=(data['yf'][-1].item()-data['yf'][0].item())*1000 #y length (m)\n",
    "Np=len(parcel['xh']) #number of lagrangian parcles\n",
    "dt=(data['time'][1]-data['time'][0]).item()/1e9 #sec\n",
    "dx=(data['xf'][1].item()-data['xf'][0].item())*1e3 #meters\n",
    "dy=(data['yf'][1].item()-data['yf'][0].item())*1e3 #meters\n",
    "xs=data['xf'].values*1000\n",
    "ys=data['yf'].values*1000\n",
    "zs=data['zf'].values*1000\n",
    "\n",
    "def zf(z):\n",
    "    k=z #z is the # level of z\n",
    "    out=data['zf'].values[k]*1000\n",
    "    \n",
    "    return out\n",
    "# def rho(x,y,z,t):\n",
    "#     p=data['prs'].isel(xh=x,yh=y,zh=z,time=t).item()\n",
    "#     p0=101325 #Pa\n",
    "#     theta=data['th'].isel(xh=x,yh=y,zh=z,time=t).item()\n",
    "#     T=theta*(p/p0)**(Rd/Cp)\n",
    "#     qv=data['qv'].isel(xh=x,yh=y,zh=z,time=t).item()\n",
    "#     # Tv=T*(1+eps*qv)\n",
    "#     Tv=T*(eps+qv)/(eps*(1+qv))\n",
    "#     rho = p/(Rd*Tv)\n",
    "#     out=rho\n",
    "#     return out\n",
    "\n",
    "def rho(x,y,z,rho_data_t):\n",
    "    out=rho_data_t[z,y,x]\n",
    "    return out\n",
    "def m(t):\n",
    "    rho_data_t=data['rho'].isel(time=t).data\n",
    "    \n",
    "    m=0\n",
    "    #triple sum\n",
    "    for k in range(len(data['zh'])):\n",
    "        dz=(zf(k+1)-zf(k))\n",
    "        for j in range(len(data['yh'])):\n",
    "            for i in range(len(data['xh'])):\n",
    "                rho_out=rho(i,j,k,rho_data_t)\n",
    "                m+=rho_out*dz\n",
    "\n",
    "    #triple sum\n",
    "    out=m*dx*dy/Np\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447270cc-d34c-4aa5-865e-8ec68664628a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if plotting==True:\n",
    "    #Calculate Mass Constant\n",
    "    # calculate='single_time'\n",
    "    # calculate=True\n",
    "    calculate=False\n",
    "    \n",
    "    if calculate==True:\n",
    "        Nt=len(data['time'])\n",
    "        m_arr=np.zeros((Nt))\n",
    "        for t in np.arange(Nt):\n",
    "            if np.mod(t,25)==0: print(t)\n",
    "            m_arr[t]=m(t)\n",
    "        dir3=dir+f'Project_Algorithms/Entrainment/OUTPUT/'\n",
    "        np.save(dir3+f'Mass_Array_{res}_{t_res}_{Np_str}.npy', m_arr)\n",
    "    elif calculate=='single_time':\n",
    "        Nt=len(data['time'])\n",
    "        m_arr=np.zeros((Nt))\n",
    "    \n",
    "        t=0 #len(data['time'])//2 #Pick some middle time\n",
    "        m_300=m(t)\n",
    "        for t in np.arange(Nt):\n",
    "            m_arr[t]=m_300 #UNCOMMENT FOR FULL CALCULATION\n",
    "        dir3=dir+f'Project_Algorithms/Entrainment/OUTPUT/'\n",
    "        np.save(dir3+f'Mass_Array_{res}_{t_res}_{Np_str}.npy', m_arr)\n",
    "    else:\n",
    "        dir3=dir+f'Project_Algorithms/Entrainment/OUTPUT/'\n",
    "        m_arr = np.load(dir3+f'Mass_Array_{res}_{t_res}_{Np_str}.npy')\n",
    "    \n",
    "    # # TESTING\n",
    "    # lst=[]\n",
    "    # for t in np.arange(133):\n",
    "    #     lst.append(m_arr[t])\n",
    "    \n",
    "    # plt.plot(lst)\n",
    "    # (np.max(lst)-np.min(lst))*100/np.mean(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf09bd9-097b-4b94-bf87-7d1c6cb39a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NONOPTIMIZED LOADING AND AVERAGING (NOT RECOMMENDED)\n",
    "\n",
    "# PROCESSING=False\n",
    "# PROCESSING=True\n",
    "\n",
    "# if PROCESSING==False:\n",
    "#     dir3=dir+f'Project_Algorithms/Entrainment/3D_entrainmentdetrainment_profiles_{res}_{t_res}_{Np_str}.h5'\n",
    "# if PROCESSING==True:\n",
    "#     dir3=dir+f'Project_Algorithms/Entrainment/3D_entrainmentdetrainment_profiles_PREPROCESSING_{res}_{t_res}_{Np_str}.h5'\n",
    "# with h5py.File(dir3, \"r\") as h5f:\n",
    "#     profile_array_e_g = h5f[\"profile_array_e_g\"][:]\n",
    "#     profile_array_e_c = h5f[\"profile_array_e_c\"][:]\n",
    "#     profile_array_d_g = h5f[\"profile_array_d_g\"][:]\n",
    "#     profile_array_d_c = h5f[\"profile_array_d_c\"][:]\n",
    "\n",
    "# def apply_constant(profile_array,apply):\n",
    "#     if apply==True:\n",
    "#         Nt=profile_array.shape[0]\n",
    "#         Nz=profile_array.shape[1]\n",
    "    \n",
    "#         profile_array/=(dx*dy*dt)\n",
    "#         for t in np.arange(Nt):\n",
    "#             profile_array[t]*=m_arr[t]\n",
    "#         for z in np.arange(Nz):\n",
    "#             dz=zf(z+1)-zf(z)\n",
    "#             profile_array[:,z]/=dz\n",
    "#     return profile_array\n",
    "\n",
    "# #APPLY CONSTANTS TO ENTRAINMENT VALUE\n",
    "# ##################################################\n",
    "# profile_array_e_g=apply_constant(profile_array_e_g,apply=True)\n",
    "# profile_array_e_c=apply_constant(profile_array_e_c,apply=True)\n",
    "# profile_array_d_g=-apply_constant(profile_array_d_g,apply=True)\n",
    "# profile_array_d_c=-apply_constant(profile_array_d_c,apply=True)\n",
    "# ##################################################\n",
    "\n",
    "# # type='general'\n",
    "# type='cloudy'\n",
    "\n",
    "# if type=='general':\n",
    "#     profile_array_e=profile_array_e_g\n",
    "#     profile_array_d=profile_array_d_g\n",
    "#     profile_array_net=profile_array_e-profile_array_d\n",
    "# if type=='cloudy':\n",
    "#     profile_array_e=profile_array_e_c\n",
    "#     profile_array_d=profile_array_d_c\n",
    "#     profile_array_net=profile_array_e-profile_array_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d60ee7-daa6-492f-94c6-2621caedf9bc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #OPTIMIZED LOADING AND AVERAGING\n",
    "# def apply_constant_tbyt(profile_array,t,apply):\n",
    "#     if apply==True:\n",
    "#         Nt=len(data['time'])\n",
    "#         Nz=len(data['zh'])\n",
    "    \n",
    "#         profile_array/=(dx*dy*dt)\n",
    "#         profile_array*=m_arr[t]\n",
    "#         for z in np.arange(Nz):\n",
    "#             dz=zf(z+1)-zf(z)\n",
    "#             profile_array[z]/=dz\n",
    "#     return profile_array\n",
    "\n",
    "\n",
    "# PROCESSING=False\n",
    "# PROCESSING=True\n",
    "\n",
    "# if PROCESSING==False:\n",
    "#     dir3=dir+f'Project_Algorithms/Entrainment/3D_entrainmentdetrainment_profiles_{res}_{t_res}_{Np_str}.h5'\n",
    "# if PROCESSING==True:\n",
    "#     dir3=dir+f'Project_Algorithms/Entrainment/3D_entrainmentdetrainment_profiles_PREPROCESSING_{res}_{t_res}_{Np_str}.h5'\n",
    "\n",
    "# def load_get_mean(e_string,d_string,type):\n",
    "#     Nt=len(data['time']); Nz=len(data['zh']); \n",
    "#     e_output_array = np.zeros((Nt, Nz))\n",
    "#     d_output_array = np.zeros((Nt, Nz))\n",
    "#     net_output_array = np.zeros((Nt, Nz))\n",
    "\n",
    "    \n",
    "#     with h5py.File(dir3, \"r\") as h5f:\n",
    "#         #Reading\n",
    "\n",
    "#         for t in np.arange(Nt):\n",
    "#             print(t)\n",
    "#             profile_array_e = h5f[e_string][t]\n",
    "#             profile_array_d = h5f[d_string][t]\n",
    "    \n",
    "#             #Applying Constants\n",
    "#             profile_array_e=apply_constant_tbyt(profile_array_e,t,apply=True)\n",
    "#             profile_array_d=-apply_constant_tbyt(profile_array_d,t,apply=True)\n",
    "    \n",
    "#             profile_array_net=profile_array_e-profile_array_d\n",
    "\n",
    "#             e_mean_yx=np.mean(profile_array_e, axis = (1,2))\n",
    "#             d_mean_yx=np.mean(profile_array_d, axis = (1,2))\n",
    "#             net_mean_yx=np.mean(profile_array_net, axis = (1,2))\n",
    "\n",
    "#             e_output_array[t]=e_mean_yx\n",
    "#             d_output_array[t]=d_mean_yx\n",
    "#             net_output_array[t]=net_mean_yx\n",
    "\n",
    "    \n",
    "#     return e_output_array, d_output_array, net_output_array\n",
    "\n",
    "# # #TESTING\n",
    "# # test=np.random.random((2,4,4,4))\n",
    "# # one=np.mean(test[0],axis=(1,2))\n",
    "# # two=np.mean(test[1],axis=(1,2))\n",
    "# # full=np.mean(test,axis=(2,3))\n",
    "# # print(full[0]==one)\n",
    "# # print(full[1]==two)\n",
    "\n",
    "# type='general'\n",
    "# type='cloudy'\n",
    "\n",
    "# if type=='general':\n",
    "#     e_string=\"profile_array_e_g\"\n",
    "#     d_string=\"profile_array_d_g\"\n",
    "#     [profile_array_e,profile_array_d,profile_array_net] = load_get_mean(e_string,d_string,type)\n",
    "    \n",
    "# if type=='cloudy':\n",
    "#     e_string=\"profile_array_e_c\"\n",
    "#     d_string=\"profile_array_d_c\"\n",
    "#     [profile_array_e,profile_array_d,profile_array_net] = load_get_mean(e_string,d_string,type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ac98ca-9fd8-4476-8577-3b4456b57a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESSING=False\n",
    "PROCESSING=True\n",
    "\n",
    "if PROCESSING==False:\n",
    "    dir3=dir+f'Project_Algorithms/Entrainment/OUTPUT/3D_entrainmentdetrainment_profiles_{res}_{t_res}_{Np_str}.h5'\n",
    "if PROCESSING==True:\n",
    "    dir3=dir+f'Project_Algorithms/Entrainment/OUTPUT/3D_entrainmentdetrainment_profiles_PREPROCESSING_{res}_{t_res}_{Np_str}.h5'\n",
    "\n",
    "import dask\n",
    "import dask.array as da\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "# Open the dataset with chunking\n",
    "ds = xr.open_dataset(\n",
    "    dir3,\n",
    "    engine='h5netcdf',  # Use the correct engine based on the file type\n",
    "    phony_dims='sort',\n",
    "    chunks = {'phony_dim_0': 100,\n",
    "              'phony_dim_1': 34,\n",
    "              'phony_dim_2': 100,\n",
    "              'phony_dim_3': 64#128\n",
    "}\n",
    ")\n",
    "\n",
    "# Rename the dimensions\n",
    "ds = ds.rename({\n",
    "    'phony_dim_0': 't',   # Rename phony_dim_0 to 't'\n",
    "    'phony_dim_1': 'z',   # Rename phony_dim_1 to 'z'\n",
    "    'phony_dim_2': 'y',   # Rename phony_dim_2 to 'y'\n",
    "    'phony_dim_3': 'x'    # Rename phony_dim_3 to 'x'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a467069-14c8-490a-bfa2-b4d3b47f87a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EVEN MORE OPTIMIZED WITH DASK\n",
    "\n",
    "def apply_constant(profile_array, apply, dx, dy, dt, m_arr, dz):\n",
    "    if apply:\n",
    "        # Step 1: Divide by dx * dy * dt (scalar)\n",
    "        profile_array = profile_array / (dx * dy * dt)\n",
    "\n",
    "        # Step 2: Multiply by m_arr[t] — shape (Nt,) needs to broadcast to (Nt, Nz, Ny, Nx)\n",
    "        m_arr_broadcasted = da.asarray(m_arr)[:, None, None, None]  # Shape: (Nt, 1, 1, 1)\n",
    "        profile_array = profile_array * m_arr_broadcasted\n",
    "\n",
    "        # Step 3: Divide by dz[z] — zf of shape (Nz + 1,), so dz is (Nz,)\n",
    "        dz = da.asarray(dz)  # Shape: (Nz,)\n",
    "        dz_broadcasted = dz[None, :, None, None]  # Shape: (1, Nz, 1, 1)\n",
    "        profile_array = profile_array / dz_broadcasted\n",
    "\n",
    "    return profile_array\n",
    "\n",
    "profile_vars = ['e_c', 'd_c', 'e_g', 'd_g']\n",
    "tz_profiles = {}\n",
    "zf2=data['zf'].data*1000\n",
    "dz=zf2[1:]-zf2[:-1]\n",
    "\n",
    "with ProgressBar():\n",
    "    for var in profile_vars:\n",
    "        profile_array = ds[f'profile_array_{var}']\n",
    "        # Apply the same transformation to each variable\n",
    "        profile_array_updated = apply_constant(profile_array, apply=True, dx=dx, dy=dy, dt=dt, m_arr=m_arr, dz=dz)\n",
    "        # Compute the zx mean\n",
    "        tz_profile = profile_array_updated.mean(dim=('y', 'x'))\n",
    "        tz_profiles[f'tz_profile_array_{var}'] = tz_profile#.compute()\n",
    "\n",
    "    # Persist the results (keep them in memory across workers)\n",
    "    tz_profiles_persisted = {k: v.persist() for k, v in tz_profiles.items()}\n",
    " \n",
    "    # Compute all profiles at once to avoid individual .compute() calls\n",
    "    computed_profiles = dask.compute(*tz_profiles_persisted.values())\n",
    "\n",
    "    # Map the computed results back to the dictionary\n",
    "    tz_profiles = dict(zip(tz_profiles_persisted.keys(), computed_profiles))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5726895-2590-4046-99a7-d0e7714becd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVING\n",
    "dir3=dir2+f'Project_Algorithms/Entrainment/OUTPUT/Entrainment_tz_profiles_{res}_{t_res}_{Np_str}.npz'\n",
    "np.savez(dir3, **tz_profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f1238d-887b-4d80-abdb-81a677a70bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6b5b31-4cf0-4572-a738-24e885cb634a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOADING\n",
    "dir3=dir2+f'Project_Algorithms/Entrainment/OUTPUT/Entrainment_tz_profiles_{res}_{t_res}_{Np_str}.npz'\n",
    "tz_profiles=np.load(dir3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ed48d3-a224-4fbb-b4dc-7ff006c3d217",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "type1='general'\n",
    "type1='cloudy'\n",
    "profile_array_e = tz_profiles['tz_profile_array_e_'+type1[0]].copy()\n",
    "profile_array_d = -tz_profiles['tz_profile_array_d_'+type1[0]].copy()\n",
    "profile_array_net=profile_array_e-profile_array_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f9b235-8971-49de-af2f-bd3e81be7d85",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# #OLD PLOTTING FUNCTION\n",
    "\n",
    "# #Plotting\n",
    "# ############################################################\n",
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.gridspec import GridSpec\n",
    "# import numpy as np\n",
    "\n",
    "# fig = plt.figure(figsize=(10, 8))\n",
    "# gs = GridSpec(2, 2, figure=fig)\n",
    "\n",
    "# ######\n",
    "# cmap1 = plt.cm.viridis\n",
    "# cmap2 = plt.cm.seismic \n",
    "# n_levels=29\n",
    "# ######\n",
    "\n",
    "# ######\n",
    "# vmax_shared = np.max([np.max(profile_array_e), np.max(profile_array_d)])\n",
    "# print(np.max([np.max(profile_array_e), np.max(profile_array_d)]))\n",
    "# norm_shared = mcolors.Normalize(vmin=0, vmax=vmax_shared)\n",
    "# ######\n",
    "\n",
    "# # First subplot: Entrainment\n",
    "# ########################################\n",
    "# ax1 = fig.add_subplot(gs[0, 0])\n",
    "# # contour1 = ax1.contourf(profile_array_e.T, cmap=cmap1)\n",
    "# contour1 = ax1.contourf(profile_array_e.T, cmap=cmap1, norm=norm_shared, levels=n_levels)\n",
    "# cbar1=fig.colorbar(contour1, ax=ax1)\n",
    "# Nz = len(data['zh'])\n",
    "# ax1.set_yticks(np.arange(Nz))\n",
    "# new_ytick_labels = np.round(data['zf'].values[:Nz], 2)\n",
    "# ax1.set_yticklabels(new_ytick_labels, fontsize=8, rotation=0)\n",
    "# ax1.set_ylabel('z (km)');ax1.set_xlabel('t (timesteps)')\n",
    "# ax1.set_title('Entrainment using Lagrangian Binary Array',fontsize=8)\n",
    "\n",
    "# # Second subplot: Detrainment\n",
    "# ########################################\n",
    "# ax2 = fig.add_subplot(gs[0, 1])\n",
    "# # contour2 = ax2.contourf(profile_array_d.T, cmap=cmap1)\n",
    "# contour2 = ax2.contourf(profile_array_d.T, cmap=cmap1, norm=norm_shared, levels=n_levels)\n",
    "# cbar2 = fig.colorbar(contour2, ax=ax2)\n",
    "# ax2.set_yticks(np.arange(Nz))\n",
    "# new_ytick_labels = np.round(data['zf'].values[:Nz], 2)\n",
    "# ax2.set_yticklabels(new_ytick_labels, fontsize=8, rotation=0)\n",
    "# ax2.set_ylabel('z (km)');ax2.set_xlabel('t (timesteps)')\n",
    "# ax2.set_title('Detrainment')\n",
    "\n",
    "# # Third subplot: Net Entrainment\n",
    "# ########################################\n",
    "\n",
    "\n",
    "# # #OLD METHOD, DOESNT BALANCE COLOR LEVELS\n",
    "# # # Normalize with a balanced vmin and vmax\n",
    "# # levels=49; vmin=np.min(profile_array_net);vmax=np.max(profile_array_net)\n",
    "# # # vmin=-np.max(abs(profile_array_net)); vmax=+np.max(abs(profile_array_net))\n",
    "# # norm = mcolors.TwoSlopeNorm(vmin=vmin, vcenter=0, vmax=vmax)\n",
    "\n",
    "# # Normalize with a balanced vmin and vmax\n",
    "# vmin=-np.max(abs(profile_array_net)); vmax=+np.max(abs(profile_array_net))\n",
    "# levels = np.linspace(vmin, vmax, n_levels)\n",
    "# norm = mcolors.BoundaryNorm(boundaries=levels, ncolors=256)\n",
    "# cmap = plt.get_cmap('RdBu_r', n_levels)\n",
    "\n",
    "# ax3 = fig.add_subplot(gs[1, 0])\n",
    "# contour3 = ax3.contourf((profile_array_net).T, cmap=cmap2, norm=norm, levels=levels)\n",
    "# # contour3 = ax3.contourf((profile_array_net).T, cmap=cmap2, levels=30,vmin=-np.max(abs(profile_array_net)), vmax=+np.max(abs(profile_array_net)))\n",
    "# # cmap2 = plt.get_cmap('RdBu', 29);contour3 = ax3.pcolor(profile_array_net.T, cmap=cmap2, norm=norm, shading='auto')\n",
    "# cbar3 = fig.colorbar(contour3, ax=ax3, norm=norm)\n",
    "\n",
    "# #FIXING TICKS\n",
    "# ax3.set_yticks(np.arange(Nz))\n",
    "# new_ytick_labels = np.round(data['zf'].values[:Nz], 2)\n",
    "# ax3.set_yticklabels(new_ytick_labels, fontsize=8, rotation=0)\n",
    "# ax3.set_ylabel('z (km)');ax3.set_xlabel('t (timesteps)')\n",
    "# ax3.set_title('Entrainment - Detrainment')\n",
    "\n",
    "# #FIXING SCIENTIFIC NOTATION\n",
    "\n",
    "# def apply_scientific_notation_colorbar(cbars):\n",
    "#     from matplotlib.ticker import ScalarFormatter\n",
    "#     formatter = ScalarFormatter(useMathText=True)\n",
    "#     formatter.set_powerlimits((-2, 2))  # Adjust the range for scientific notation\n",
    "#     for cbar in cbars:  # These must be Colorbar instances\n",
    "#         cbar.formatter = formatter\n",
    "#         cbar.update_ticks()\n",
    "# apply_scientific_notation_colorbar([cbar1,cbar2,cbar3])\n",
    "\n",
    "# # Display the plot\n",
    "# plt.tight_layout()\n",
    "\n",
    "# #TESTING\n",
    "# print(f\"Max of profile_array_e: {np.max(profile_array_e)}\")\n",
    "# print(f\"Max of profile_array_d: {np.max(profile_array_d)}\")\n",
    "\n",
    "# ###################### FIXING Y TICKS\n",
    "# Nz = len(data['zh'])\n",
    "# step = 4  # change to 2, 5, etc. depending on how spaced you want them\n",
    "# ytick_pos = np.arange(0, Nz, step)\n",
    "# ytick_labels = np.round(data['zf'].values[ytick_pos], 2)\n",
    "# for axis in [ax1,ax2,ax3]:\n",
    "#     axis.set_yticks(ytick_pos)\n",
    "#     axis.set_yticklabels(ytick_labels, fontsize=8, rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaf46db-f75b-47ed-a036-f4397e7ac5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NEW PLOTTING METHOD\n",
    "if plotting==True:\n",
    "    \n",
    "    ######\n",
    "    cmap1 = plt.cm.viridis\n",
    "    cmap2 = plt.cm.seismic \n",
    "    n_levels=29\n",
    "    ######\n",
    "    \n",
    "    ######\n",
    "    vmax_shared = np.max([np.max(profile_array_e), np.max(profile_array_d)])\n",
    "    norm_shared = mcolors.Normalize(vmin=0, vmax=vmax_shared)\n",
    "    norm_shared = None #COMMENT OUT IF COLORBARS SHOULD BE SHARED\n",
    "    ######\n",
    "    \n",
    "    # === Create figure and subplots ===\n",
    "    # fig, axs = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    from matplotlib.gridspec import GridSpec\n",
    "    gs = GridSpec(2, 2, figure=fig)\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    ax3 = fig.add_subplot(gs[1, 0])\n",
    "    \n",
    "    # === Base Plot configuration parameters ===\n",
    "    plot_kwargs = {\n",
    "        'PlotData': None, #THIS MUST BE SET SOMEWHERE\n",
    "        'xTickLabels': None, 'yTickLabels': None, #THESE MUST BE SET SOMEWHERE\n",
    "        'contour_type': 'fill',\n",
    "        'num_xticks': 10,'round_xticks': 0, 'xTickInterval': 100,\n",
    "        'num_yticks': 15,'round_yticks': 2, 'yTickInterval': None,\n",
    "        'add_colorbar': True,'fig': fig, 'levels': 29, 'colorbar_label_rotation': 0, 'colorbar_label': None,\n",
    "        'xlabel': \"t (timesteps)\", 'ylabel': \"z (km)\",\n",
    "        'solid_contour_labels': True, 'solid_contour_round': None,\n",
    "        'xtick_rotation': 0, 'ytick_rotation': 0, 'cbar_rotation': 0,\n",
    "        'save_path': None, 'save_dpi': 300,\n",
    "        'colorbar_kwargs': {\n",
    "                'extend': 'both'\n",
    "            },\n",
    "    \n",
    "        'norm': norm_shared\n",
    "    }\n",
    "    \n",
    "    # === Plot 1 ===\n",
    "    plot_data1 = profile_array_e.copy().T\n",
    "    # plot_data1[plot_data1==0]=np.nan\n",
    "    y = data['zh'].data  # len 95\n",
    "    x = np.arange(profile_array_e.shape[0])  # len 661\n",
    "    plot_kwargs['xTickLabels'] = x\n",
    "    plot_kwargs['yTickLabels'] = y\n",
    "    \n",
    "    plot_kwargs1 = plot_kwargs.copy()\n",
    "    plot_kwargs1['PlotData'] = plot_data1\n",
    "    plot_kwargs1['cmap'] = cmap1\n",
    "    [contour1,cbar1]=UltimateContourPlot(ax1, **plot_kwargs1)\n",
    "    ax1.set_ylim(0,19)\n",
    "    ax1.set_title('Entrainment')\n",
    "    \n",
    "    # # === Plot 2 ===\n",
    "    plot_data2 = profile_array_d.copy().T\n",
    "    # plot_data2[plot_data2==0]=np.nan\n",
    "    plot_kwargs2 = plot_kwargs.copy()\n",
    "    plot_kwargs2['PlotData'] = plot_data2\n",
    "    plot_kwargs2['cmap'] = cmap1\n",
    "    [contour2,cbar2]=UltimateContourPlot(ax2, **plot_kwargs2)\n",
    "    ax2.set_ylim(0,19)\n",
    "    ax2.set_title('Detrainment')\n",
    "    \n",
    "    # # === Plot 3 ===\n",
    "    plot_data3 = profile_array_net.copy().T\n",
    "    #######################################\n",
    "    vmin=-np.max(abs(profile_array_net))/2; vmax=+np.max(abs(profile_array_net))\n",
    "    percentile_vminmax=False\n",
    "    if percentile_vminmax==True:\n",
    "        ####\n",
    "        vmin = np.percentile(profile_array_net[profile_array_net<0], 1)\n",
    "        vmax = np.percentile(profile_array_net[profile_array_net>0], 99)\n",
    "        ####    \n",
    "    levels = np.linspace(vmin, vmax, n_levels)\n",
    "    norm = mcolors.BoundaryNorm(boundaries=levels, ncolors=256)\n",
    "    #######################################\n",
    "    \n",
    "    # plot_data3[plot_data3==0]=np.nan\n",
    "    plot_kwargs3 = plot_kwargs.copy()\n",
    "    plot_kwargs3['PlotData'] = plot_data3\n",
    "    plot_kwargs3['cmap'] = cmap2\n",
    "    plot_kwargs3['norm'] = norm\n",
    "    plot_kwargs3['levels'] = levels\n",
    "    [contour3,cbar3]=UltimateContourPlot(ax3, **plot_kwargs3)\n",
    "    ax3.set_ylim(0,19)\n",
    "    ax3.set_title('Net Entrainment')\n",
    "    \n",
    "    \n",
    "    \n",
    "    ################################################################################\n",
    "    \n",
    "    #APPLY SCIENTIFIC NOTATION\n",
    "    def apply_scientific_notation_colorbar(cbars):\n",
    "        from matplotlib.ticker import ScalarFormatter\n",
    "        formatter = ScalarFormatter(useMathText=True)\n",
    "        formatter.set_powerlimits((-2, 2))  # Adjust the range for scientific notation\n",
    "        for cbar in cbars:  # These must be Colorbar instances\n",
    "            cbar.formatter = formatter\n",
    "            cbar.update_ticks()\n",
    "    apply_scientific_notation_colorbar([cbar1,cbar2,cbar3])\n",
    "\n",
    "    #TIGHT PLOTTING LAYOUT\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11fb1d4-694e-4eb1-82b1-328c79680177",
   "metadata": {},
   "outputs": [],
   "source": [
    "e=np.mean(profile_array_e,axis=(0))\n",
    "d=np.mean(profile_array_d,axis=(0))\n",
    "net=np.mean(profile_array_net,axis=(0))\n",
    "\n",
    "plt.plot(e,data['zh'],color='blue',label='entrainment')\n",
    "plt.plot(d,data['zh'],color='red',label='detrainment')\n",
    "plt.plot(net,data['zh'],linestyle='dashed',color='black',label='entrainment - detrainment')\n",
    "plt.axvline(0,color='black')\n",
    "\n",
    "plt.legend(); plt.title('2D Entrainment and Detrainment Using Lagrangian Binary Array')\n",
    "\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "formatter = ScalarFormatter(useMathText=True)\n",
    "formatter.set_scientific(True)\n",
    "formatter.set_powerlimits((-1, 1))\n",
    "plt.gca().xaxis.set_major_formatter(formatter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c2eff4-9d3c-43f4-a756-69dd1bbc6c60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f434e648-3b27-435e-a352-12d6dcac33fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b21b73-3fbf-467f-a4e9-583c028ac74a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c252ac16-afd2-417b-98fd-d28d0997c648",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9d54f4-c29b-461e-b59d-d68957ed7592",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abf7435-6b54-477b-b49e-2230a8476f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "#Z-X Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ce4b54-15bc-46fd-a6e0-2d9a4ea53834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import dask.array as da\n",
    "\n",
    "def apply_constant(profile_array, apply, dx, dy, dt, m_arr, dz):\n",
    "    if apply:\n",
    "        # Step 1: Divide by dx * dy * dt (scalar)\n",
    "        profile_array = profile_array / (dx * dy * dt)\n",
    "\n",
    "        # Step 2: Multiply by m_arr[t] — shape (Nt,) needs to broadcast to (Nt, Nz, Ny, Nx)\n",
    "        m_arr_broadcasted = da.asarray(m_arr)[:, None, None, None]  # Shape: (Nt, 1, 1, 1)\n",
    "        profile_array = profile_array * m_arr_broadcasted\n",
    "\n",
    "        # Step 3: Divide by dz[z] — zf of shape (Nz + 1,), so dz is (Nz,)\n",
    "        dz = da.asarray(dz)  # Shape: (Nz,)\n",
    "        dz_broadcasted = dz[None, :, None, None]  # Shape: (1, Nz, 1, 1)\n",
    "        profile_array = profile_array / dz_broadcasted\n",
    "\n",
    "    return profile_array\n",
    "\n",
    "profile_vars = ['e_c', 'd_c', 'e_g', 'd_g']\n",
    "zx_profiles = {}\n",
    "zf2=data['zf'].data*1000\n",
    "dz=zf2[1:]-zf2[:-1]\n",
    "\n",
    "with ProgressBar():\n",
    "    for var in profile_vars:\n",
    "        profile_array = ds[f'profile_array_{var}']\n",
    "        # Apply the same transformation to each variable\n",
    "        profile_array_updated = apply_constant(profile_array, apply=True, dx=dx, dy=dy, dt=dt, m_arr=m_arr, dz=dz)\n",
    "        # Compute the zx mean\n",
    "        zx_profile = profile_array_updated.mean(dim=('t', 'y'))\n",
    "        zx_profiles[f'zx_profile_array_{var}'] = zx_profile#.compute()\n",
    "\n",
    "    # Persist the results (keep them in memory across workers)\n",
    "    zx_profiles_persisted = {k: v.persist() for k, v in zx_profiles.items()}\n",
    " \n",
    "    # Compute all profiles at once to avoid individual .compute() calls\n",
    "    computed_profiles = dask.compute(*zx_profiles_persisted.values())\n",
    "\n",
    "    # Map the computed results back to the dictionary\n",
    "    tz_profiles = dict(zip(zx_profiles_persisted.keys(), computed_profiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2942e84a-a8f8-4edc-b8eb-18d4bfd64356",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVING\n",
    "dir3=dir2+f'Project_Algorithms/Entrainment/Entrainment_zx_profiles_{res}_{t_res}_{Np_str}.npz'\n",
    "np.savez(dir3, **tz_profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cc22c4-66af-4ce5-9ede-3d03bbf3845f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8c68b0-654f-48e6-834f-75cabab300bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOADING\n",
    "dir3=dir2+f'Project_Algorithms/Entrainment/Entrainment_zx_profiles_{res}_{t_res}_{Np_str}.npz'\n",
    "zx_profiles=np.load(dir3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ad482f-c253-47de-90dd-c25ef5317721",
   "metadata": {},
   "outputs": [],
   "source": [
    "type1='general'\n",
    "type1='cloudy'\n",
    "profile_array_e = zx_profiles['zx_profile_array_e_'+type1[0]].copy()\n",
    "profile_array_d = -zx_profiles['zx_profile_array_d_'+type1[0]].copy()\n",
    "profile_array_net=profile_array_e-profile_array_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10364e8-cfe9-4c4a-a034-ac56d3b39dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrainment\n",
    "\n",
    "#Plotting\n",
    "############################################################\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import numpy as np\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "gs = GridSpec(2, 2, figure=fig)\n",
    "\n",
    "######\n",
    "cmap1 = plt.cm.viridis\n",
    "cmap2 = plt.cm.seismic \n",
    "n_levels=29\n",
    "######\n",
    "\n",
    "######\n",
    "vmax_shared = np.max([np.max(profile_array_e), np.max(profile_array_d)])\n",
    "print(np.max([np.max(profile_array_e), np.max(profile_array_d)]))\n",
    "norm_shared = mcolors.Normalize(vmin=0, vmax=vmax_shared)\n",
    "######\n",
    "\n",
    "# First subplot: Entrainment\n",
    "########################################\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "# contour1 = ax1.contourf(profile_array_e.T, cmap=cmap1)\n",
    "contour1 = ax1.contour(profile_array_e, cmap=cmap1, norm=norm_shared, levels=n_levels)\n",
    "cbar1=fig.colorbar(contour1, ax=ax1)\n",
    "Nz = len(data['zh'])\n",
    "ax1.set_yticks(np.arange(Nz))\n",
    "new_ytick_labels = np.round(data['zf'].values[:Nz], 2)\n",
    "ax1.set_yticklabels(new_ytick_labels, fontsize=8, rotation=0)\n",
    "ax1.set_ylabel('z (km)');ax1.set_xlabel('x (km)')\n",
    "ax1.set_title('Entrainment using Lagrangian Binary Array',fontsize=8)\n",
    "\n",
    "# Second subplot: Detrainment\n",
    "########################################\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "# contour2 = ax2.contourf(profile_array_d.T, cmap=cmap1)\n",
    "contour2 = ax2.contour(profile_array_d, cmap=cmap1, norm=norm_shared, levels=n_levels)\n",
    "cbar2 = fig.colorbar(contour2, ax=ax2)\n",
    "ax2.set_yticks(np.arange(Nz))\n",
    "new_ytick_labels = np.round(data['zf'].values[:Nz], 2)\n",
    "ax2.set_yticklabels(new_ytick_labels, fontsize=8, rotation=0)\n",
    "ax2.set_ylabel('z (km)');ax2.set_xlabel('x (km)')\n",
    "ax2.set_title('Detrainment')\n",
    "\n",
    "# Third subplot: Net Entrainment\n",
    "########################################\n",
    "\n",
    "\n",
    "# #OLD METHOD, DOESNT BALANCE COLOR LEVELS\n",
    "# # Normalize with a balanced vmin and vmax\n",
    "# levels=49; vmin=np.min(profile_array_net);vmax=np.max(profile_array_net)\n",
    "# # vmin=-np.max(abs(profile_array_net)); vmax=+np.max(abs(profile_array_net))\n",
    "# norm = mcolors.TwoSlopeNorm(vmin=vmin, vcenter=0, vmax=vmax)\n",
    "\n",
    "# Normalize with a balanced vmin and vmax\n",
    "vmin=-np.max(abs(profile_array_net)); vmax=+np.max(abs(profile_array_net))\n",
    "levels = np.linspace(vmin, vmax, n_levels)\n",
    "norm = mcolors.BoundaryNorm(boundaries=levels, ncolors=256)\n",
    "cmap = plt.get_cmap('RdBu_r', n_levels)\n",
    "\n",
    "ax3 = fig.add_subplot(gs[1, 0])\n",
    "contour3 = ax3.contour((profile_array_net), cmap=cmap2, norm=norm, levels=levels)\n",
    "# contour3 = ax3.contourf((profile_array_net).T, cmap=cmap2, levels=30,vmin=-np.max(abs(profile_array_net)), vmax=+np.max(abs(profile_array_net)))\n",
    "# cmap2 = plt.get_cmap('RdBu', 29);contour3 = ax3.pcolor(profile_array_net.T, cmap=cmap2, norm=norm, shading='auto')\n",
    "cbar3 = fig.colorbar(contour3, ax=ax3, norm=norm)\n",
    "\n",
    "#FIXING YTICKS\n",
    "ax3.set_yticks(np.arange(Nz))\n",
    "new_ytick_labels = np.round(data['zf'].values[:Nz], 2)\n",
    "ax3.set_yticklabels(new_ytick_labels, fontsize=8, rotation=0)\n",
    "ax3.set_ylabel('z (km)');ax3.set_xlabel('x (km)')\n",
    "ax3.set_title('Entrainment - Detrainment')\n",
    "\n",
    "#FIXING XTICKS\n",
    "fix_tick_labels([ax1,ax2,ax3], data, data_dim='x', tick_axis='x', d_xtick=85, d_ytick=20, cell_loc='center',round=1,meters=False) \n",
    "\n",
    "\n",
    "#FIXING SCIENTIFIC NOTATION\n",
    "\n",
    "def apply_scientific_notation_colorbar(cbars):\n",
    "    from matplotlib.ticker import ScalarFormatter\n",
    "    formatter = ScalarFormatter(useMathText=True)\n",
    "    formatter.set_powerlimits((-2, 2))  # Adjust the range for scientific notation\n",
    "    for cbar in cbars:  # These must be Colorbar instances\n",
    "        cbar.formatter = formatter\n",
    "        cbar.update_ticks()\n",
    "apply_scientific_notation_colorbar([cbar1,cbar2,cbar3])\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "\n",
    "#TESTING\n",
    "print(f\"Max of profile_array_e: {np.max(profile_array_e)}\")\n",
    "print(f\"Max of profile_array_d: {np.max(profile_array_d)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b9037e-86b7-47ba-a634-908297c21735",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0ff4fe-7eb5-45ba-8daf-d4b3b8daf74d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3964ce8b-53ec-4c6e-bd1d-1e57cc6e9ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#COMBINED ENTRAINMENT\n",
    "PROCESSING=False\n",
    "PROCESSING=True\n",
    "\n",
    "# if PROCESSING==False:\n",
    "#     dir3=dir+f'Project_Algorithms/Entrainment/OUTPUT/3D_entrainmentdetrainment_combined_profiles_{res}_{t_res}_{Np_str}.h5'\n",
    "# if PROCESSING==True:\n",
    "#     dir3=dir+f'Project_Algorithms/Entrainment/OUTPUT/3D_entrainmentdetrainment_combined_profiles_PREPROCESSING_{res}_{t_res}_{Np_str}.h5'\n",
    "\n",
    "if PROCESSING==False:\n",
    "    dir3=dir+f'Project_Algorithms/Entrainment/OUTPUT/3D_entrainmentdetrainment_profiles_{res}_{t_res}_{Np_str}.h5'\n",
    "if PROCESSING==True:\n",
    "    dir3=dir+f'Project_Algorithms/Entrainment/OUTPUT/3D_entrainmentdetrainment_profiles_PREPROCESSING_{res}_{t_res}_{Np_str}.h5'\n",
    "\n",
    "import dask\n",
    "import dask.array as da\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "# Open the dataset with chunking\n",
    "ds2 = xr.open_dataset(\n",
    "    dir3,\n",
    "    engine='h5netcdf',  # Use the correct engine based on the file type\n",
    "    phony_dims='sort',\n",
    "    chunks = {'phony_dim_0': 100,\n",
    "              'phony_dim_1': 34,\n",
    "              'phony_dim_2': 100,\n",
    "              'phony_dim_3': 64#128\n",
    "}\n",
    ")\n",
    "\n",
    "# Rename the dimensions\n",
    "ds2 = ds2.rename({\n",
    "    'phony_dim_0': 't',   # Rename phony_dim_0 to 't'\n",
    "    'phony_dim_1': 'z',   # Rename phony_dim_1 to 'z'\n",
    "    'phony_dim_2': 'y',   # Rename phony_dim_2 to 'y'\n",
    "    'phony_dim_3': 'x'    # Rename phony_dim_3 to 'x'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282ad68f-b267-4723-92f4-395d3ac8b279",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EVEN MORE OPTIMIZED WITH DASK\n",
    "\n",
    "def apply_constant(profile_array, apply, dx, dy, dt, m_arr, dz):\n",
    "    if apply:\n",
    "        # Step 1: Divide by dx * dy * dt (scalar)\n",
    "        profile_array = profile_array / (dx * dy * dt)\n",
    "\n",
    "        # Step 2: Multiply by m_arr[t] — shape (Nt,) needs to broadcast to (Nt, Nz, Ny, Nx)\n",
    "        m_arr_broadcasted = da.asarray(m_arr)[:, None, None, None]  # Shape: (Nt, 1, 1, 1)\n",
    "        profile_array = profile_array * m_arr_broadcasted\n",
    "\n",
    "        # Step 3: Divide by dz[z] — zf of shape (Nz + 1,), so dz is (Nz,)\n",
    "        dz = da.asarray(dz)  # Shape: (Nz,)\n",
    "        dz_broadcasted = dz[None, :, None, None]  # Shape: (1, Nz, 1, 1)\n",
    "        profile_array = profile_array / dz_broadcasted\n",
    "\n",
    "    return profile_array\n",
    "\n",
    "profile_vars = ['c_to_g_E', 'g_to_c_E','c_to_g_D', 'g_to_c_D']\n",
    "tz_profiles = {}\n",
    "zf2=data['zf'].data*1000\n",
    "dz=zf2[1:]-zf2[:-1]\n",
    "\n",
    "with ProgressBar():\n",
    "    for var in profile_vars:\n",
    "        profile_array = ds[f'profile_array_{var}']\n",
    "        # Apply the same transformation to each variable\n",
    "        profile_array_updated = apply_constant(profile_array, apply=True, dx=dx, dy=dy, dt=dt, m_arr=m_arr, dz=dz)\n",
    "        # Compute the zx mean\n",
    "        tz_profile = profile_array_updated.mean(dim=('y', 'x'))\n",
    "        tz_profiles[f'tz_profile_array_{var}'] = tz_profile#.compute()\n",
    "\n",
    "    # Persist the results (keep them in memory across workers)\n",
    "    tz_profiles_persisted = {k: v.persist() for k, v in tz_profiles.items()}\n",
    " \n",
    "    # Compute all profiles at once to avoid individual .compute() calls\n",
    "    computed_profiles = dask.compute(*tz_profiles_persisted.values())\n",
    "\n",
    "    # Map the computed results back to the dictionary\n",
    "    tz_profiles = dict(zip(tz_profiles_persisted.keys(), computed_profiles))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802ed06c-29c4-4357-ba9c-8c577dca4adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_array_c_to_g_E = tz_profiles['tz_profile_array_c_to_g_E'].copy()\n",
    "profile_array_g_to_c_E = tz_profiles['tz_profile_array_g_to_c_E'].copy()\n",
    "profile_array_c_to_g_D = tz_profiles['tz_profile_array_c_to_g_D'].copy()\n",
    "profile_array_g_to_c_D = tz_profiles['tz_profile_array_g_to_c_D'].copy()\n",
    "\n",
    "#SAVING\n",
    "dir3=dir2+f'Project_Algorithms/Entrainment/OUTPUT/Combined_Entrainment_tz_profiles_{res}_{t_res}_{Np_str}.npz'\n",
    "np.savez(dir3, **tz_profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a219d043-f03e-43e2-86d5-badf68f1f0fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f1884f-ab94-444a-9bce-cd25aa6a3c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOADING\n",
    "dir3=dir2+f'Project_Algorithms/Entrainment/OUTPUT/Entrainment_tz_profiles_{res}_{t_res}_{Np_str}.npz'\n",
    "tz_profiles=np.load(dir3)\n",
    "\n",
    "type1='general'\n",
    "profile_array_e_g = tz_profiles['tz_profile_array_e_'+type1[0]].copy()\n",
    "profile_array_d_g = -tz_profiles['tz_profile_array_d_'+type1[0]].copy()\n",
    "\n",
    "type1='cloudy'\n",
    "profile_array_e_c = tz_profiles['tz_profile_array_e_'+type1[0]].copy()\n",
    "profile_array_d_c = -tz_profiles['tz_profile_array_d_'+type1[0]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6ec73c-8302-4f71-a335-fe83bbb4d0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOADING\n",
    "dir3=dir2+f'Project_Algorithms/Entrainment/OUTPUT/Combined_Entrainment_tz_profiles_{res}_{t_res}_{Np_str}.npz'\n",
    "tz_profiles=np.load(dir3)\n",
    "\n",
    "# Extract and make independent copies of the four arrays\n",
    "profile_array_c_to_g_E = tz_profiles['tz_profile_array_c_to_g_E'].copy()\n",
    "profile_array_g_to_c_E = tz_profiles['tz_profile_array_g_to_c_E'].copy()\n",
    "profile_array_c_to_g_D = tz_profiles['tz_profile_array_c_to_g_D'].copy()\n",
    "profile_array_g_to_c_D = tz_profiles['tz_profile_array_g_to_c_D'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3b20de-a13d-4afa-9f5c-f5974daf6f1d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def plot_transfer_rate(ax, c_to_g, g_to_c,title):\n",
    "#     zh=data['zh'].data\n",
    "\n",
    "#     # Mean profiles\n",
    "#     c_to_g_mean = np.mean(c_to_g, axis=0)\n",
    "#     g_to_c_mean = np.mean(g_to_c, axis=0)\n",
    "\n",
    "#     # Plot transfers\n",
    "#     ax.plot(c_to_g_mean, zh, color='red', label='Cloudy → General')\n",
    "#     ax.plot(g_to_c_mean, zh, color='blue', label='General → Cloudy')\n",
    "#     ax.axvline(0, color='black', linewidth=1)\n",
    "\n",
    "#     # Reference lines\n",
    "#     # ax.axhline(cloudbase, color='purple', linestyle='dashed',lw=1.2)\n",
    "#     # ax.axhline(MeanLFC / 1000, color='forestgreen', linestyle='dashed',lw=1.2)\n",
    "\n",
    "#     # Labeling and formatting\n",
    "#     ax.set_title(f\"{title}\")\n",
    "#     ax.set_xlabel('Mass Transfer Rate')\n",
    "#     ax.set_xlabel(r\"($kg m^{-3} s^{-1}$)\")  \n",
    "#     ax.set_ylabel('z (km)')\n",
    "#     # ax.set_xlim(left=0)\n",
    "#     ax.legend()\n",
    "\n",
    "#     apply_scientific_notation([ax])\n",
    "\n",
    "# def plot_transfer_ratio(ax, profile_array_e_g, c_to_g, profile_array_e_c, g_to_c, title):\n",
    "#     zh = data['zh'].data\n",
    "\n",
    "#     # Compute mean profiles first\n",
    "#     mean_c_to_g = np.mean(c_to_g, axis=0)\n",
    "#     mean_g_to_c = np.mean(g_to_c, axis=0)\n",
    "    \n",
    "#     mean_e_g = np.mean(profile_array_e_g, axis=0)\n",
    "#     mean_e_c = np.mean(profile_array_e_c, axis=0)\n",
    "#     mean_d_g = np.mean(profile_array_d_g, axis=0)\n",
    "#     mean_d_c = np.mean(profile_array_d_c, axis=0)\n",
    "\n",
    "#     # Mask ratios where denominator is too small\n",
    "#     threshold = 0\n",
    "#     with np.errstate(divide='ignore', invalid='ignore'):\n",
    "#         ratio_1 = np.where(mean_e_c > threshold, mean_g_to_c / mean_e_c, np.nan)\n",
    "#         ratio_2 = np.where(mean_d_g > threshold, mean_g_to_c / mean_d_g, np.nan)\n",
    "#         ratio_3 = np.where(mean_e_g > threshold, mean_c_to_g / mean_e_g, np.nan)\n",
    "#         ratio_4 = np.where(mean_d_c > threshold, mean_c_to_g / mean_d_c, np.nan)\n",
    "    \n",
    "#     # Plot in specified order\n",
    "#     ax.plot(ratio_1, zh, color='blue', label='General → Cloudy / Cloudy Entrainment')\n",
    "#     ax.plot(ratio_2, zh, color='deepskyblue', label='General → Cloudy / General Detrainment')\n",
    "#     ax.plot(ratio_3, zh, color='red', label='Cloudy → General / General Entrainment')\n",
    "#     ax.plot(ratio_4, zh, color='orangered', label='Cloudy → General / Cloudy Detrainment')\n",
    "    \n",
    "#     ax.axvline(1, color='black', linestyle='dashed', linewidth=1)\n",
    "\n",
    "#     # Reference horizontal lines\n",
    "#     # ax.axhline(cloudbase, color='purple', linestyle='dashed', lw=1.2)\n",
    "#     # ax.axhline(MeanLFC / 1000, color='green', linestyle='dashed', lw=1.2)\n",
    "\n",
    "#     # Labels and limits\n",
    "#     ax.set_title(f\"{title}\")\n",
    "#     ax.set_xlabel('Ratio')\n",
    "#     ax.set_ylabel('z (km)')\n",
    "#     pad_fraction = 10\n",
    "#     pad_multiplier = (100 + pad_fraction) / 100\n",
    "#     ax.set_xlim(0, 1 * pad_multiplier)\n",
    "\n",
    "#     ax.legend(fontsize=10.5-2, loc='upper right')\n",
    "#     apply_scientific_notation([ax])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48d8274-6839-4c20-a493-c33e0fd7bfbd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# #VERTICAL PROFILES\n",
    "# fig = plt.figure(figsize=(18, 6))\n",
    "# gs = gridspec.GridSpec(1, 4, wspace=0.2)\n",
    "\n",
    "# ax1 = fig.add_subplot(gs[0])\n",
    "# ax2 = fig.add_subplot(gs[1])\n",
    "# ax3 = fig.add_subplot(gs[2])\n",
    "# ax4 = fig.add_subplot(gs[3])\n",
    "\n",
    "# # Call function for each subplot\n",
    "# plot_mean_entrainment(ax1, profile_array_e_g, profile_array_d_g, title='')\n",
    "# plot_mean_entrainment(ax2, profile_array_e_c, profile_array_d_c, title='')\n",
    "# plot_transfer_rate(ax3, profile_array_c_to_g, profile_array_g_to_c, title='')\n",
    "# plot_transfer_ratio(ax4, profile_array_e_g,profile_array_c_to_g, profile_array_e_c,profile_array_g_to_c, title='')\n",
    "\n",
    "# # #SAVING FIGURE\n",
    "# # fig.savefig(f\"PLOTS/Combined_Entrainment_VerticalProfiles_{res}_{t_res}_{Np_str}.jpg\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8665ae-b23d-48cf-bbbf-57a96ea84307",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean_entrainment(ax, profile_array_e, profile_array_d, title, linestyle='solid'):\n",
    "    zh=data['zh'].data\n",
    "\n",
    "    # Compute mean profiles\n",
    "    e = np.mean(profile_array_e, axis=0)\n",
    "    d = np.mean(profile_array_d, axis=0)\n",
    "    net = np.mean(profile_array_e - profile_array_d, axis=0)\n",
    "\n",
    "    # Plot\n",
    "    ax.plot(e, zh, linestyle=linestyle, color='blue', label='Entrainment')\n",
    "    ax.plot(d, zh, linestyle=linestyle, color='red', label='Detrainment')\n",
    "    ax.plot(net, zh, linestyle=linestyle, color='black', label='Net Entrainment')\n",
    "    ax.axvline(0, color='black')\n",
    "\n",
    "    ax.axhline(cloudbase, color='purple', linestyle='dashed', lw=1.2)\n",
    "    ax.axhline(MeanLFC / 1000, color='green', linestyle='dashed', lw=1.2)\n",
    "    \n",
    "    ax.set_title(f\"{title}\",fontsize=10.5)\n",
    "    ax.set_xlabel(r\"($kg\\ m^{-3}\\ s^{-1}$)\")  \n",
    "    ax.set_ylabel('z (km)')\n",
    "    ax.set_ylim(bottom=0)\n",
    "    ax.legend()\n",
    "\n",
    "    # Format x-axis in scientific notation\n",
    "    apply_scientific_notation([ax])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6394763-c5f6-4603-b060-6e66799228dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_means_for_transfer(c_to_g_E, g_to_c_E, c_to_g_D, g_to_c_D,\n",
    "                               profile_array_e_g, profile_array_e_c,\n",
    "                               profile_array_d_g, profile_array_d_c):\n",
    "    \"\"\"Compute and return mean profiles for transfer rates and entrainment/detrainment arrays.\"\"\"\n",
    "\n",
    "    # Compute means of transfer rates\n",
    "    c_to_g_E_mean = np.mean(c_to_g_E, axis=0)\n",
    "    g_to_c_E_mean = np.mean(g_to_c_E, axis=0)\n",
    "    c_to_g_D_mean = np.mean(c_to_g_D, axis=0)\n",
    "    g_to_c_D_mean = np.mean(g_to_c_D, axis=0)\n",
    "\n",
    "    # Compute means of entrainment/detrainment profiles\n",
    "    mean_e_g = np.mean(profile_array_e_g, axis=0)\n",
    "    mean_e_c = np.mean(profile_array_e_c, axis=0)\n",
    "    mean_d_g = np.mean(profile_array_d_g, axis=0)\n",
    "    mean_d_c = np.mean(profile_array_d_c, axis=0)\n",
    "\n",
    "    return {\n",
    "        'c_to_g_E_mean': c_to_g_E_mean,\n",
    "        'g_to_c_E_mean': g_to_c_E_mean,\n",
    "        'c_to_g_D_mean': c_to_g_D_mean,\n",
    "        'g_to_c_D_mean': g_to_c_D_mean,\n",
    "        'mean_e_g': mean_e_g,\n",
    "        'mean_e_c': mean_e_c,\n",
    "        'mean_d_g': mean_d_g,\n",
    "        'mean_d_c': mean_d_c\n",
    "    }\n",
    "\n",
    "    \n",
    "def plot_transfer_rate(ax, means, title):\n",
    "    zh = data['zh'].data\n",
    "\n",
    "    c_to_g_mean_E = means['c_to_g_E_mean']\n",
    "    g_to_c_mean_E = means['g_to_c_E_mean']\n",
    "    c_to_g_mean_D = means['c_to_g_D_mean']\n",
    "    g_to_c_mean_D = means['g_to_c_D_mean']\n",
    "\n",
    "    # ax.plot(g_to_c_mean_E, zh, color='blue', label='General → Cloudy',linestyle='solid')\n",
    "    # ax.plot(c_to_g_mean_E, zh, color='red', label='Cloudy → General',linestyle='solid')\n",
    "    ax.plot(g_to_c_mean_E, zh, color='blue', label='General → Cloudy (Entrainment)',linestyle='solid')\n",
    "    ax.plot(c_to_g_mean_E, zh, color='red', label='Cloudy → General (Entrainment)',linestyle='solid')\n",
    "    ax.plot(c_to_g_mean_D, zh, color='blue', label='Cloudy → General (Detrainment)',linestyle='dashed')\n",
    "    ax.plot(g_to_c_mean_D, zh, color='red', label='General → Cloudy (Detrainment)',linestyle='dashed')\n",
    "    ax.axvline(0, color='black', linewidth=1)\n",
    "\n",
    "    ax.axhline(cloudbase, color='purple', linestyle='dashed', lw=1.2)\n",
    "    ax.axhline(MeanLFC / 1000, color='forestgreen', linestyle='dashed', lw=1.2)\n",
    "\n",
    "    ax.set_title(f\"{title}\")\n",
    "    ax.set_xlabel('Mass Transfer Rate')\n",
    "    ax.set_xlabel(r\"($kg m^{-3} s^{-1}$)\")  \n",
    "    ax.set_ylabel('z (km)')\n",
    "    ax.set_ylim(bottom=0)\n",
    "    ax.legend()\n",
    "    apply_scientific_notation([ax])\n",
    "\n",
    "def plot_transfer_ratio(ax, means, title):\n",
    "    zh = data['zh'].data\n",
    "\n",
    "    mean_e_g = means['mean_e_g']\n",
    "    mean_e_c = means['mean_e_c']\n",
    "    mean_d_g = means['mean_d_g']\n",
    "    mean_d_c = means['mean_d_c']\n",
    "    \n",
    "    mean_c_to_g_E = means['c_to_g_E_mean']\n",
    "    mean_g_to_c_E = means['g_to_c_E_mean']\n",
    "    mean_c_to_g_D = means['c_to_g_D_mean']\n",
    "    mean_g_to_c_D = means['g_to_c_D_mean']\n",
    "\n",
    "    threshold = 0\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        ratio_1 = np.where(mean_e_c > threshold, mean_g_to_c_E / mean_e_c, np.nan)\n",
    "        ratio_2 = np.where(mean_d_g > threshold, mean_g_to_c_D / mean_d_g, np.nan)\n",
    "        ratio_3 = np.where(mean_e_g > threshold, mean_c_to_g_E / mean_e_g, np.nan)\n",
    "        ratio_4 = np.where(mean_d_c > threshold, mean_c_to_g_D / mean_d_c, np.nan)\n",
    "\n",
    "    # print(np.nanmean(ratio_1))\n",
    "    # print(np.nanmean(ratio_2))\n",
    "    # print(np.nanmean(ratio_3))\n",
    "    # print(np.nanmean(ratio_4))\n",
    "\n",
    "    ax.plot(ratio_1*100, zh, color='blue', label='General → Cloudy / Cloudy Entrainment')\n",
    "    ax.plot(ratio_2*100, zh, color='deepskyblue', label='General → Cloudy / General Detrainment')\n",
    "    ax.plot(ratio_3*100, zh, color='red', label='Cloudy → General / General Entrainment')\n",
    "    ax.plot(ratio_4*100, zh, color='orangered', label='Cloudy → General / Cloudy Detrainment')\n",
    "\n",
    "    ax.axvline(0, color='black', linestyle='dashed', linewidth=1)\n",
    "    # ax.axvline(1, color='black', linestyle='dashed', linewidth=1)\n",
    "    ax.axvline(100, color='black', linestyle='dashed', linewidth=1)\n",
    "    ax.axhline(cloudbase, color='purple', linestyle='dashed', lw=1.2)\n",
    "    ax.axhline(MeanLFC / 1000, color='green', linestyle='dashed', lw=1.2)\n",
    "\n",
    "    ax.set_title(f\"{title}\")\n",
    "    # ax.set_xlabel('Ratio')\n",
    "    ax.set_xlabel('%')\n",
    "    ax.set_ylabel('z (km)')\n",
    "    # ax.set_xlim(-0.05, 1.05)\n",
    "    ax.set_xlim(-5, 105)\n",
    "    ax.set_ylim(bottom=0)\n",
    "    ax.legend(fontsize=10.5-3, loc='upper right')\n",
    "    # apply_scientific_notation([ax])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc6c5a4-d133-4a73-827f-448e44740b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cloudbase=1.2\n",
    "MeanLFC=2\n",
    "# === Compute means for transfer rate and ratio plots ===\n",
    "means = compute_means_for_transfer(\n",
    "    c_to_g_E=profile_array_c_to_g_E,\n",
    "    g_to_c_E=profile_array_g_to_c_E,\n",
    "    c_to_g_D=profile_array_c_to_g_D,\n",
    "    g_to_c_D=profile_array_g_to_c_D,\n",
    "    profile_array_e_g=profile_array_e_g,\n",
    "    profile_array_e_c=profile_array_e_c,\n",
    "    profile_array_d_g=profile_array_d_g,\n",
    "    profile_array_d_c=profile_array_d_c\n",
    ")\n",
    "\n",
    "# === Set up figure and subplots ===\n",
    "fig = plt.figure(figsize=(18, 6))\n",
    "gs = gridspec.GridSpec(1, 4, wspace=0.2)\n",
    "\n",
    "ax1 = fig.add_subplot(gs[0])\n",
    "ax2 = fig.add_subplot(gs[1])\n",
    "ax3 = fig.add_subplot(gs[2])\n",
    "ax4 = fig.add_subplot(gs[3])\n",
    "\n",
    "# === Plot each panel ===\n",
    "plot_mean_entrainment(ax1, profile_array_e_g, profile_array_d_g, title='')\n",
    "plot_mean_entrainment(ax2, profile_array_e_c, profile_array_d_c, title='')\n",
    "plot_transfer_rate(ax3, means, title='')\n",
    "plot_transfer_ratio(ax4, means, title='')\n",
    "\n",
    "fix_x_limits([ax2, ax3])\n",
    "\n",
    "# # === Save figure ===\n",
    "# filename = \"Combined_Entrainment_VerticalProfiles\"\n",
    "# SaveFigure(fig, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915cce47-c01d-4475-bbf4-d163b632ae17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15249036-c8b7-48f1-872f-a13ca37f7beb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb499a96-f0bc-4959-ab35-8bcced3cd3c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e285724b-b412-4e1d-9e10-50b638e4ee65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019d2de9-3ea3-460d-ae4a-cc28038bcba3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# dm=m_arr[10]\n",
    "# zf=data['zf'].data;zh=data['zh'].data;\n",
    "# dz=(zf.copy()[1:]-zf.copy()[:-1])*1000\n",
    "# V=(dx*dy*dz)\n",
    "# rate=dm/(V*dt)\n",
    "\n",
    "# #####\n",
    "# Nx=len(data['xh']);Ny=len(data['yh']);Nt=len(data['time'])\n",
    "# rate/=(Nx*Ny)#*Nt)\n",
    "# #####\n",
    "\n",
    "# plt.plot(rate,zh)\n",
    "# plt.ylabel('z (km)');plt.xlabel('rate (minimum)');\n",
    "\n",
    "# ax=plt.gca()\n",
    "# apply_scientific_notation([ax])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e64c9ef-a551-48c9-913f-cdf13a7c9981",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# plt.plot(dz,zh)\n",
    "# plt.ylabel('z (km)');plt.xlabel('dz (m)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02674dd0-fe94-4b5b-b96d-13cc7b390214",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# #WHAT IS THE AVERAGE SUM?\n",
    "# dir3=dir+f'Project_Algorithms/Entrainment/3D_entrainmentdetrainment_profiles_PREPROCESSING_{res}_{t_res}_{Np_str}.h5'\n",
    "# e_string='profile_array_e_c'\n",
    "\n",
    "# with h5py.File(dir3, \"r\") as h5f:\n",
    "#     #Reading\n",
    "#     profile_array_e = h5f[e_string][:]\n",
    "# print(profile_array_e.max())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
