{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "913f7227-b392-4b56-a0e2-67c5291bf533",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "#ENVIRONMENT SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33c03b10-fd0b-40b4-a350-c11aaf606ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "import matplotlib.gridspec as gridspec\n",
    "import xarray as xr\n",
    "import os; import time\n",
    "import pickle\n",
    "import h5py\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d69f7a80-0933-454b-8f10-ac0a885a50a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAIN DIRECTORIES\n",
    "def GetDirectories():\n",
    "    mainDirectory='/mnt/lustre/koa/koastore/torri_group/air_directory/Projects/DCI-Project/'\n",
    "    mainCodeDirectory=os.path.join(mainDirectory,\"Code/CodeFiles/\")\n",
    "    scratchDirectory='/mnt/lustre/koa/scratch/air673/'\n",
    "    codeDirectory=os.getcwd()\n",
    "    return mainDirectory,mainCodeDirectory,scratchDirectory,codeDirectory\n",
    "\n",
    "[mainDirectory,mainCodeDirectory,scratchDirectory,codeDirectory] = GetDirectories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "600981ea-2000-4d87-832f-e8e7aa1adf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "#LOADING CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46db7fc6-0750-4956-9d0b-b595d4d80127",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT CLASSES (from current directory)\n",
    "sys.path.append(os.path.join(mainCodeDirectory,\"2_Variable_Calculation\"))\n",
    "from CLASSES_Variable_Calculation import ModelData_Class, SlurmJobArray_Class, DataManager_Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad6eba0a-0d27-4d33-a85c-b2d1e684268a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CM1 Data Summary ===\n",
      " Simulation #:   1\n",
      " Resolution:     1km\n",
      " Time step:      5min\n",
      " Vertical levels:34\n",
      " Parcels:        1e6\n",
      " Data file:      /mnt/lustre/koa/koastore/torri_group/air_directory/Projects/DCI-Project/Model/cm1r20.3/run/cm1out_1km_5min_34nz.nc\n",
      " Parcel file:    /mnt/lustre/koa/koastore/torri_group/air_directory/Projects/DCI-Project/Model/cm1r20.3/run/cm1out_pdata_1km_5min_1e6np.nc\n",
      " Time steps:     133\n",
      "========================= \n",
      "\n",
      "=== DataManager Summary ===\n",
      " inputDirectory #:   /mnt/lustre/koa/koastore/torri_group/air_directory/Projects/DCI-Project/Code/OUTPUT/Variable_Calculation/TimeSplitModelData\n",
      " outputDirectory #:   /mnt/lustre/koa/koastore/torri_group/air_directory/Projects/DCI-Project/Code/OUTPUT/Variable_Calculation/LagrangianArrays\n",
      " inputDataDirectory #:   /mnt/lustre/koa/koastore/torri_group/air_directory/Projects/DCI-Project/Code/OUTPUT/Variable_Calculation/TimeSplitModelData/1km_5min_34nz/ModelData\n",
      " inputParcelDirectory #:   /mnt/lustre/koa/koastore/torri_group/air_directory/Projects/DCI-Project/Code/OUTPUT/Variable_Calculation/TimeSplitModelData/1km_5min_34nz/ParcelData\n",
      " outputDataDirectory #:   /mnt/lustre/koa/koastore/torri_group/air_directory/Projects/DCI-Project/Code/OUTPUT/Variable_Calculation/LagrangianArrays/1km_5min_34nz/PROCESSED_Lagrangian_Binary_Array\n",
      "========================= \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#data loading class\n",
    "ModelData = ModelData_Class(mainDirectory, scratchDirectory, simulationNumber=1)\n",
    "#data manager class\n",
    "DataManager = DataManager_Class(mainDirectory, scratchDirectory, ModelData.res, ModelData.t_res, ModelData.Nz_str,\n",
    "                                ModelData.Np_str, dataType=\"LagrangianArrays\", dataName=\"PROCESSED_Lagrangian_Binary_Array\",\n",
    "                                dtype='int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2a48238-09ac-49be-8c88-e7811cf5dfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT CLASSES\n",
    "sys.path.append(os.path.join(mainCodeDirectory,\"3_Project_Algorithms\",\"2_Tracking_Algorithms\"))\n",
    "from CLASSES_TrackingAlgorithms import SlurmJobArray_Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb909daa-78e2-48fa-9baa-77785c274a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "path=os.path.join(mainCodeDirectory,'Functions/')\n",
    "sys.path.append(path)\n",
    "\n",
    "import NumericalFunctions\n",
    "from NumericalFunctions import * # import NumericalFunctions \n",
    "import PlottingFunctions\n",
    "from PlottingFunctions import * # import PlottingFunctions\n",
    "\n",
    "\n",
    "# # Get all functions in NumericalFunctions\n",
    "# import inspect\n",
    "# functions = [f[0] for f in inspect.getmembers(NumericalFunctions, inspect.isfunction)]\n",
    "# functions\n",
    "\n",
    "# # Get all functions in NumericalFunctions\n",
    "# import inspect\n",
    "# functions = [f[0] for f in inspect.getmembers(PlottingFunctions, inspect.isfunction)]\n",
    "# functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3f907d6-1cdb-425b-bee3-7c69dec6a1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "#SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a63594e6-24fb-4bc5-9109-53db2c10a028",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "#JOB ARRAY SETUP\n",
    "################################\n",
    "#*#*\n",
    "# how many total jobs are being run? i.e. array=1-100 ==> num_jobs=100\n",
    "if ModelData.Np_str=='1e6': #1M parcels\n",
    "    num_jobs=60  \n",
    "    num_slurm_jobs=20 #this is the number that goes into sbatch script\n",
    "elif ModelData.Np_str=='50e6': #50M parcels\n",
    "    num_jobs=1200 \n",
    "    num_slurm_jobs=150 #this is the number that goes into sbatch script\n",
    "##############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f96b430-de52-4567-9701-3e3bbe60296f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "#DATA LOADING FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38d8afb6-0e30-4456-831a-27c64718da98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INITIALIZE DATA FUNCTION\n",
    "###############################################################\n",
    "def InitiateArray(out_file, vars, t_chunk_size, p_chunk_size, t_size=None, p_size=None):\n",
    "    if t_size is None:\n",
    "        t_size = ModelData.Ntime  # Number of timesteps\n",
    "    if p_size is None:\n",
    "        p_size = ModelData.Np  # Number of parcel indexes\n",
    "\n",
    "    with h5py.File(out_file, 'w') as f:\n",
    "        for var_name in vars:\n",
    "            if var_name not in f:\n",
    "                # Set dtype conditionally\n",
    "                if var_name in ['Z', 'Y', 'X']:\n",
    "                    dtype = np.uint16\n",
    "                elif var_name in ['A_g','A_c','PROCESSED_A_g','PROCESSED_A_c']:\n",
    "                    dtype = np.bool_\n",
    "                else:\n",
    "                    dtype = np.float32  # or whatever your default is\n",
    "\n",
    "                f.create_dataset(\n",
    "                    var_name,\n",
    "                    shape=(t_size, p_size),\n",
    "                    chunks=(t_chunk_size, p_chunk_size),\n",
    "                    dtype=dtype\n",
    "                )\n",
    "def InitiateArray_Job(Np,out_file, vars, t_chunk_size, p_chunk_size, t_size=None, p_size=None):\n",
    "    if t_size is None:\n",
    "        t_size = ModelData.Ntime  # Number of timesteps\n",
    "    if p_size is None:\n",
    "        p_size = Np # Number of vertical levels\n",
    "\n",
    "    with h5py.File(out_file, 'w') as f:\n",
    "        for var_name in vars:\n",
    "            if var_name not in f:\n",
    "                # Set dtype conditionally\n",
    "                if var_name in ['Z', 'Y', 'X']:\n",
    "                    dtype = np.uint16\n",
    "                elif var_name in ['A_g','A_c','PROCESSED_A_g','PROCESSED_A_c']:\n",
    "                    dtype = np.bool_\n",
    "                else:\n",
    "                    dtype = np.float32  # or whatever your default is\n",
    "\n",
    "                f.create_dataset(\n",
    "                    var_name,\n",
    "                    shape=(t_size, p_size),\n",
    "                    chunks=(t_chunk_size, p_chunk_size),\n",
    "                    dtype=dtype\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93c55aa9-9717-41cc-a832-dd41686cae95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Combined Lagrangian_Binary_Array\n",
      "Done \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MULTIPLE FILES\n",
    "\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from glob import glob\n",
    "\n",
    "def TestingTimes(files):\n",
    "    print(files)\n",
    "    for f in files:\n",
    "        m = re.search(r'_(\\d+-\\d+-\\d+)\\.h5$', f)\n",
    "        if m:\n",
    "            print(m.group(1))\n",
    "def OpenMultipleSingleTimes_LagrangianArray(directory, ModelData, pattern=\"Lagrangian_Binary_Array_*.h5\"):\n",
    "    \"\"\"\n",
    "    Load a sequence of Lagrangian .h5 files (each a single timestep)\n",
    "    into one xarray.Dataset with dimensions (time, p),\n",
    "    enforcing time order from ModelData.timeStrings.\n",
    "    \"\"\"\n",
    "    # --- Find all available files\n",
    "    files_all = glob(os.path.join(directory, pattern))\n",
    "    if not files_all:\n",
    "        raise FileNotFoundError(f\"No files found in {directory} matching {pattern}\")\n",
    "\n",
    "    # --- Build the correctly ordered list according to ModelData.timeStrings\n",
    "    files = []\n",
    "    for t in ModelData.timeStrings:\n",
    "        time_pattern = f\"_{t}.h5\"\n",
    "        matched = [f for f in files_all if f.endswith(time_pattern)]\n",
    "        if matched:\n",
    "            files.append(matched[0])\n",
    "        else:\n",
    "            print(f\"Missing file for time {t}\")\n",
    "\n",
    "    #####\n",
    "    # TestingTimes(files) \n",
    "    #####\n",
    "    \n",
    "    # --- Convert ModelData.timeStrings (like ['0-00-00', '0-05-00', ...]) to pandas datetime\n",
    "    #     using an arbitrary date\n",
    "    times = pd.to_datetime([t.replace('-', ':') for t in ModelData.timeStrings], format=\"%H:%M:%S\")\n",
    "\n",
    "    # --- Open and concatenate along time\n",
    "    ds = xr.open_mfdataset(\n",
    "        files,\n",
    "        engine=\"h5netcdf\",\n",
    "        phony_dims=\"sort\",\n",
    "        combine=\"nested\",\n",
    "        concat_dim=\"time\",\n",
    "    )\n",
    "\n",
    "    # --- Rename the phony dimension to 'p'\n",
    "    if \"phony_dim_0\" in ds.dims:\n",
    "        ds = ds.rename({\"phony_dim_0\": \"p\"})\n",
    "\n",
    "    # --- Assign your correct time coordinate\n",
    "    ds = ds.assign_coords(time=times)\n",
    "\n",
    "    return ds, files\n",
    "\n",
    "\n",
    "directory = f\"/mnt/lustre/koa/koastore/torri_group/air_directory/Projects/DCI-Project/Code/OUTPUT/Variable_Calculation/LagrangianArrays/{ModelData.res}_{ModelData.t_res}_{ModelData.Nz_str}nz/Lagrangian_Binary_Array/\"\n",
    "\n",
    "print(\"Loading Combined Lagrangian_Binary_Array\")\n",
    "Lagrangian_Binary_Array,files = OpenMultipleSingleTimes_LagrangianArray(directory, ModelData)\n",
    "print(\"Done\",\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d388b49-fe15-4be9-976c-132f794c8e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Back Data Later\n",
    "##############\n",
    "def make_data_dict(var_names,start_job,end_job):\n",
    "\n",
    "    data_dict = {var_name: Lagrangian_Binary_Array[var_name].isel(p=slice(start_job, end_job)).data.compute()\n",
    "                 for var_name in var_names}\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "602dd91b-ff19-4d1a-9313-ac5f2d92c84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetArrays(start_job,end_job):    \n",
    "    var_names = ['A_g', 'A_c',\n",
    "                 'Z','Y','X']\n",
    "    data_dict = make_data_dict(var_names,start_job,end_job)\n",
    "    A_g,A_c, Z,Y,X = (data_dict[k] for k in var_names)\n",
    "    return A_g,A_c, Z,Y,X\n",
    "#also run PROCESSED VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c33fd7a-303a-4360-af06-13b8a4333cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "#FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "85508e99-9279-4d27-9c14-475ae4b8cef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RESIDENCE CALCULATION CODE\n",
    "########################################################################################################################\n",
    "\n",
    "def residence_times(p,type,updraft_type):#, \n",
    "                    #A_g,A_c, Z,Y,X):\n",
    "\n",
    "    if updraft_type=='general':\n",
    "        A=A_g\n",
    "    elif updraft_type=='cloudy':\n",
    "        A=A_c\n",
    "    \n",
    "    # B = A[:,p]\n",
    "\n",
    "    # B=np.array([0,1,0,1,0,0,1,1,0,1,1]) #TESTING\n",
    "    \n",
    "    T=np.arange(len(B))\n",
    "    \n",
    "    if np.any(B)==True:\n",
    "        if type=='e':\n",
    "            C=B.copy()\n",
    "        elif type=='d':\n",
    "            C=1-B\n",
    "    \n",
    "        \n",
    "        # Find the changes in the array\n",
    "        changes = np.diff(np.concatenate(([0], C, [0])))  # Add 0s to detect edges\n",
    "            \n",
    "        start_ind = np.where(changes == 1)[0]  # Start of sequences\n",
    "        end_ind = np.where(changes == -1)[0]  # End of sequences\n",
    "        \n",
    "        # Calculate the lengths of sequences\n",
    "        lengths = end_ind - start_ind\n",
    "\n",
    "        sequences = [(start) for start, end, length in zip(start_ind, end_ind, lengths) if length >= 1] #only records en/detrainment time\n",
    "        # sequences = [(start, *range(start + 1, end+1)) for start, end, length in zip(start_ind, end_ind, lengths) if length >= 1]\n",
    "        lens=[(end-start) for start, end, length in zip(start_ind, end_ind, lengths) if length >= 1] #residence times\n",
    "\n",
    "        #Remove the last one to get rid of entrainments that reach end of simulation\n",
    "        sequences=sequences[:-1];lens=lens[:-1]\n",
    "\n",
    "        #Initial Entrainment/Detrainment Times\n",
    "        ts=np.array(sequences.copy()) #only records en/detrainment time \n",
    "        # ts=np.array(tuple(item for seq in sequences for item in seq))\n",
    "\n",
    "         #Finds Last Time Parcel is in Cloudy Updraft before Initial Entrainment\n",
    "        last=[None]+[np.where(C[:ind + 1] == 1)[0][-2] for ind in ts[1:]]\n",
    "        last_lens=ts[1:]-last[1:]; \n",
    "        last_lens=np.insert(last_lens, 0, -1e5) #if never in cloudy updraft add -1e5 for nan\n",
    "\n",
    "        if np.any(ts):\n",
    "            zs=Z[ts,p]\n",
    "            ys=Y[ts,p]\n",
    "            xs=X[ts,p]\n",
    "            return [np.array(lens),ts,zs,ys,xs,last_lens]\n",
    "        else:\n",
    "            return []\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b64d35e7-2fad-4a77-87e5-f8fd03e89c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1, 1, 2]),\n",
       " array([1, 3, 6]),\n",
       " array([32, 32, 32], dtype=int16),\n",
       " array([29, 35, 43], dtype=int16),\n",
       " array([209, 212, 217], dtype=int16),\n",
       " array([-100000,       2,       3])]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residence_times(0,'e','general')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42382a9a-4d80-4bb3-ad75-a6a0ec2462c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CALCULATING RESIDENCE TIMES\n",
    "#############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3aa16af3-5d5c-47de-b095-3e9dab6dcee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on Slurm_Jobs for Slurm_Job_Ids: (1, 2)\n",
      "current job_id = 1\n",
      "\n",
      "0\n",
      "current job_id = 2\n",
      "\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "#RUNNING\n",
    "[start_slurm_job,end_slurm_job]=SlurmJobArray_Class.StartSlurmJobArray(num_jobs=num_jobs,num_slurm_jobs=num_slurm_jobs,ISRUN=True) #if ISRUN is False, then will not run using slurm_job_array\n",
    "\n",
    "print(f\"Running on Slurm_Jobs for Slurm_Job_Ids: {(start_slurm_job,end_slurm_job-1)}\")\n",
    "\n",
    "job_id_list=np.arange(start_slurm_job,end_slurm_job)\n",
    "for job_id in job_id_list:\n",
    "    if job_id % 1 ==0: print(f\"current job_id = {job_id}\\n\")\n",
    "    [start_job,end_job,index_adjust]=SlurmJobArray_Class.StartJobArray(ModelData, job_id, num_jobs)\n",
    "\n",
    "\n",
    "    #setup profiles\n",
    "    Nx=ModelData.Nxh;Ny=ModelData.Nyh;Nz=ModelData.Nzh\n",
    "    yx_array=np.zeros((Ny,Nx));yx_counter=np.zeros_like(yx_array)\n",
    "    zx_array=np.zeros((Nz,Nx));zx_counter=np.zeros_like(zx_array)\n",
    "    A_g, A_c, Z,Y,X = GetArrays(start_job,end_job)\n",
    "    \n",
    "    Np=ModelData.Np\n",
    "    for p in np.arange(Np): \n",
    "        if np.mod(p,4000)==0: print(p)\n",
    "        out=residence_times(p,type='e',updraft_type='cloudy',\n",
    "                            A_g=A_g,A_c=A_c, Z=Z,Y=Y,X=X)\n",
    "        \n",
    "        break\n",
    "        if np.any(out):\n",
    "            np.add.at(yx_array, (out[3], out[4]), out[0])  \n",
    "            np.add.at(yx_counter, (out[3], out[4]), 1)\n",
    "    \n",
    "            np.add.at(zx_array, (out[2], out[4]), out[0])  # Add residence times to (x, z) positions\n",
    "            np.add.at(zx_counter, (out[2], out[4]), 1)\n",
    "    # #Divide by Counts (MOVED TO JOB_ARRAY COMPILE STEP)\n",
    "\n",
    "    # #SAVING\n",
    "    # dir2=dir+'Project_Algorithms/Entrainment/'\n",
    "    # output_file = dir2+f'job_out/e_residence_time_arrays_{res}_{t_res}_{Np_str}_{job_id}.h5' \n",
    "    # with h5py.File(output_file, 'w') as f:\n",
    "    #     f.create_dataset('yx_array', data=yx_array, compression=\"gzip\")\n",
    "    #     f.create_dataset('yx_counter', data=yx_counter, compression=\"gzip\")\n",
    "    #     f.create_dataset('zx_array', data=zx_array, compression=\"gzip\")\n",
    "    #     f.create_dataset('zx_counter', data=zx_counter, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702e1982-34f3-4afd-9ab2-2e526acd4ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "#RECOMBINE SEPERATE JOB_ARRAYS AFTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678617c5-7fac-4428-ab0f-69aff3932d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir2=dir+'Project_Algorithms/Entrainment/'\n",
    "output_file = dir2+f'job_out/e_residence_time_arrays_{res}_{t_res}_{Np_str}.h5' \n",
    "\n",
    "Nz=len(data['zh'])\n",
    "Ny=len(data['yh'])\n",
    "Nx=len(data['xh'])\n",
    "yx_array=np.zeros((Ny,Nx))\n",
    "yx_counter=yx_array.copy()                  \n",
    "zx_array=np.zeros((Nz,Nx))\n",
    "zx_counter=zx_array.copy()                  \n",
    "\n",
    "num_jobs=60\n",
    "for job_id in np.arange(1,num_jobs+1):\n",
    "    if np.mod(job_id,20)==0: print(f\"{job_id}/{num_jobs}\")\n",
    "    input_file = dir2+f'job_out/e_residence_time_arrays_{res}_{t_res}_{Np_str}_{job_id}.h5' \n",
    "    with h5py.File(input_file,'r') as f:\n",
    "        yx_array+=f['yx_array']\n",
    "        yx_counter+=f['yx_counter']\n",
    "        zx_array+=f['zx_array']\n",
    "        zx_counter+=f['zx_counter']\n",
    "\n",
    "######################################################\n",
    "#Divide by Counts\n",
    "print('dividing by counts')\n",
    "mask = yx_counter != 0\n",
    "yx_array[mask]/=yx_counter[mask]\n",
    "mask = zx_counter != 0\n",
    "zx_array[mask]/=zx_counter[mask]\n",
    "\n",
    "#Convert to Minutes\n",
    "mins=((data['time'][1]-data['time'][0])/1e9/60).item()\n",
    "yx_array*=mins\n",
    "zx_array*=mins\n",
    "######################################################\n",
    "\n",
    "#SAVING INTO FINAL FORM\n",
    "print('saving')\n",
    "with h5py.File(output_file, 'w') as f:\n",
    "    f.create_dataset('yx_array', data=yx_array, compression=\"gzip\")\n",
    "    f.create_dataset('yx_counter', data=yx_counter, compression=\"gzip\")\n",
    "    f.create_dataset('zx_array', data=zx_array, compression=\"gzip\")\n",
    "    f.create_dataset('zx_counter', data=zx_counter, compression=\"gzip\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ee3401-c0b1-4131-a491-66a346aa2433",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir2=dir+'Project_Algorithms/Entrainment/'\n",
    "output_file = dir2+f'job_out/d_residence_time_arrays_{res}_{t_res}_{Np_str}.h5' \n",
    "\n",
    "Nz=len(data['zh'])\n",
    "Ny=len(data['yh'])\n",
    "Nx=len(data['xh'])\n",
    "yx_array=np.zeros((Ny,Nx))\n",
    "yx_counter=yx_array.copy()                  \n",
    "zx_array=np.zeros((Nz,Nx))\n",
    "zx_counter=zx_array.copy()                  \n",
    "\n",
    "num_jobs=60\n",
    "for job_id in np.arange(1,num_jobs+1):\n",
    "    if np.mod(job_id,20)==0: print(f\"{job_id}/{num_jobs}\")\n",
    "    input_file = dir2+f'job_out/d_residence_time_arrays_{res}_{t_res}_{Np_str}_{job_id}.h5' \n",
    "    with h5py.File(input_file,'r') as f:\n",
    "        yx_array+=f['yx_array']\n",
    "        yx_counter+=f['yx_counter']\n",
    "        zx_array+=f['zx_array']\n",
    "        zx_counter+=f['zx_counter']\n",
    "\n",
    "######################################################\n",
    "#Divide by Counts\n",
    "print('dividing by counts')\n",
    "mask = yx_counter != 0\n",
    "yx_array[mask]/=yx_counter[mask]\n",
    "mask = zx_counter != 0\n",
    "zx_array[mask]/=zx_counter[mask]\n",
    "\n",
    "#Convert to Minutes\n",
    "mins=((data['time'][1]-data['time'][0])/1e9/60).item()\n",
    "yx_array*=mins\n",
    "zx_array*=mins\n",
    "######################################################\n",
    "\n",
    "#SAVING INTO FINAL FORM\n",
    "print('saving')\n",
    "with h5py.File(output_file, 'w') as f:\n",
    "    f.create_dataset('yx_array', data=yx_array, compression=\"gzip\")\n",
    "    f.create_dataset('yx_counter', data=yx_counter, compression=\"gzip\")\n",
    "    f.create_dataset('zx_array', data=zx_array, compression=\"gzip\")\n",
    "    f.create_dataset('zx_counter', data=zx_counter, compression=\"gzip\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104c9629-7e2d-4a67-ab85-64255feffa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "#PLOTTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1de1e2-1ba9-4232-8a7b-5c15c3352254",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = dir2+f'job_out/e_residence_time_arrays_{res}_{t_res}_{Np_str}.h5' \n",
    "with h5py.File(output_file, 'r') as f:\n",
    "    yx_array = f['yx_array'][:]\n",
    "    yx_counter = f['yx_counter'][:]\n",
    "    zx_array = f['zx_array'][:]\n",
    "    zx_counter = f['zx_counter'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a216879-504b-40d1-bf9a-ac2e33f9f263",
   "metadata": {},
   "outputs": [],
   "source": [
    "yx_array[yx_array==0]=np.nan\n",
    "zx_array[zx_array==0]=np.nan\n",
    "\n",
    "fig = plt.figure(figsize=(8*(512/34)/5, 8))\n",
    "gs = gridspec.GridSpec(2, 1)  # 1 row, 2 columns\n",
    "cmap='seismic'\n",
    "levels1=15;levels2=15\n",
    "\n",
    "# First subplot (yx_array contour)\n",
    "ax1 = fig.add_subplot(gs[0, 0])  # First column\n",
    "contour1 = ax1.contourf(yx_array,levels=levels1,cmap=cmap)\n",
    "cbar1 = plt.colorbar(contour1, ax=ax1);cbar1.set_label(\"mins / parcel\")\n",
    "ax1.set_title(\"XY Entrainment Residence Time (Plotted by Entrainment Time)\")\n",
    "\n",
    "# Second subplot (zx_array contour)\n",
    "ax2 = fig.add_subplot(gs[1, 0])  # Second column\n",
    "contour2 = ax2.contourf(zx_array, levels=levels2, cmap=cmap)\n",
    "cbar2 = plt.colorbar(contour2, ax=ax2);cbar2.set_label(\"mins / parcel\")\n",
    "ax2.set_title(\"XZ Entrainment Residence Time (Plotted by Entrainment Time)\")\n",
    "\n",
    "\n",
    "#COASTLINE\n",
    "ocean_fraction=2/8\n",
    "ax1.axvline(yx_array.shape[1]*ocean_fraction,color='green',linewidth=3)\n",
    "ax2.axvline(yx_array.shape[1]*ocean_fraction,color='green',linewidth=3)\n",
    "\n",
    "#THICKEN COLOR LINES\n",
    "\n",
    "for edge in cbar1.ax.collections:  # Loop over individual elements in each list\n",
    "    edge.set_linewidth(10)\n",
    "for edge in cbar2.ax.collections:  # Loop over individual elements in each list\n",
    "    edge.set_linewidth(8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1f333e-a971-46c7-ad29-7824b68cb748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# currently i look for runs of being in cloudy updraft that are at least 5 minutes (1 timestep). i add the total length of that run at the location of initial entrainment/detrainment. then i average to get vertical profile. \n",
    "\n",
    "# For entrainment, particles should stay in a cloud for 30/60 minutes\n",
    "# I’m very surprised by a) the extremely low values for entrainment time and b) the extremely high values for detainment times\n",
    "# another thing: this is only cloudy updrafts, not clouds as well. is that 30/60 minutes true for the “cloud updrafts”?\n",
    "# for detrainment then, there are some parcels that don’t interact with any “cloudy updrafts” for a very long time.\n",
    "# also, if you look at the contour plot we do have higher values than the vertical profile \n",
    "\n",
    "plt.plot(np.nanmean(zx_array[:,:],axis=(1)),data['zh'],label='everywhere')\n",
    "plt.ylabel('z (km)');plt.xlabel('residence time (mins)')\n",
    "\n",
    "\n",
    "# plt.plot(np.nanmean(zx_array[:,int(512/2):512],axis=(1)),data['zh'],label='over land')\n",
    "# plt.ylabel('z (km)');plt.xlabel('preconditioning time (mins)')\n",
    "\n",
    "# plt.plot(np.nanmean(zx_array[:,0:int(512/2)],axis=(1)),data['zh'],label='over ocean')\n",
    "# plt.ylabel('z (km)');plt.xlabel('preconditioning time (mins)')\n",
    "\n",
    "plt.ylim(top=20)\n",
    "plt.title('preconditioning time')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff2ba32-1fea-481a-afa8-eefd6ede9bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = dir2+f'job_out/d_residence_time_arrays_{res}_{t_res}_{Np_str}.h5' \n",
    "with h5py.File(output_file, 'r') as f:\n",
    "    yx_array = f['yx_array'][:]\n",
    "    yx_counter = f['yx_counter'][:]\n",
    "    zx_array = f['zx_array'][:]\n",
    "    zx_counter = f['zx_counter'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a649fb31-0fb5-456f-853b-ebc90b0d7e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "yx_array[yx_array==0]=np.nan\n",
    "zx_array[zx_array==0]=np.nan\n",
    "\n",
    "fig = plt.figure(figsize=(8*(512/34)/5, 8))\n",
    "gs = gridspec.GridSpec(2, 1)  # 1 row, 2 columns\n",
    "cmap='seismic'\n",
    "levels1=15;levels2=15\n",
    "\n",
    "# First subplot (yx_array contour)\n",
    "ax1 = fig.add_subplot(gs[0, 0])  # First column\n",
    "contour1 = ax1.contourf(yx_array,levels=levels1,cmap=cmap)\n",
    "cbar1 = plt.colorbar(contour1, ax=ax1);cbar1.set_label(\"mins / parcel\")\n",
    "ax1.set_title(\"XY Detrainment Residence Time (Plotted by Detrainment Time)\")\n",
    "\n",
    "# Second subplot (zx_array contour)\n",
    "ax2 = fig.add_subplot(gs[1, 0])  # Second column\n",
    "contour2 = ax2.contourf(zx_array, levels=levels2, cmap=cmap)\n",
    "cbar2 = plt.colorbar(contour2, ax=ax2);cbar2.set_label(\"mins / parcel\")\n",
    "ax2.set_title(\"XZ Detrainment Residence Time (Plotted by Detrainment Time)\")\n",
    "\n",
    "\n",
    "#COASTLINE\n",
    "ocean_fraction=2/8\n",
    "ax1.axvline(yx_array.shape[1]*ocean_fraction,color='green',linewidth=3)\n",
    "ax2.axvline(yx_array.shape[1]*ocean_fraction,color='green',linewidth=3)\n",
    "\n",
    "#THICKEN COLOR LINES\n",
    "\n",
    "for edge in cbar1.ax.collections:  # Loop over individual elements in each list\n",
    "    edge.set_linewidth(10)\n",
    "for edge in cbar2.ax.collections:  # Loop over individual elements in each list\n",
    "    edge.set_linewidth(8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6d0137-f81b-4cce-8eef-8737733ce80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# currently i look for runs of being in cloudy updraft that are at least 5 minutes (1 timestep). i add the total length of that run at the location of initial entrainment/detrainment. then i average to get vertical profile. \n",
    "\n",
    "# For entrainment, particles should stay in a cloud for 30/60 minutes\n",
    "# I’m very surprised by a) the extremely low values for entrainment time and b) the extremely high values for detainment times\n",
    "# another thing: this is only cloudy updrafts, not clouds as well. is that 30/60 minutes true for the “cloud updrafts”?\n",
    "# for detrainment then, there are some parcels that don’t interact with any “cloudy updrafts” for a very long time.\n",
    "# also, if you look at the contour plot we do have higher values than the vertical profile \n",
    "\n",
    "plt.plot(np.nanmean(zx_array[:,:],axis=(1)),data['zh'],label='everywhere')\n",
    "plt.ylabel('z (km)');plt.xlabel('nonresidence time (mins)')\n",
    "\n",
    "\n",
    "# plt.plot(np.nanmean(zx_array[:,int(512/2):512],axis=(1)),data['zh'],label='over land')\n",
    "# plt.ylabel('z (km)');plt.xlabel('preconditioning time (mins)')\n",
    "\n",
    "# plt.plot(np.nanmean(zx_array[:,0:int(512/2)],axis=(1)),data['zh'],label='over ocean')\n",
    "# plt.ylabel('z (km)');plt.xlabel('preconditioning time (mins)')\n",
    "\n",
    "plt.ylim(top=20)\n",
    "plt.title('nonresidence time')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcbb952-503b-4712-a1a8-13764fc2657d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTANT FOR PLOTTING\n",
    "\n",
    "# xticks/yticks\n",
    "# xticks = plt.gca().get_xticks()\n",
    "# new_labels = [str(int(tick * 5)) for tick in xticks]\n",
    "# plt.gca().set_xticklabels(new_labels);\n",
    "\n",
    "# cbar-ticks\n",
    "# cbar_ticks = cbar.get_ticks()  # Get the current ticks\n",
    "# new_ticks = [str(int(tick * 5)) for tick in cbar_ticks]  # Modify ticks (multiply by 5 and convert to string)\n",
    "# cbar.set_ticks(cbar_ticks)  # Set the original ticks again to avoid resetting\n",
    "# cbar.set_ticklabels(new_ticks)\n",
    "\n",
    "\n",
    "#imshow\n",
    "# plt.yticks(np.arange(Nz))\n",
    "# new_ytick_labels = np.round(data['zf'].values[:Nz], 2)\n",
    "# plt.gca().set_yticklabels(new_ytick_labels, fontsize=8, rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0facb6e5-9016-4ccb-af5b-1c54db8303c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d46026-6386-4ac8-8c24-e594be9c58e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ab3109-514a-49d5-884f-38723ae7fbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "#OTHER TESTING FOR POSSIBLY ANALYSISES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4664da-80dc-40cd-b1dc-bad97bead02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAKING 2D HISTOGRAM OF RESIDENCE TIME VS Z (COLOR: VARIABLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7774861-7716-4531-96a6-ce083c2cac57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def averaged_profiles(profile): \n",
    "    out_var=profile[ (profile[:, 1] != 0)]; #gets rid of rows that have no data\n",
    "    out_var=np.array([out_var[:, 0] / out_var[:, 1], out_var[:, 2]]).T #divides the data column by the counter column\n",
    "    return out_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb08040-9920-4e93-8d7c-887eb97faf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=[]\n",
    "for p in np.arange(Np):\n",
    "    out=residence_times(p,type='e',updraft_type='cloudy')\n",
    "    if np.any(out)==True:\n",
    "        lens=out[0]\n",
    "        lst.append(lens)\n",
    "print(f'max entrainment time: {max(arr.max() for arr in lst)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feef2197-982f-4891-b9fd-c776d6036c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nz=len(data['zh'])\n",
    "profile=np.zeros((Nz,18)); #residence time by Z levels\n",
    "counter=np.zeros_like(profile)\n",
    "\n",
    "Np=125000-1\n",
    "for p in np.arange(Np):\n",
    "    out=residence_times(p,type='e',updraft_type='cloudy')\n",
    "    if np.any(out)==True:\n",
    "        lens=out[0]\n",
    "        # print(lens)\n",
    "        \n",
    "        ts=out[1]\n",
    "        zs=out[2]\n",
    "        ys=out[3]\n",
    "        xs=out[4]\n",
    "\n",
    "        for ind,(z,l) in enumerate(zip(zs,lens)):\n",
    "            profile[z,l]+=1\n",
    "\n",
    "# #NORMALIZATION\n",
    "row_averages = np.nansum(profile, axis=1)\n",
    "mask = row_averages!=0\n",
    "profile[mask] /= row_averages[mask,np.newaxis]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ecaac8-4d07-4e7d-af0c-546bdca32fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one=profile.copy()\n",
    "two=profile.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98cd31b-4af3-47f8-9007-70d02a604360",
   "metadata": {},
   "outputs": [],
   "source": [
    "residence_profile=profile.copy() #save for comparing with TKE later\n",
    "\n",
    "\n",
    "#Nan out zeros\n",
    "cmap='plasma'\n",
    "profile2=profile.copy()\n",
    "profile2[profile2==0]=np.nan\n",
    "\n",
    "\n",
    "#PLOTTING\n",
    "# plt.imshow(profile.T);plt.gca().invert_yaxis()\n",
    "plt.contourf(profile2*100,cmap=cmap,levels=50)\n",
    "\n",
    "cbar=plt.colorbar(label='normalized count (%)')\n",
    "plt.ylabel('z (km)');plt.xlabel('total entrainment residence time (mins)')\n",
    "plt.title('Entrainment Count')\n",
    "\n",
    "#FIXING TICKS\n",
    "\n",
    "plt.yticks(np.arange(Nz));\n",
    "new_ytick_labels = np.round(data['zf'].values[:Nz], 2);\n",
    "plt.gca().set_yticklabels(new_ytick_labels, fontsize=8, rotation=0);\n",
    "\n",
    "xticks = plt.gca().get_xticks()\n",
    "new_labels = [str(int(tick * 5)) for tick in xticks]\n",
    "plt.gca().set_xticklabels(new_labels);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44ea838-0643-4004-8f1a-680ea88efa8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts\n",
    "for ind,(z,l) in enumerate(zip(zs,lens)):\n",
    "    print(ind,z,l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea82606-94d0-49e4-b788-55d1f13a0b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loading Important Variables\n",
    "# ##############\n",
    "# if 'emptylike' not in globals():\n",
    "#     print('loading neccessary variables')\n",
    "#     variable='w'; w_data=data[variable] #get w data\n",
    "#     w_data=w_data.interp(zf=data['zh']).data #interpolation w data z coordinate from zh to zf\n",
    "#     variable='qv'; qv_data=data[variable].data # get qc data\n",
    "#     variable='qc'; qc_data=data[variable].data # get qc data\n",
    "#     variable='qi'; qi_data=data[variable].data # get qc data\n",
    "#     qc_plus_qi=qc_data+qi_data\n",
    "#     buoyancy_data=data['buoyancy'].data\n",
    "\n",
    "#     import h5py\n",
    "#     with h5py.File(dir + 'Variable_Calculation/' + 'theta_e'+f'_{res}_{t_res}'+'.h5', 'r') as f:\n",
    "#         theta_e_data = f['theta_e'][:]\n",
    "    \n",
    "#     print('done')\n",
    "#     empty_like=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a805137a-73da-4ebb-88d4-58abf5a2ade6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def call_variables(t): \n",
    "#     if np.mod(t,25)==0: print(f'loading variables for time {t}')\n",
    "#     variable='w'; w_data=data[variable].isel(time=t).interp(zf=data['zh']).data #get w_data and interpolation w data z coordinate from zh to zf\n",
    "#     variable='qv'; qv_data=data[variable].isel(time=t).data # get qc data\n",
    "#     variable='qc'; qc_data=data[variable].isel(time=t).data # get qc data\n",
    "#     variable='qi'; qi_data=data[variable].isel(time=t).data # get qc data\n",
    "#     qc_plus_qi=qc_data+qi_data\n",
    "#     variable='th'; th_data=data[variable].isel(time=t).data # get qc data\n",
    "#     variable='buoyancy'; buoyancy_data=data[variable].isel(time=t).data # get qc data\n",
    "    \n",
    "#     import h5py\n",
    "#     with h5py.File(dir + 'Variable_Calculation/' + 'theta_e'+f'_{res}_{t_res}'+'.h5', 'r') as f:\n",
    "#         theta_e_data = f['theta_e'][t]\n",
    "        \n",
    "#     if np.mod(t,25)==0:print(f'done loading')\n",
    "\n",
    "#     return w_data,qv_data,qc_data,qi_data,qc_plus_qi,th_data,buoyancy_data,theta_e_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7b24d5-5b64-48b7-84c1-c3259720f739",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nz=len(data['zh'])\n",
    "profile=np.zeros((Nz,18)); #residence time by Z levels\n",
    "counter=np.zeros_like(profile)\n",
    "\n",
    "Np=125000-1\n",
    "for p in np.arange(Np):\n",
    "    out=residence_times(p,type='e',updraft_type='cloudy')\n",
    "    if np.any(out)==True:\n",
    "        lens=out[0]\n",
    "        # print(lens)\n",
    "        \n",
    "        ts=out[1]\n",
    "        zs=out[2]\n",
    "        ys=out[3]\n",
    "        xs=out[4]\n",
    "\n",
    "        \n",
    "        for ind,(z,l) in enumerate(zip(zs,lens)): \n",
    "            profile[z,l]+=w_data[ts[ind],zs[ind],ys[ind],xs[ind]] #USE IF LOADING IN FULL VARIABLE\n",
    "            # t=ts[ind];variable='w'; w_data=data[variable].isel(time=t).interp(zf=data['zh']).data #get w_data and interpolation w data z coordinate from zh to zf #THIS IS WAY TOO SLOW\n",
    "            # profile[z,l]+=w_data[zs[ind],ys[ind],xs[ind]]\n",
    "            counter[z,l]+=1\n",
    "\n",
    "#averaging by number of parcel\n",
    "mask=profile!=0\n",
    "profile[mask]/=counter[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edbb097-cb74-467a-9a65-1b65eca4c690",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap='plasma'\n",
    "profile[profile==0]=np.nan\n",
    "plt.contourf(profile,cmap=cmap,levels=50)\n",
    "plt.colorbar(label='w (m/s) per parcel')\n",
    "plt.xlabel('total entrainment residence time (mins)');plt.ylabel('z (km)')\n",
    "plt.title('Entrained W Profile')\n",
    "\n",
    "xticks = plt.gca().get_xticks()\n",
    "new_labels = [str(int(tick * 5)) for tick in xticks]\n",
    "plt.gca().set_xticklabels(new_labels);\n",
    "\n",
    "\n",
    "plt.yticks(np.arange(Nz));\n",
    "new_ytick_labels = np.round(data['zf'].values[:Nz], 2);\n",
    "plt.gca().set_yticklabels(new_ytick_labels, fontsize=8, rotation=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ffbe1f-9579-451d-8ca1-803952631d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nz=len(data['zh'])\n",
    "profile=np.zeros((Nz,18)); #residence time by Z levels\n",
    "counter=np.zeros_like(profile)\n",
    "\n",
    "Np=125000-1\n",
    "for p in np.arange(Np):\n",
    "    out=residence_times(p,type='e',updraft_type='cloudy')\n",
    "    if np.any(out)==True:\n",
    "        lens=out[0]\n",
    "        # print(lens)\n",
    "        \n",
    "        ts=out[1]\n",
    "        zs=out[2]\n",
    "        ys=out[3]\n",
    "        xs=out[4]\n",
    "\n",
    "        \n",
    "        for ind,(z,l) in enumerate(zip(zs,lens)):\n",
    "            profile[z,l]+=theta_e_data[ts[ind],zs[ind],ys[ind],xs[ind]] #USE IF LOADING IN FULL VARIABLE\n",
    "            # t=ts[ind];import h5py #     with h5py.File(dir + 'Variable_Calculation/' + 'theta_e'+f'_{res}_{t_res}'+'.h5', 'r') as f: #         theta_e_data = f['theta_e'][t] #THIS IS WAY TOO SLOW\n",
    "            # profile[z,l]+=theta_e_data[zs[ind],ys[ind],xs[ind]]\n",
    "            counter[z,l]+=1\n",
    "\n",
    "#averaging by number of parcel\n",
    "mask=profile!=0\n",
    "profile[mask]/=counter[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2567d02-5414-4294-b110-de66134ef919",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap='viridis'\n",
    "profile[profile==0]=np.nan\n",
    "\n",
    "plt.contourf(profile,cmap=cmap,levels=50)#,vmin=200)\n",
    "plt.colorbar(label='theta_e (K) per parcel')\n",
    "plt.xlabel('total entrainment residence time (mins)');plt.ylabel('z (km)')\n",
    "plt.title(r'Entrained $\\theta_e$ Profile')\n",
    "\n",
    "xticks = plt.gca().get_xticks()\n",
    "new_labels = [str(int(tick * 5)) for tick in xticks]\n",
    "plt.gca().set_xticklabels(new_labels);\n",
    "\n",
    "plt.yticks(np.arange(Nz));\n",
    "new_ytick_labels = np.round(data['zf'].values[:Nz], 2);\n",
    "plt.gca().set_yticklabels(new_ytick_labels, fontsize=8, rotation=0);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ff3826-ee75-47d2-b108-11686e40a0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Some Data\n",
    "tke_data=data['tke'].interp(zf=data['zh']).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c963c03a-b369-4793-8f1b-7ae3fd1e0905",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nz=len(data['zh'])\n",
    "profile=np.zeros((Nz,18)); #residence time by Z levels\n",
    "counter=np.zeros_like(profile)\n",
    "\n",
    "Np=125000-1\n",
    "for p in np.arange(Np):\n",
    "    out=residence_times(p,type='e',updraft_type='cloudy')\n",
    "    if np.any(out)==True:\n",
    "        lens=out[0]\n",
    "        # print(lens)\n",
    "        \n",
    "        ts=out[1]\n",
    "        zs=out[2]\n",
    "        ys=out[3]\n",
    "        xs=out[4]\n",
    "\n",
    "        \n",
    "        for ind,(z,l) in enumerate(zip(zs,lens)):\n",
    "            profile[z,l]+=tke_data[ts[ind],zs[ind],ys[ind],xs[ind]] #USE IF LOADING IN FULL VARIABLE\n",
    "            # t=ts[ind];tke_data=data['tke'].isel(time=t).interp(zf=data['zh']).data\n",
    "            # profile[z,l]+=tke_data[zs[ind],ys[ind],xs[ind]]\n",
    "            counter[z,l]+=1\n",
    "\n",
    "#averaging by number of parcel\n",
    "mask=profile!=0\n",
    "profile[mask]/=counter[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de93dc66-8c56-46bf-b713-9e6c8d6a6c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "TKE_profile=profile.copy()\n",
    "\n",
    "cmap='plasma'\n",
    "profile[profile==0]=np.nan\n",
    "\n",
    "plt.contourf(profile,cmap=cmap, levels=50)\n",
    "plt.colorbar(label=r'TKE ($m^2/s^2$) per parcel')\n",
    "plt.xlabel('total entrainment residence time (mins)');plt.ylabel('z (km)')\n",
    "plt.title('Entrained TKE Profile')\n",
    "\n",
    "xticks = plt.gca().get_xticks()\n",
    "new_labels = [str(int(tick * 5)) for tick in xticks]\n",
    "plt.gca().set_xticklabels(new_labels);\n",
    "\n",
    "plt.yticks(np.arange(Nz));\n",
    "new_ytick_labels = np.round(data['zf'].values[:Nz], 2);\n",
    "plt.gca().set_yticklabels(new_ytick_labels, fontsize=8, rotation=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533d2174-898c-42af-a00f-ea3648bb7cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TESTING TESTING TESTING\n",
    "\n",
    "\n",
    "TKE_norm = (TKE_profile - np.min(TKE_profile)) / (np.max(TKE_profile) - np.min(TKE_profile))\n",
    "residence_norm = (residence_profile - np.min(residence_profile)) / (np.max(residence_profile) - np.min(residence_profile))\n",
    "\n",
    "compare_array = (1-TKE_norm) - (1-residence_norm)\n",
    "\n",
    "\n",
    "\n",
    "plt.contourf(compare_array)\n",
    "plt.colorbar(label='Difference of Norms')\n",
    "plt.xlabel('total entrainment residence time (mins)');plt.ylabel('z (km)')\n",
    "plt.title('Entrainment Compared with Entrained TKE Profile')\n",
    "\n",
    "####\n",
    "\n",
    "xticks = plt.gca().get_xticks()\n",
    "new_labels = [str(int(tick * 5)) for tick in xticks]\n",
    "plt.gca().set_xticklabels(new_labels);\n",
    "\n",
    "plt.yticks(np.arange(Nz));\n",
    "new_ytick_labels = np.round(data['zf'].values[:Nz], 2);\n",
    "plt.gca().set_yticklabels(new_ytick_labels, fontsize=8, rotation=0);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
