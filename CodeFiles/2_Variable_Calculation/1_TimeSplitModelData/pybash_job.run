#!/bin/bash
#SBATCH --job-name=python
#SBATCH --array=1-100 #%+number after to limit number of of runs at a time
##SBATCH --account=torri
##SBATCH --partition=torri

#SBATCH --partition=shared

#SBATCH --time=0-00:30:00
##SBATCH --ntasks=1
#SBATCH --nodes=1 
#SBATCH  --tasks-per-node=1  
#SBATCH --cpus-per-task=1 #Each node has 47 CPUs
#SBATCH --mem=10G #GBTotal 180GB per node (180G/30 = 6G) #0 for full node memory

##SBATCH --constraint=“ib_hdr” # will allow a mix of HDR200 and HDR100 nodes
##SBATCH --constraint=“ib_hdr100” # explicitly only allow HDR100 nodes
##SBATCH --distribution=“*:*:*” # Set the distribution to defaults if doing sbatch from interactive session

#SBATCH --error=pybash_job-%A.err
#SBATCH --output=pybash_job-%A.out
## Remote notification
#SBATCH --mail-type=BEGIN,END,FAIL,REQUEUE,TIME_LIMIT_80
#SBATCH --mail-user=air673@hawaii.edu

mkdir -p job_out
#exec >> "job_out/py-$SLURM_ARRAY_TASK_ID.out" 2>&1 #don't use if you are piping to .out file below

#LOADING MODULES
module purge
module load lang/Anaconda3
source activate work #personal python custom environment

#PYTHON SETTINGS
export HDF5_USE_FILE_LOCKING=FALSE #disable HDF5 file locking
export PYTHONUNBUFFERED=TRUE #allows print statements during run

# --- RUNNING PYTHON ---

mkdir -p job_out/TimeSplitModelData

#jupyter nbconvert --to script TimeSplitModelData.ipynb 
#not good for job arrays, just do manually

python -u TimeSplitModelData.py $SLURM_ARRAY_TASK_ID \
    > job_out/TimeSplitModelData/py-${SLURM_ARRAY_TASK_ID}.out 2>&1
