{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09d2900e-621d-4803-b3cd-aa766b7f5c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #How to Import to Code Document\n",
    "# import sys\n",
    "# path=os.path.join(mainCodeDirectory,'Functions/')\n",
    "# sys.path.append(path)\n",
    "\n",
    "# import NumericalFunctions\n",
    "# from NumericalFunctions import * # import NumericalFunctions \n",
    "\n",
    "# # # Get all functions in NumericalFunctions\n",
    "# # import inspect\n",
    "# # functions = [f[0] for f in inspect.getmembers(NumericalFunctions, inspect.isfunction)]\n",
    "# # functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ac2029-399a-4e3d-b3b5-4d062cb082a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTING NECESSARY LIBRARIES\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ecd5b9-6ff7-4d50-a320-37a971075dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INITIALIZE DATA FUNCTION\n",
    "###############################################################\n",
    "def initiate_array_2D(out_file,vars,t_chunk_size,z_chunk_size,t_size=None,z_size=None):\n",
    "    # Define array dimensions (adjust based on your data)\n",
    "\n",
    "    if t_size==None:\n",
    "        t_size = len(data['time'])  # Number of timesteps\n",
    "    if z_size==None:\n",
    "        z_size = len(data['zh'])    # Number of vertical levels\n",
    "    \n",
    "    with h5py.File(out_file, 'w') as f: \n",
    "        # Check if the dataset 'theta_e' already exists\n",
    "        for var_name in vars:\n",
    "            if var_name not in f:\n",
    "                # Create a dataset with the full size for all time steps (initially empty)\n",
    "                f.create_dataset(var_name, \n",
    "                                 (t_size, z_size),  # Full size for all timesteps\n",
    "                                 chunks=(t_chunk_size, z_chunk_size))  # Chunks for time axis to allow resizing\n",
    "\n",
    "#INITIALIZE DATA FUNCTION\n",
    "###############################################################\n",
    "def initiate_array_4D(out_file,vars,t_chunk_size,z_chunk_size,y_chunk_size,x_chunk_size,t_size=None,z_size=None,y_size=None,x_size=None):\n",
    "    # Define array dimensions (adjust based on your data)\n",
    "\n",
    "    if t_size==None:\n",
    "        t_size = len(data['time'])  # Number of timesteps\n",
    "    if z_size==None:\n",
    "        z_size = len(data['zh'])    # Number of vertical levels\n",
    "    if y_size==None:\n",
    "        y_size = len(data['yh'])    # Number of vertical levels\n",
    "    if x_size==None:\n",
    "        x_size = len(data['xh'])    # Number of vertical levels\n",
    "    \n",
    "    with h5py.File(out_file, 'w') as f: \n",
    "        # Check if the dataset 'theta_e' already exists\n",
    "        for var_name in vars:\n",
    "            if var_name not in f:\n",
    "                # Create a dataset with the full size for all time steps (initially empty)\n",
    "                f.create_dataset(var_name, \n",
    "                                 (t_size, z_size, y_size, x_size),  # Full size for all timesteps\n",
    "                                 chunks=(t_chunk_size, z_chunk_size, y_chunk_size, x_chunk_size))  # Chunks for time axis to allow resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65b7022b-5dab-4bc6-ada6-d7c17138e0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ddt(f,dt):\n",
    "    # dt=(data['time'][1]-data['time'][0]).item()/1e9\n",
    "    _ddt=np.zeros_like(f)\n",
    "    _ddt[1:-1] = (f[2:] - f[:-2]) / (dt)\n",
    "    return _ddt\n",
    "\n",
    "def Ddz_1D(f,dz):  \n",
    "    _ddz=np.zeros_like(f)\n",
    "    _ddz[:, 1:-1] = (f[:, 2:] - f[:, :-2]) / (2 * dz)\n",
    "    _ddz[:, 0] = (f[:, 1] - f[:, 0]) / dz  # Forward difference \n",
    "    _ddz[:, -1] = (f[:, -1] - f[:, -2]) / dz  # Backward difference \n",
    "    return _ddz\n",
    "\n",
    "def Ddz_1DStretch(f,data):\n",
    "    #f must be interpolated to cell centers\n",
    "    dz=np.diff(data['zf'].values)\n",
    "    \n",
    "    ddz=np.zeros_like(f)\n",
    "    ddz[1:-1] = (f[2:] - f[:-2]) / (2 * dz[1:-1])\n",
    "    ddz[0] = (f[1] - f[0]) / dz[0]  # Forward difference \n",
    "    ddz[-1] = (f[-1] - f[-2]) / dz[-1]  # Backward difference \n",
    "    return ddz\n",
    "\n",
    "##################################################################\n",
    "\n",
    "def Profile_Ddz(profile):\n",
    "    #f must be interpolated to cell centers\n",
    "    dz=np.diff(profile[:,1])\n",
    "\n",
    "    f=profile[:,0]\n",
    "    ddz=np.zeros_like(f)\n",
    "    denom=dz[1:] + dz[:-1]\n",
    "    ddz[1:-1] = (f[2:] - f[:-2]) / (2 * denom)\n",
    "    ddz[0] = (f[1] - f[0]) / dz[0]  # Forward difference \n",
    "    ddz[-1] = (f[-1] - f[-2]) / dz[-1]  # Backward difference \n",
    "    return np.column_stack([ddz, profile[:,1]])\n",
    "\n",
    "##################################################################\n",
    "\n",
    "def Ddz_4DStretch(f,data):\n",
    "    #f must be interpolated to cell centers\n",
    "    dz=np.diff(data['zf'].values)\n",
    "    dz=dz.copy()[np.newaxis, :, np.newaxis, np.newaxis]\n",
    "    \n",
    "    ddz=np.zeros_like(f)\n",
    "    ddz[:, 1:-1] = (f[:, 2:] - f[:, :-2]) / (2 * dz[:, 1:-1])\n",
    "    ddz[:, 0] = (f[:, 1] - f[:, 0]) / dz[:, 0]  # Forward difference \n",
    "    ddz[:, -1] = (f[:, -1] - f[:, -2]) / dz[:, -1]  # Backward difference \n",
    "    return ddz\n",
    "\n",
    "def Ddy_4D(f,dy):   \n",
    "    _ddy=np.zeros_like(f)\n",
    "    _ddy[:, :, 1:-1] = (f[:, :, 2:] - f[:, :, :-2]) / (2 * dy)\n",
    "    _ddy[:, :, 0] = (f[:, :, 1] - f[:, :, 0]) / dy  # Forward difference \n",
    "    _ddy[:, :, -1] = (f[:, :, -1] - f[:, :, -2]) / dy  # Backward difference \n",
    "    return _ddy\n",
    "\n",
    "def Ddx_4D(f,dx): \n",
    "    _ddx=np.zeros_like(f)\n",
    "    _ddx[:, :, :, 1:-1] = (f[:, :, :, 2:] - f[:, :, :, :-2]) / (2 * dx)\n",
    "    _ddx[:, :, :, 0] = (f[:, :, :, 1] - f[:, :, :, 0]) / dx  # Forward difference \n",
    "    _ddx[:, :, :, -1] = (f[:, :, :, -1] - f[:, :, :, -2]) / dx  # Backward difference \n",
    "    return _ddx\n",
    "\n",
    "##############################\n",
    "\n",
    "def Ddz_3D(f,dz): \n",
    "    _ddz=np.zeros_like(f)\n",
    "    _ddz[1:-1] = (f[2:] - f[:-2]) / (2 * dz)\n",
    "    _ddz[0] = (f[1] - f[0]) / dz  # Forward difference \n",
    "    _ddz[-1] = (f[-1] - f[-2]) / dz  # Backward difference \n",
    "    return _ddz\n",
    "\n",
    "def Ddz_3DStretch(f,data):\n",
    "    #f must be interpolated to cell centers\n",
    "    dz=np.diff(data['zf'].values)\n",
    "    dz=dz.copy()[:, np.newaxis, np.newaxis]\n",
    "    \n",
    "    ddz=np.zeros_like(f)\n",
    "    ddz[1:-1] = (f[2:] - f[:-2]) / (2 * dz[1:-1])\n",
    "    ddz[0] = (f[1] - f[0]) / dz[0]  # Forward difference \n",
    "    ddz[-1] = (f[-1] - f[-2]) / dz[-1]  # Backward difference \n",
    "    return ddz\n",
    "\n",
    "def Ddy_3D(f,dy):   \n",
    "    _ddy=np.zeros_like(f)\n",
    "    _ddy[:, 1:-1] = (f[:, 2:] - f[:, :-2]) / (2 * dy)\n",
    "    _ddy[:, 0] = (f[:, 1] - f[:, 0]) / dy  # Forward difference \n",
    "    _ddy[:, -1] = (f[:, -1] - f[:, -2]) / dy  # Backward difference \n",
    "    return _ddy\n",
    "\n",
    "def Ddx_3D(f,dx): \n",
    "    _ddx=np.zeros_like(f)\n",
    "    _ddx[:, :, 1:-1] = (f[:, :, 2:] - f[:, :, :-2]) / (2 * dx)\n",
    "    _ddx[:, :, 0] = (f[:, :, 1] - f[:, :, 0]) / dx  # Forward difference \n",
    "    _ddx[:, :, -1] = (f[:, :, -1] - f[:, :, -2]) / dx  # Backward difference \n",
    "    return _ddx\n",
    "\n",
    "def DivergenceHoriz(f,dx,dy):\n",
    "    out=Ddy(f,dy)+Ddx(f,dx)\n",
    "    return out\n",
    "\n",
    "def Divergence3D(f,dx,dy,dz):\n",
    "    out=Ddz(f,dz)+Ddy(f,dy)+Ddx(f,dx)\n",
    "    return out\n",
    "\n",
    "def Divergence3DStretch(f,dx,dy):\n",
    "    out=DdzStretch(f)+Ddy(f,dy)+Ddx(f,dx)\n",
    "    return out\n",
    "\n",
    "def LaplacianHoriz(f,dx,dy):\n",
    "    # Initialize the second derivatives arrays with zeros, same shape as f\n",
    "    d2f_dx2 = np.zeros_like(f)\n",
    "    d2f_dy2 = np.zeros_like(f)\n",
    "    \n",
    "    # Second derivatives using central differences\n",
    "    d2f_dx2[:, :, 1:-1, :] = (f[:, :, :-2, :] - 2 * f[:, :, 1:-1, :] + f[:, :, 2:, :]) / dx**2\n",
    "    d2f_dy2[:, :, :, 1:-1] = (f[:, :, :, :-2] - 2 * f[:, :, :, 1:-1] + f[:, :, :, 2:]) / dy**2\n",
    "    \n",
    "    # Combine to reconstruct the Laplacian (RHS)\n",
    "    out = d2f_dx2 + d2f_dy2\n",
    "    return out\n",
    "\n",
    "def Laplacian3D(f, dx, dy, dz):\n",
    "\n",
    "    #f must be provided at a specific \n",
    "    \n",
    "    # Initialize the second derivatives arrays with zeros, same shape as f\n",
    "    d2f_dz2 = np.zeros_like(f)\n",
    "    d2f_dy2 = np.zeros_like(f)\n",
    "    d2f_dx2 = np.zeros_like(f)\n",
    "    \n",
    "    # Second derivatives using central differences\n",
    "    d2f_dz2[:, 1:-1, :, :] = (f[:, :-2, :, :] - 2 * f[:, 1:-1, :, :] + f[:, 2:, :, :]) / dz**2\n",
    "    d2f_dy2[:, :, 1:-1, :] = (f[:, :, :-2, :] - 2 * f[:, :, 1:-1, :] + f[:, :, 2:, :]) / dy**2\n",
    "    d2f_dx2[:, :, :, 1:-1] = (f[:, :, :, :-2] - 2 * f[:, :, :, 1:-1] + f[:, :, :, 2:]) / dx**2\n",
    "    \n",
    "    # Combine to reconstruct the Laplacian (RHS)\n",
    "    out = d2f_dx2 + d2f_dy2 + d2f_dz2\n",
    "    return out\n",
    "\n",
    "def Laplacian3DStretch(f, dx, dy):\n",
    "    # Initialize the second derivatives arrays with zeros, same shape as f\n",
    "    #f must be interpolated to cell centers\n",
    "    #f must be an array array with f for face and h for center (e.g. zf/zh)\n",
    "    dz=np.diff(data['zf'].values)\n",
    "    dz=dz.copy()[np.newaxis, :, np.newaxis, np.newaxis]\n",
    "    \n",
    "    # Initialize the second derivatives arrays with zeros, same shape as f\n",
    "    d2f_dz2 = np.zeros_like(f)\n",
    "    d2f_dy2 = np.zeros_like(f)\n",
    "    d2f_dx2 = np.zeros_like(f)\n",
    "    \n",
    "    # Second derivatives using central differences\n",
    "    d2f_dz2[:, 1:-1, :, :] = (f[:, :-2, :, :] - 2 * f[:, 1:-1, :, :] + f[:, 2:, :, :]) / dz[:,1:-1]**2\n",
    "    d2f_dy2[:, :, 1:-1, :] = (f[:, :, :-2, :] - 2 * f[:, :, 1:-1, :] + f[:, :, 2:, :]) / dy**2\n",
    "    d2f_dx2[:, :, :, 1:-1] = (f[:, :, :, :-2] - 2 * f[:, :, :, 1:-1] + f[:, :, :, 2:]) / dx**2\n",
    "    \n",
    "    # Combine to reconstruct the Laplacian (RHS)\n",
    "    out = d2f_dx2 + d2f_dy2 + d2f_dz2\n",
    "    return out\n",
    "\n",
    "# #TESTING\n",
    "# ######################################\n",
    "# import numpy as np\n",
    "# f = np.random.random((4, 4, 4, 4))\n",
    "# Ddt(f,1)\n",
    "# Ddz(f,1)\n",
    "# Ddy(f,1)\n",
    "# Ddx(f,1)\n",
    "# DivergenceHoriz(f,1,1)\n",
    "# Divergence3D(f,1,1,1)\n",
    "\n",
    "# HorizLaplacian(f,1,1)\n",
    "# Laplacian3D(f,1,1,1)\n",
    "\n",
    "# import xarray as xr\n",
    "# dir='/mnt/lustre/koa/koastore/torri_group/air_directory/'\n",
    "# data=xr.open_dataset(dir+'/cm1r20.3/run/cm1out_test7tundra-7_062217.nc') #***\n",
    "# f=data['w'].interp(zf=data['zh']).data\n",
    "# DdzStretch(f)\n",
    "# Divergence3DStretch(f,1,1)\n",
    "# Laplacian3DStretch(f,1,1)\n",
    "\n",
    "# u=data['u'].interp(xf=data['xh']).data; dx=1000\n",
    "# v=data['v'].interp(yf=data['yh']).data; dy=1000\n",
    "# conv=-(Ddx(u,dx)+Ddy(v,dy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df94e4c-1079-4154-bed7-67c6cf37c747",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Averaging and Slicing Functions\n",
    "def HorizAvg_zt(f): \n",
    "    out=np.mean(f, axis=(2,3)) #takes horizontal average leaving f(t,z)\n",
    "    return out\n",
    "def VertProfile_z(f): \n",
    "    out=np.mean(f, axis=(0,2,3)) #takes horizontal + time average leaving f(z)\n",
    "    return out\n",
    "def HorizProfile_txy(f): \n",
    "    out=np.mean(f, axis=(1)) #takes horizontal + time average leaving f(z)\n",
    "    return out    \n",
    "def Slice(type,f,ind):\n",
    "    if type=='t':\n",
    "        out=f[ind]\n",
    "    if type=='z':\n",
    "        out=f[:,ind]\n",
    "    if type=='y':\n",
    "        out=f[:, :, ind]\n",
    "    if type=='x':\n",
    "        out=f[:, :, :, ind]\n",
    "    return out\n",
    "    \n",
    "# #TESTING\n",
    "# ######################################\n",
    "# import numpy as np\n",
    "# f = np.random.random((4, 4, 4, 4))\n",
    "# HorizAvg_zt(f)\n",
    "# VertProfile_z(f)\n",
    "# HorizProfile_txy(f)\n",
    "# Slice('t',f,2)\n",
    "# Slice('z',f,2)\n",
    "# Slice('y',f,2)\n",
    "# Slice('x',f,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "22c8a7f7-413b-4dc0-9c98-4bf9c78d152c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ultimate_AreaAverage(data, dims, avg_over):\n",
    "    \"\"\"\n",
    "    Average a NumPy array over selected dimensions by name.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : np.ndarray\n",
    "        Input array (2D–4D).\n",
    "    dims : tuple of str\n",
    "        Names of each axis in order of data.shape, e.g. ('t','z','y','x').\n",
    "    avg_over : tuple of str\n",
    "        Dimensions to average over, e.g. ('z',) or ('z','y','x').\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out : np.ndarray\n",
    "        Array averaged over the specified axes.\n",
    "    out_dims : tuple of str\n",
    "        Remaining dimensions after averaging.\n",
    "    \"\"\"\n",
    "    # Map dimension names to axis indices\n",
    "    axes = [dims.index(d) for d in avg_over]\n",
    "\n",
    "    # String of Remaining dimensions\n",
    "    out_dims = tuple(d for d in dims if d not in avg_over)\n",
    "\n",
    "    # Take Area Average\n",
    "    out = np.mean(data, axis=tuple(axes))\n",
    "    \n",
    "    return out, out_dimshow \n",
    "\n",
    "\n",
    "# # #TESTING \n",
    "# # ######################################\n",
    "# import numpy as np\n",
    "# arr4d = np.random.rand(10, 11, 12, 13)  # shape (t,z,y,x)\n",
    "# arr3d = np.random.rand(11, 12, 13)  # shape (z,y,x)\n",
    "# arr2d = np.random.rand(12, 13)  # shape (y,x)\n",
    "\n",
    "# # Time series (avg over z,y,x)\n",
    "# out, dims = Ultimate_AreaAverage(arr4d, dims=('t','z','y','x'), avg_over=('z','y','x'))\n",
    "# print(out.shape, dims, '\\n')   \n",
    "# out, dims = Ultimate_AreaAverage(arr4d, dims=('t','z','y','x'), avg_over=('y','x'))\n",
    "# print(out.shape, dims, '\\n')   \n",
    "# out, dims = Ultimate_AreaAverage(arr4d, dims=('t','z','y','x'), avg_over=('y'))\n",
    "# print(out.shape, dims, '\\n')  \n",
    "\n",
    "# print('------','\\n')\n",
    "\n",
    "# out, dims = Ultimate_AreaAverage(arr3d, dims=('z','y','x'), avg_over=('y','x'))\n",
    "\n",
    "# print(out.shape, dims, '\\n')   \n",
    "\n",
    "# out, dims = Ultimate_AreaAverage(arr3d, dims=('z','y','x'), avg_over=('x'))\n",
    "# print(out.shape, dims, '\\n')  \n",
    "\n",
    "# print('------','\\n')\n",
    "\n",
    "# out, dims = Ultimate_AreaAverage(arr2d, dims=('y','x'), avg_over=('x'))\n",
    "# print(out.shape, dims, '\\n')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ede30c-f495-48ba-8ad0-3df77bc9151e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3097dba-2984-49ac-a5a1-c85bb03c85cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 objects with highest memory usage\n",
      "{'open': '0.0 MB', 'check_memory': '0.0 MB'}\n",
      "\n",
      "0.0 GB in use overall\n"
     ]
    }
   ],
   "source": [
    "# def check_memory():\n",
    "#     ipython_vars = [\"In\", \"Out\", \"exit\", \"quit\", \"get_ipython\", \"ipython_vars\"]\n",
    "#     print(\"Top 10 objects with highest memory usage\")\n",
    "#     # Get a sorted list of the objects and their sizes\n",
    "#     mem = {\n",
    "#         key: round(value/1e6,2)\n",
    "#         for key, value in sorted(\n",
    "#             [\n",
    "#                 (x, sys.getsizeof(globals().get(x)))\n",
    "#                 for x in globals()\n",
    "#                 if not x.startswith(\"_\") and x not in sys.modules and x not in ipython_vars\n",
    "#             ],\n",
    "#             key=lambda x: x[1],\n",
    "#             reverse=True)[:10]\n",
    "#     }\n",
    "#     print({key:f\"{value} MB\" for key,value in mem.items()})\n",
    "#     print(f\"\\n{round(sum(mem.values()),2)/1000} GB in use overall\")\n",
    "\n",
    "# check_memory()\n",
    "\n",
    "def check_memory(namespace):\n",
    "    ipython_vars = [\"In\", \"Out\", \"exit\", \"quit\", \"get_ipython\", \"ipython_vars\"]\n",
    "    print(\"Top 10 objects with highest memory usage\")\n",
    "    # Get a sorted list of the objects and their sizes\n",
    "    mem = {\n",
    "        key: round(value/1e6, 2)\n",
    "        for key, value in sorted(\n",
    "            [\n",
    "                (x, sys.getsizeof(namespace.get(x)))\n",
    "                for x in namespace\n",
    "                if not x.startswith(\"_\") and x not in sys.modules and x not in ipython_vars\n",
    "            ],\n",
    "            key=lambda x: x[1],\n",
    "            reverse=True)[:10]\n",
    "    }\n",
    "    print({key: f\"{value} MB\" for key, value in mem.items()})\n",
    "    print(f\"\\n{round(sum(mem.values()), 2)/1000} GB in use overall\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
