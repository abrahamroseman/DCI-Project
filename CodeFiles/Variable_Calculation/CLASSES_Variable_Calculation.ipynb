{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62c8198c-65fe-412a-bbb9-4f1ef3c22b59",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ModelData_Class\n",
    "# ============================================================\n",
    "\n",
    "#Libraries\n",
    "import os\n",
    "import xarray as xr\n",
    "from datetime import timedelta\n",
    "\n",
    "class ModelData_Class:\n",
    "    def __init__(self, mainDirectory, scratchDirectory, simulationNumber):\n",
    "        self.mainDirectory = mainDirectory\n",
    "        self.scratchDirectory = scratchDirectory\n",
    "        self.simulationNumber = simulationNumber\n",
    "        \n",
    "        # Initialize directories and metadata\n",
    "        (self.dataDirectory, \n",
    "         self.parcelDirectory, \n",
    "         self.res, \n",
    "         self.t_res, \n",
    "         self.Np_str, \n",
    "         self.Nz_str) = self.GetDataDirectories()\n",
    "\n",
    "        # Load coordinate data only (lightweight)\n",
    "        self.GetCoordinateData()\n",
    "        self.Np = self.GetCoordinateParcel()\n",
    "        self.timeStrings = self.GetTimeStrings(self.time)\n",
    "\n",
    "        # Load Variable Names\n",
    "        self.varList = self.GetVariableNames()\n",
    "\n",
    "        # Print summary\n",
    "        self.Summary()\n",
    "\n",
    "    # ============================================================\n",
    "    # ========== Data Loading Functions ==========\n",
    "    # ============================================================\n",
    "\n",
    "    def GetDataDirectories(self):\n",
    "        \"\"\"Return directory paths and metadata based on simulation number.\"\"\"\n",
    "        if self.simulationNumber == 1:\n",
    "            Directory = os.path.join(self.mainDirectory, 'Model/cm1r20.3/run')\n",
    "            res, t_res, Np_str, Nz_str = '1km', '5min', '1e6', '34'\n",
    "        elif self.simulationNumber == 2:\n",
    "            Directory = self.scratchDirectory\n",
    "            res, t_res, Np_str, Nz_str = '1km', '1min', '50e6', '95'\n",
    "        elif self.simulationNumber == 3:\n",
    "            Directory = self.scratchDirectory\n",
    "            res, t_res, Np_str, Nz_str = '250m', '1min', '50e6', '95'\n",
    "        else:\n",
    "            raise ValueError(\"Invalid simulationNumber (must be 1, 2, or 3).\")\n",
    "\n",
    "        dataDirectory = os.path.join(Directory, f\"cm1out_{res}_{t_res}_{Nz_str}nz.nc\")\n",
    "        parcelDirectory = os.path.join(Directory, f\"cm1out_pdata_{res}_{t_res}_{Np_str}np.nc\")\n",
    "        return dataDirectory, parcelDirectory, res, t_res, Np_str, Nz_str\n",
    "\n",
    "    def GetCoordinateData(self):\n",
    "        \"\"\"\n",
    "        Extract coordinate arrays (time, zf, zh, yf, yh, xf, xh) \n",
    "        from the CM1 dataset and immediately close the file.\n",
    "        \"\"\"\n",
    "        with xr.open_dataset(self.dataDirectory, decode_timedelta=True) as ds:\n",
    "            coords = ['time', 'zf', 'zh', 'yf', 'yh', 'xf', 'xh']\n",
    "            extracted = {k: ds[k].values for k in coords}\n",
    "\n",
    "        # Assign coordinate arrays and their lengths\n",
    "        for k, v in extracted.items():\n",
    "            setattr(self, k, v)\n",
    "            setattr(self, f\"N{k}\", len(v))\n",
    "            \n",
    "        return extracted\n",
    "\n",
    "    def GetCoordinateParcel(self):\n",
    "        \"\"\"\n",
    "        Extract coordinate arrays (time, zf, zh, yf, yh, xf, xh) \n",
    "        from the CM1 lagrangian parcel dataset and immediately close the file.\n",
    "        \"\"\"\n",
    "        with xr.open_dataset(self.parcelDirectory, decode_timedelta=True) as ds:\n",
    "            p = ds['xh'].values\n",
    "            Np = len(p)\n",
    "        return Np\n",
    "\n",
    "    def GetTimeStrings(self, times):\n",
    "        \"\"\"Convert CM1 time array (nanoseconds) to formatted strings.\"\"\"\n",
    "        return [str(timedelta(seconds=float(s))).replace(\":\", \"-\") for s in times / 1e9]\n",
    "\n",
    "    def GetVariableNames(self):\n",
    "        \"\"\"Get list of variable names available in the CM1 dataset.\"\"\"\n",
    "        with xr.open_dataset(self.dataDirectory, decode_timedelta=True) as ds:\n",
    "            varList = list(ds.data_vars)\n",
    "        return varList\n",
    "    \n",
    "    # ============================================================\n",
    "    # ========== On-demand Variable Access ==========\n",
    "    # ============================================================\n",
    "\n",
    "    def OpenData(self, decode_timedelta=True):\n",
    "        #EXAMPLE: ds = ModelData.OpenData()\n",
    "        #         ...\n",
    "        #         del ds\n",
    "        data = xr.open_dataset(self.dataDirectory, decode_timedelta=decode_timedelta)\n",
    "        print(f\"Opened dataset: {self.dataDirectory}\")\n",
    "        return data\n",
    "\n",
    "    def OpenParcel(self, decode_timedelta=True):\n",
    "        #EXAMPLE: ds = ModelData.OpenParcel()\n",
    "        #         ...\n",
    "        #         del ds\n",
    "        parcel = xr.open_dataset(self.parcelDirectory, decode_timedelta=decode_timedelta)\n",
    "        print(f\"Opened dataset: {self.parcelDirectory}\")\n",
    "        return parcel\n",
    "\n",
    "    def SubsetDataVars(self, data):\n",
    "        varList = [\"thflux\", \"qvflux\", \"tsk\", \"cape\", \n",
    "                   \"cin\", \"lcl\", \"lfc\", \"th\",\n",
    "                   \"prs\", \"rho\", \"qv\", \"qc\",\n",
    "                   \"qr\", \"qi\", \"qs\",\"qg\", \n",
    "                   \"buoyancy\", \"uinterp\", \"vinterp\", \"winterp\",]\n",
    "        \n",
    "        varList += [\"ptb_hadv\", \"ptb_vadv\", \"ptb_hidiff\", \"ptb_vidiff\",\n",
    "                    \"ptb_hturb\", \"ptb_vturb\", \"ptb_mp\", \"ptb_rdamp\", \n",
    "                    \"ptb_rad\", \"ptb_div\", \"ptb_diss\",]\n",
    "        \n",
    "        varList += [\"qvb_hadv\", \"qvb_vadv\", \"qvb_hidiff\", \"qvb_vidiff\", \n",
    "                    \"qvb_hturb\", \"qvb_vturb\", \"qvb_mp\",]\n",
    "        \n",
    "        varList += [\"wb_hadv\", \"wb_vadv\", \"wb_hidiff\", \"wb_vidiff\",\n",
    "                    \"wb_hturb\", \"wb_vturb\", \"wb_pgrad\", \"wb_rdamp\", \"wb_buoy\",]\n",
    "    \n",
    "        # Filter only available variables in the dataset\n",
    "        available_vars = [v for v in varList if v in data.variables]\n",
    "    \n",
    "        if not available_vars:\n",
    "            raise ValueError(\"None of the requested variables were found in the dataset.\")\n",
    "    \n",
    "        return data[available_vars]\n",
    "\n",
    "    def GetVariable(self, varName, isel=None):\n",
    "        #EXAMPLE: w = ModelData.GetVariable('winterp', isel={'time': slice(0,2), 'zh': 0, 'yh': 0, 'xh': 0}) #example getting a variable\n",
    "        \"\"\"\n",
    "        Open the full NetCDF file, extract a variable (optionally subset via .isel), \n",
    "        then close immediately. Returns the variable data as a NumPy array.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        varName : str\n",
    "            Name of the variable to extract.\n",
    "        isel : dict, optional\n",
    "            Dictionary of indices to select (e.g., {'time': 0, 'zh': slice(0,10)}).\n",
    "        decode_timedelta : bool, optional\n",
    "            Whether to decode CF-style timedelta coordinates (default: True).\n",
    "        \"\"\"\n",
    "        with xr.open_dataset(self.dataDirectory, decode_timedelta=True) as ds:\n",
    "            if varName not in ds.variables:\n",
    "                raise KeyError(f\"Variable '{varName}' not found in dataset.\")\n",
    "            da = ds[varName]\n",
    "            if isel is not None:\n",
    "                da = da.isel(**isel)\n",
    "            varData = da.data  # load into memory before closing\n",
    "        return varData\n",
    "\n",
    "    # ============================================================\n",
    "    # === Information ========================================\n",
    "    # ============================================================\n",
    "\n",
    "    def Summary(self):\n",
    "        \"\"\"Print a summary of the simulation configuration.\"\"\"\n",
    "        print(\"=== CM1 Data Summary ===\")\n",
    "        print(f\" Simulation #:   {self.simulationNumber}\")\n",
    "        print(f\" Resolution:     {self.res}\")\n",
    "        print(f\" Time step:      {self.t_res}\")\n",
    "        print(f\" Vertical levels:{self.Nz_str}\")\n",
    "        print(f\" Parcels:        {self.Np_str}\")\n",
    "        print(f\" Data file:      {self.dataDirectory}\")\n",
    "        print(f\" Parcel file:    {self.parcelDirectory}\")\n",
    "        print(f\" Time steps:     {len(self.time)}\")\n",
    "        print(\"=========================\",\"\\n\")\n",
    "\n",
    "#EXAMPLE: ModelData = ModelData_Class(mainDirectory, scratchDirectory, simulationNumber=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf350113-ab7e-492f-b204-bf288d140cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SlurmJobArray_Class\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "class SlurmJobArray_Class:\n",
    "    def __init__(self, total_elements, num_jobs, UsingJobArray):\n",
    "        self.total_elements = total_elements\n",
    "        self.num_jobs = num_jobs\n",
    "        self.UsingJobArray = UsingJobArray\n",
    "        \n",
    "        # Get job ID (default = 1 if not running under Slurm)\n",
    "        self.job_id = int(os.environ.get('SLURM_ARRAY_TASK_ID', 0))\n",
    "        if self.job_id == 0:\n",
    "            self.job_id = 1\n",
    "        \n",
    "        # Precompute range info\n",
    "        self.job_range = total_elements // num_jobs\n",
    "        self.remaining = total_elements % num_jobs\n",
    "        \n",
    "        # Compute job range for this job\n",
    "        self.start_job, self.end_job = self._get_job_range(self.job_id)\n",
    "\n",
    "        # Print summary\n",
    "        self.Summary()\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    def _get_job_range(self, job_id):\n",
    "        if self.UsingJobArray == True:\n",
    "            \"\"\"Compute start and end indices for this job.\"\"\"\n",
    "            job_id -= 1\n",
    "            start_job = job_id * self.job_range + min(job_id, self.remaining)\n",
    "            end_job = start_job + self.job_range + (1 if job_id < self.remaining else 0)\n",
    "            if job_id == self.num_jobs - 1:\n",
    "                end_job = self.total_elements\n",
    "        elif self.UsingJobArray == False:\n",
    "            start_job, end_job = 0, self.total_elements\n",
    "        return start_job, end_job\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    def TESTING(self):\n",
    "        \"\"\"Print start/end for all jobs to verify chunking logic.\"\"\"\n",
    "        start, end = [], []\n",
    "        for job_id in range(1, self.num_jobs + 1):\n",
    "            s, e = self._get_job_range(job_id)\n",
    "            print(f\"Job {job_id}: {s} → {e}\")\n",
    "            start.append(s)\n",
    "            end.append(e)\n",
    "        print(\"Unique starts:\", len(np.unique(start)) == len(start))\n",
    "        print(\"Unique ends:\", len(np.unique(end)) == len(end))\n",
    "        print(\"No zero-length ranges:\", np.all(np.array(start) != np.array(end)))\n",
    "\n",
    "    def Summary(self):\n",
    "        print(f\"Running timesteps from {self.start_job}:{self.end_job}\",\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ad18874-a7d2-49a4-a54a-6c33e11ca232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DataManager_Class\n",
    "# ============================================================\n",
    "\n",
    "#Libraries\n",
    "import os\n",
    "import h5py\n",
    "\n",
    "class DataManager_Class:\n",
    "    def __init__(self, mainDirectory, scratchDirectory, res, t_res, Nz_str, Np_str, dataType, dataName, dtype, make_dirs=True):\n",
    "        self.mainDirectory = mainDirectory\n",
    "        self.scratchDirectory = scratchDirectory\n",
    "        self.dataType = dataType\n",
    "        self.res = res\n",
    "        self.t_res = t_res\n",
    "        self.Nz_str = Nz_str\n",
    "        self.Np_str = Np_str\n",
    "        self.dataName = dataName\n",
    "        self.dtype = dtype\n",
    "        self.make_dirs = make_dirs\n",
    "\n",
    "        # Initialize directories on creation\n",
    "        self.inputDirectory = self.GetInputDirectory(mainDirectory, scratchDirectory)\n",
    "        self.outputDirectory = self.GetOutputDirectory(mainDirectory, scratchDirectory)\n",
    "        self.inputDataDirectory = self.MakeInputDataDirectory(self.inputDirectory)\n",
    "        self.inputParcelDirectory = self.MakeInputParcelDirectory(self.inputDirectory)\n",
    "        self.outputDataDirectory = self.MakeOutputDataDirectory(self.outputDirectory)\n",
    "\n",
    "        # Print summary\n",
    "        self.Summary()\n",
    "\n",
    "    # ============================================================\n",
    "    # ========== Functions ==========\n",
    "    # ============================================================\n",
    "\n",
    "    def GetInputDirectory(self, mainDirectory, scratchDirectory):\n",
    "        if self.res == '1km':\n",
    "            inputDirectory = os.path.join(mainDirectory, 'Code', 'OUTPUT', 'Variable_Calculation', 'TimeSplitModelData')\n",
    "        if self.res == '250m':\n",
    "            inputDirectory = os.path.join(scratchDirectory, 'OUTPUT', 'Variable_Calculation', 'TimeSplitModelData')\n",
    "        return inputDirectory\n",
    "\n",
    "    def GetOutputDirectory(self, mainDirectory, scratchDirectory):\n",
    "        if self.res == '1km':\n",
    "            outputDirectory = os.path.join(mainDirectory, 'Code', 'OUTPUT', 'Variable_Calculation', self.dataType)\n",
    "            if self.make_dirs:\n",
    "                os.makedirs(outputDirectory, exist_ok=True)\n",
    "        if self.res == '250m':\n",
    "            outputDirectory = os.path.join(scratchDirectory, 'OUTPUT', 'Variable_Calculation', self.dataType)\n",
    "            if self.make_dirs:\n",
    "                os.makedirs(outputDirectory, exist_ok=True)\n",
    "        return outputDirectory\n",
    "\n",
    "    def MakeInputDataDirectory(self, inputDirectory):\n",
    "        inputDataDirectory = os.path.join(inputDirectory, f\"{self.res}_{self.t_res}_{self.Nz_str}nz\", \"ModelData\")\n",
    "        return inputDataDirectory\n",
    "\n",
    "    def MakeInputParcelDirectory(self, inputDirectory):\n",
    "        inputParcelDirectory = os.path.join(inputDirectory, f\"{self.res}_{self.t_res}_{self.Nz_str}nz\", \"ParcelData\")\n",
    "        return inputParcelDirectory\n",
    "\n",
    "    def MakeOutputDataDirectory(self, outputDirectory):\n",
    "        outputDataDirectory = os.path.join(outputDirectory, f\"{self.res}_{self.t_res}_{self.Nz_str}nz\",self.dataName)\n",
    "        if self.make_dirs:\n",
    "            os.makedirs(outputDataDirectory, exist_ok=True)\n",
    "        return outputDataDirectory\n",
    "\n",
    "    def GetTimestepData(self, inputDataDirectory, timeString, variableName, dataName=\"cm1out\"):\n",
    "        inputDataFile = os.path.join(\n",
    "            inputDataDirectory,\n",
    "            f\"{dataName}_{self.res}_{self.t_res}_{self.Nz_str}nz_{timeString}.h5\"\n",
    "        )\n",
    "        with h5py.File(inputDataFile, 'r') as f:\n",
    "            InputData = f[variableName][:]\n",
    "        return InputData\n",
    "\n",
    "    def GetTimestepParcel(self, inputParcelDirectory, timeString, variableName, dataName=\"cm1out_pdata\"):\n",
    "        inputDataFile = os.path.join(\n",
    "            inputParcelDirectory,\n",
    "            f\"{dataName}_{self.res}_{self.t_res}_{self.Np_str}np_{timeString}.h5\"\n",
    "        )\n",
    "        with h5py.File(inputDataFile, 'r') as f:\n",
    "            InputData = f[variableName][:]\n",
    "        return InputData\n",
    "\n",
    "    def SaveOutputTimestep(self, outputDataDirectory, timeString, outputDictionary,\n",
    "                           dtype=None,dataName=None):\n",
    "        if dtype is None:\n",
    "            dtype = self.dtype\n",
    "        if dataName is None:\n",
    "            dataName = self.dataName\n",
    "        \n",
    "        out_file = os.path.join(\n",
    "            outputDataDirectory,\n",
    "            f\"{dataName}_{self.res}_{self.t_res}_{self.Nz_str}nz_{timeString}.h5\"\n",
    "        )\n",
    "        with h5py.File(out_file, 'w') as f:\n",
    "            for var_name, arr in outputDictionary.items():\n",
    "                f.create_dataset(var_name, data=arr, dtype=dtype, compression=\"gzip\")\n",
    "        print(f\"Saved timestep to output file: {out_file}\",\"\\n\")\n",
    "\n",
    "    def Save1DVariable(self, outputDataDirectory, outputDictionary, dtype=None,dataName=None):\n",
    "        if dtype is None:\n",
    "            dtype = self.dtype\n",
    "        if dataName is None:\n",
    "            dataName = self.dataName\n",
    "        \n",
    "        out_file = os.path.join(\n",
    "            outputDataDirectory,\n",
    "            f\"{dataName}_{self.res}_{self.t_res}_{self.Nz_str}nz.h5\"\n",
    "        )\n",
    "        with h5py.File(out_file, 'w') as f:\n",
    "            for var_name, arr in outputDictionary.items():\n",
    "                print(arr)\n",
    "                f.create_dataset(var_name, data=arr, dtype=dtype, compression=\"gzip\")\n",
    "        print(f\"Saved timestep to output file: {out_file}\",\"\\n\")\n",
    "\n",
    "    def Load1DVariable(self, inputDataDirectory, dataName=None):\n",
    "            if dataName is None:\n",
    "                dataName = self.dataName\n",
    "    \n",
    "            input_file = os.path.join(\n",
    "                inputDataDirectory,\n",
    "                f\"{dataName}_{self.res}_{self.t_res}_{self.Nz_str}nz.h5\"\n",
    "            )\n",
    "    \n",
    "            output_dict = {}\n",
    "            with h5py.File(input_file, 'r') as f:\n",
    "                for var_name in f.keys():\n",
    "                    data = f[var_name][:]\n",
    "                    output_dict[var_name] = data\n",
    "    \n",
    "            print(f\"Loaded 1D variable file: {input_file}\", \"\\n\")\n",
    "            return output_dict\n",
    "\n",
    "    def Summary(self):\n",
    "        \"\"\"Print a summary of the simulation configuration.\"\"\"\n",
    "        print(\"=== DataManager Summary ===\")\n",
    "        print(f\" inputDirectory #:   {self.inputDirectory}\")\n",
    "        print(f\" outputDirectory #:   {self.outputDirectory}\")\n",
    "        print(f\" inputDataDirectory #:   {self.inputDataDirectory}\")\n",
    "        print(f\" inputParcelDirectory #:   {self.inputParcelDirectory}\")\n",
    "        print(f\" outputDataDirectory #:   {self.outputDataDirectory}\")\n",
    "        print(\"=========================\",\"\\n\")\n",
    "\n",
    "# EXAMPLE: DataManager = DataManager_Class(mainDirectory, scratchDirectory, ModelData.res, ModelData.t_res, ModelData.Nz_str, dataName=\"Eulerian_Binary_Array\", dtype='bool')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
