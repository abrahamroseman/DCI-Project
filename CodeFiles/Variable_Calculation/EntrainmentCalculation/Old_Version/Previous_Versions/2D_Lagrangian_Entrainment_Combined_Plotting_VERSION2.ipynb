{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3411e523-2126-4767-aae1-fbef4b65f0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading in Packages and Data\n",
    "\n",
    "#Importing Packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "import matplotlib.gridspec as gridspec\n",
    "import xarray as xr\n",
    "import os; import time\n",
    "import pickle\n",
    "import h5py\n",
    "###############################################################\n",
    "def coefs(coefficients,degree):\n",
    "    coef=coefficients\n",
    "    coefs=\"\"\n",
    "    for n in range(degree, -1, -1):\n",
    "        string=f\"({coefficients[len(coef)-(n+1)]:.1e})\"\n",
    "        coefs+=string + f\"x^{n}\"\n",
    "        if n != 0:\n",
    "            coefs+=\" + \"\n",
    "    return coefs\n",
    "###############################################################\n",
    "\n",
    "#Importing Model Data\n",
    "check=False\n",
    "dir='/mnt/lustre/koa/koastore/torri_group/air_directory/DCI-Project/'\n",
    "\n",
    "# dx = 1 km; Np = 1M; Nt = 5 min\n",
    "data=xr.open_dataset(dir+'../cm1r20.3/run/cm1out_1km_5min.nc') #***\n",
    "parcel=xr.open_dataset(dir+'../cm1r20.3/run/cm1out_pdata_1km_5min_1e6.nc') #***\n",
    "res='1km';t_res='5min'\n",
    "Np_str='1e6'\n",
    "\n",
    "# # dx = 1km; Np = 50M\n",
    "# #Importing Model Data\n",
    "# check=False\n",
    "# dir2='/home/air673/koa_scratch/'\n",
    "# data=xr.open_dataset(dir2+'cm1out_1km_1min.nc') #***\n",
    "# parcel=xr.open_dataset(dir2+'cm1out_pdata_1km_1min_50M.nc') #***\n",
    "# res='1km'; t_res='1min'; Np_str='50e6'\n",
    "\n",
    "# # dx = 1km; Np = 100M\n",
    "# #Importing Model Data\n",
    "# check=False\n",
    "# dir2='/home/air673/koa_scratch/'\n",
    "# data=xr.open_dataset(dir2+'cm1out_1km_1min.nc') #***\n",
    "# parcel=xr.open_dataset(dir2+'cm1out_pdata_1km_1min_100M.nc') #***\n",
    "# res='1km'; t_res='1min'; Np_str='100e6'\n",
    "\n",
    "\n",
    "# dx = 250 m\n",
    "# #Importing Model Data\n",
    "# check=False\n",
    "# dir2='/home/air673/koa_scratch/'\n",
    "# data=xr.open_dataset(dir2+'cm1out_250m.nc') #***\n",
    "# parcel=xr.open_dataset(dir2+'cm1out_pdata_250m.nc') #***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3133df4-2cfe-42bc-9df1-42577c476900",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "dir2='/mnt/lustre/koa/koastore/torri_group/air_directory/DCI-Project/'\n",
    "path=dir2+'../Functions/'\n",
    "sys.path.append(path)\n",
    "\n",
    "import NumericalFunctions\n",
    "from NumericalFunctions import * # import NumericalFunctions \n",
    "import PlottingFunctions\n",
    "from PlottingFunctions import * # import PlottingFunctions\n",
    "\n",
    "\n",
    "# # Get all functions in NumericalFunctions\n",
    "# import inspect\n",
    "# functions = [f[0] for f in inspect.getmembers(NumericalFunctions, inspect.isfunction)]\n",
    "# functions\n",
    "\n",
    "# # Get all functions in NumericalFunctions\n",
    "# import inspect\n",
    "# functions = [f[0] for f in inspect.getmembers(PlottingFunctions, inspect.isfunction)]\n",
    "# functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad276cc-dc75-47db-be8e-c92f3dacd076",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "#PLOTTING\n",
    "plotting=False #KEEP FALSE IF JOB ARRAY IS RUNNING\n",
    "plotting=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fc1167-2e2f-4996-ad32-7a0f4bbbcba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if plotting==True:\n",
    "    #constants\n",
    "    Cp=1004 #Jkg-1K-1\n",
    "    Cv=717 #Jkg-1K-1\n",
    "    Rd=Cp-Cv #Jkg-1K-1\n",
    "    eps=0.608\n",
    "    \n",
    "    Lx=(data['xf'][-1].item()-data['xf'][0].item())*1000 #x length (m)\n",
    "    Ly=(data['yf'][-1].item()-data['yf'][0].item())*1000 #y length (m)\n",
    "    Np=len(parcel['xh']) #number of lagrangian parcles\n",
    "    dt=(data['time'][1]-data['time'][0]).item()/1e9 #sec\n",
    "    dx=(data['xf'][1].item()-data['xf'][0].item())*1e3 #meters\n",
    "    dy=(data['yf'][1].item()-data['yf'][0].item())*1e3 #meters\n",
    "    xs=data['xf'].values*1000\n",
    "    ys=data['yf'].values*1000\n",
    "    zs=data['zf'].values*1000\n",
    "    \n",
    "    def zf(z):\n",
    "        k=z #z is the # level of z\n",
    "        out=data['zf'].values[k]*1000\n",
    "        \n",
    "        return out\n",
    "    # def rho(x,y,z,t):\n",
    "    #     p=data['prs'].isel(xh=x,yh=y,zh=z,time=t).item()\n",
    "    #     p0=101325 #Pa\n",
    "    #     theta=data['th'].isel(xh=x,yh=y,zh=z,time=t).item()\n",
    "    #     T=theta*(p/p0)**(Rd/Cp)\n",
    "    #     qv=data['qv'].isel(xh=x,yh=y,zh=z,time=t).item()\n",
    "    #     # Tv=T*(1+eps*qv)\n",
    "    #     Tv=T*(eps+qv)/(eps*(1+qv))\n",
    "    #     rho = p/(Rd*Tv)\n",
    "    #     out=rho\n",
    "    #     return out\n",
    "    \n",
    "    def rho(x,y,z,rho_data_t):\n",
    "        out=rho_data_t[z,y,x]\n",
    "        return out\n",
    "    def m(t):\n",
    "        rho_data_t=data['rho'].isel(time=t).data\n",
    "        \n",
    "        m=0\n",
    "        #triple sum\n",
    "        for k in range(len(data['zh'])):\n",
    "            dz=(zf(k+1)-zf(k))\n",
    "            for j in range(len(data['yh'])):\n",
    "                for i in range(len(data['xh'])):\n",
    "                    rho_out=rho(i,j,k,rho_data_t)\n",
    "                    m+=rho_out*dz\n",
    "                    \n",
    "        #triple sum\n",
    "        out=m*dx*dy/Np\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a628b441-cb34-4625-98ea-756399604ffd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#SOME CALCULATIONS (TESTING)\n",
    "# # (Lx*Ly*(10**4))/1e6 #1M parcels ==> 1 billion kg/parcel\n",
    "# # (Lx*Ly*(10**4))/50e6 #50M parcels ==> 20 million kg/parcel\n",
    "# # (Lx*Ly*(10**4))/100e6 #100M parcels ==> 10 million kg/parcel\n",
    "\n",
    "# # 1e5 kg | 9.1125 e4 m^3\n",
    "# # x   kg | 1000*1000*62 = 6.2e7 m^3\n",
    "# (1000*1000*62)*(1e5/(9.1125e4))# ==> 68038408 ==> should have 68M kg in the bottom most layer \n",
    "\n",
    "# 68038408/19729158# (expected/calculated mass) ==> should have 3.5 parcels in each grid box on the bottom most layer\n",
    "# #we have 369e3 parcels on bottom layer ==> 369e3/(Nx*Ny) = 369e3/102400 = 3.6 parcels per layer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b876564-f013-44c3-918e-525b263f414d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if plotting==True:\n",
    "    #Calculate Mass Constant\n",
    "    # calculate='single_time'\n",
    "    # calculate=True\n",
    "    calculate=False\n",
    "    \n",
    "    if calculate==True:\n",
    "        Nt=len(data['time'])\n",
    "        m_arr=np.zeros((Nt))\n",
    "        for t in np.arange(Nt):\n",
    "            if np.mod(t,25)==0: print(t)\n",
    "            m_arr[t]=m(t)\n",
    "        dir3=dir+f'Project_Algorithms/Entrainment/'\n",
    "        np.save(dir3+f'Mass_Array_{res}_{t_res}_{Np_str}.npy', m_arr)\n",
    "    elif calculate=='single_time':\n",
    "        Nt=len(data['time'])\n",
    "        m_arr=np.zeros((Nt))\n",
    "    \n",
    "        t=0 #len(data['time'])//2 #Pick some middle time\n",
    "        m_300=m(t)\n",
    "        for t in np.arange(Nt):\n",
    "            m_arr[t]=m_300 #UNCOMMENT FOR FULL CALCULATION\n",
    "        dir3=dir+f'Project_Algorithms/Entrainment/'\n",
    "        np.save(dir3+f'Mass_Array_{res}_{t_res}_{Np_str}.npy', m_arr)\n",
    "    else:\n",
    "        dir3=dir+f'Project_Algorithms/Entrainment/'\n",
    "        m_arr = np.load(dir3+f'Mass_Array_{res}_{t_res}_{Np_str}.npy')\n",
    "    \n",
    "    # # TESTING\n",
    "    # lst=[]\n",
    "    # for t in np.arange(133):\n",
    "    #     lst.append(m_arr[t])\n",
    "    \n",
    "    # plt.plot(lst)\n",
    "    # (np.max(lst)-np.min(lst))*100/np.mean(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be859db5-6d0c-41de-b16a-18534f0da7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if plotting==True:\n",
    "    PROCESSING=False\n",
    "    PROCESSING=True\n",
    "    \n",
    "    dir3=dir+'Project_Algorithms/Entrainment/'\n",
    "    if PROCESSING==False:\n",
    "        open_file=dir3+f'2D_entrainmentdetrainment_combined2_profiles_{res}_{t_res}_{Np_str}.h5'\n",
    "    if PROCESSING==True:\n",
    "        open_file=dir3+f'2D_entrainmentdetrainment_combined2_profiles_PREPROCESSING_{res}_{t_res}_{Np_str}.h5'\n",
    "    with h5py.File(open_file, \"r\") as h5f:\n",
    "        profile_array_e_g = h5f[\"profile_array_e_g\"][:]\n",
    "        profile_array_e_c = h5f[\"profile_array_e_c\"][:]\n",
    "        profile_array_d_g = h5f[\"profile_array_d_g\"][:]\n",
    "        profile_array_d_c = h5f[\"profile_array_d_c\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c287244-909e-4da7-92e5-17e9875b7acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if plotting==True:\n",
    "    type='general'\n",
    "    type='cloudy'\n",
    "    \n",
    "    def apply_constant(profile_array,apply):\n",
    "        if apply==True:\n",
    "            Nt=profile_array.shape[0]\n",
    "            Nz=profile_array.shape[1]\n",
    "        \n",
    "            profile_array/=(Lx*Ly*dt)\n",
    "            for t in np.arange(Nt):\n",
    "                profile_array[t]*=m_arr[t]\n",
    "            for z in np.arange(Nz):\n",
    "                dz=zf(z+1)-zf(z)\n",
    "                profile_array[:,z]/=dz\n",
    "        return profile_array\n",
    "    #APPLY CONSTANTS TO ENTRAINMENT VALUE\n",
    "    ##################################################\n",
    "    profile_array_e_g=apply_constant(profile_array_e_g,apply=True)\n",
    "    profile_array_e_c=apply_constant(profile_array_e_c,apply=True)\n",
    "    profile_array_d_g=apply_constant(profile_array_d_g,apply=True)\n",
    "    profile_array_d_c=apply_constant(profile_array_d_c,apply=True)\n",
    "    ##################################################\n",
    "    \n",
    "    if type=='general':\n",
    "        profile_array_e=profile_array_e_g\n",
    "        profile_array_d=profile_array_d_g\n",
    "        profile_array_net=profile_array_e-profile_array_d\n",
    "    if type=='cloudy':\n",
    "        profile_array_e=profile_array_e_c\n",
    "        profile_array_d=profile_array_d_c\n",
    "        profile_array_net=profile_array_e-profile_array_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2489adc0-6370-44e2-aeae-e0914fbee596",
   "metadata": {},
   "outputs": [],
   "source": [
    "if plotting==True:\n",
    "    #Plotting\n",
    "    ############################################################\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib.gridspec import GridSpec\n",
    "    import numpy as np\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    gs = GridSpec(2, 2, figure=fig)\n",
    "    \n",
    "    ######\n",
    "    cmap1 = plt.cm.viridis\n",
    "    cmap2 = plt.cm.seismic \n",
    "    n_levels=29\n",
    "    ######\n",
    "    \n",
    "    ######\n",
    "    vmax_shared = np.max([np.max(profile_array_e), np.max(profile_array_d)])\n",
    "    norm_shared = mcolors.Normalize(vmin=0, vmax=vmax_shared)\n",
    "    ######\n",
    "    \n",
    "    # First subplot: Entrainment\n",
    "    ########################################\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    # contour1 = ax1.contourf(profile_array_e.T, cmap=cmap1)\n",
    "    contour1 = ax1.contourf(profile_array_e.T, cmap=cmap1, norm=norm_shared, levels=n_levels)\n",
    "    cbar1=fig.colorbar(contour1, ax=ax1)\n",
    "    Nz = len(data['zh'])\n",
    "    ax1.set_yticks(np.arange(Nz))\n",
    "    new_ytick_labels = np.round(data['zf'].values[:Nz], 2)\n",
    "    ax1.set_yticklabels(new_ytick_labels, fontsize=8, rotation=0)\n",
    "    ax1.set_ylabel('z (km)');ax1.set_xlabel('t (timesteps)')\n",
    "    ax1.set_title('Entrainment using Lagrangian Binary Array',fontsize=8)\n",
    "    \n",
    "    # Second subplot: Detrainment\n",
    "    ########################################\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    # contour2 = ax2.contourf(profile_array_d.T, cmap=cmap1)\n",
    "    contour2 = ax2.contourf(profile_array_d.T, cmap=cmap1, norm=norm_shared, levels=n_levels)\n",
    "    cbar2 = fig.colorbar(contour2, ax=ax2)\n",
    "    ax2.set_yticks(np.arange(Nz))\n",
    "    new_ytick_labels = np.round(data['zf'].values[:Nz], 2)\n",
    "    ax2.set_yticklabels(new_ytick_labels, fontsize=8, rotation=0)\n",
    "    ax2.set_ylabel('z (km)');ax2.set_xlabel('t (timesteps)')\n",
    "    ax2.set_title('Detrainment')\n",
    "    \n",
    "    # Third subplot: Net Entrainment\n",
    "    ########################################\n",
    "    \n",
    "    \n",
    "    # #OLD METHOD, DOESNT BALANCE COLOR LEVELS\n",
    "    # # Normalize with a balanced vmin and vmax\n",
    "    # levels=49; vmin=np.min(profile_array_net);vmax=np.max(profile_array_net)\n",
    "    # # vmin=-np.max(abs(profile_array_net)); vmax=+np.max(abs(profile_array_net))\n",
    "    # norm = mcolors.TwoSlopeNorm(vmin=vmin, vcenter=0, vmax=vmax)\n",
    "    \n",
    "    # Normalize with a balanced vmin and vmax\n",
    "    vmin=-np.max(abs(profile_array_net))/2; vmax=+np.max(abs(profile_array_net))\n",
    "\n",
    "    percentile_vminmax=False\n",
    "    if percentile_vminmax==True:\n",
    "        ####\n",
    "        vmin = np.percentile(profile_array_net[profile_array_net<0], 1)\n",
    "        vmax = np.percentile(profile_array_net[profile_array_net>0], 99)\n",
    "        ####\n",
    "\n",
    "    \n",
    "        \n",
    "    levels = np.linspace(vmin, vmax, n_levels)\n",
    "    norm = mcolors.BoundaryNorm(boundaries=levels, ncolors=256)\n",
    "    cmap = plt.get_cmap('RdBu_r', n_levels)\n",
    "    \n",
    "    ax3 = fig.add_subplot(gs[1, 0])\n",
    "    contour3 = ax3.contourf((profile_array_net).T, cmap=cmap2, norm=norm, levels=levels)\n",
    "    # contour3 = ax3.contourf((profile_array_net).T, cmap=cmap2, levels=30,vmin=-np.max(abs(profile_array_net)), vmax=+np.max(abs(profile_array_net)))\n",
    "    # cmap2 = plt.get_cmap('RdBu', 29);contour3 = ax3.pcolor(profile_array_net.T, cmap=cmap2, norm=norm, shading='auto')\n",
    "    cbar3 = fig.colorbar(contour3, ax=ax3, norm=norm)\n",
    "    \n",
    "    #FIXING TICKS\n",
    "    ax3.set_yticks(np.arange(Nz))\n",
    "    new_ytick_labels = np.round(data['zf'].values[:Nz], 2)\n",
    "    ax3.set_yticklabels(new_ytick_labels, fontsize=8, rotation=0)\n",
    "    ax3.set_ylabel('z (km)');ax3.set_xlabel('t (timesteps)')\n",
    "    ax3.set_title('Entrainment - Detrainment')\n",
    "    \n",
    "    #FIXING SCIENTIFIC NOTATION\n",
    "    \n",
    "    def apply_scientific_notation_colorbar(cbars):\n",
    "        from matplotlib.ticker import ScalarFormatter\n",
    "        formatter = ScalarFormatter(useMathText=True)\n",
    "        formatter.set_powerlimits((-2, 2))  # Adjust the range for scientific notation\n",
    "        for cbar in cbars:  # These must be Colorbar instances\n",
    "            cbar.formatter = formatter\n",
    "            cbar.update_ticks()\n",
    "    apply_scientific_notation_colorbar([cbar1,cbar2,cbar3])\n",
    "    \n",
    "    # Display the plot\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    #TESTING\n",
    "    print(f\"Max of profile_array_e: {np.max(profile_array_e)}\")\n",
    "    print(f\"Max of profile_array_d: {np.max(profile_array_d)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14eabff-12c5-47e4-8394-87f31ea2cc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "if plotting==True:\n",
    "    e=np.mean(profile_array_e,axis=(0))\n",
    "    d=np.mean(profile_array_d,axis=(0))\n",
    "    net=np.mean(profile_array_e-profile_array_d,axis=(0))\n",
    "    \n",
    "    plt.plot(e,data['zh'],color='blue',label='entrainment')\n",
    "    plt.plot(d,data['zh'],color='red',label='detrainment')\n",
    "    plt.plot(net,data['zh'],linestyle='dashed',color='black',label='entrainment - detrainment')\n",
    "    plt.axvline(0,color='black')\n",
    "    \n",
    "    plt.legend(); plt.title('2D Entrainment and Detrainment Using Lagrangian Binary Array')\n",
    "    \n",
    "    from matplotlib.ticker import ScalarFormatter\n",
    "    formatter = ScalarFormatter(useMathText=True)\n",
    "    formatter.set_scientific(True)\n",
    "    formatter.set_powerlimits((-1, 1))\n",
    "    plt.gca().xaxis.set_major_formatter(formatter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666061ac-55e6-43d2-8849-c32a47684aa1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
