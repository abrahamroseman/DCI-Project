#!/bin/bash
#SBATCH --job-name=python
##SBATCH --account=torri
##SBATCH --partition=torri

#SBATCH --partition=shared

#SBATCH --time=0-03:00:00
##SBATCH --ntasks=1
#SBATCH --nodes=1 
#SBATCH  --tasks-per-node=1  
#SBATCH --cpus-per-task=1 #Each node has 47 CPUs
#SBATCH --mem=10G #GBTotal 180GB per node (180G/30 = 6G) #0 for full node memory
##SBATCH --constraint=“ib_hdr” # will allow a mix of HDR200 and HDR100 nodes
##SBATCH --constraint=“ib_hdr100” # explicitly only allow HDR100 nodes
##SBATCH --distribution=“*:*:*” # Set the distribution to defaults if doing sbatch from interactive session
#SBATCH --error=pybash_job-%A.err
#SBATCH --output=pybash_job-%A.out
## Remote notification
#SBATCH --mail-type=BEGIN,END,FAIL,REQUEUE,TIME_LIMIT_80
#SBATCH --mail-user=air673@hawaii.edu

mkdir -p job_out
#exec >> "job_out/py-$SLURM_ARRAY_TASK_ID.out" 2>&1 #don't use if you are piping to .out file below

#LOADING MODULES
module purge
module load lang/Anaconda3
source activate work #personal python custom environment

#PYTHON SETTINGS
export HDF5_USE_FILE_LOCKING=FALSE #disable HDF5 file locking
export PYTHONUNBUFFERED=TRUE #allows print statements during run

# --- RUNNING PYTHON ---

# ONE
mkdir -p job_out/Lagrangian_Entrainment_Plotting
jupyter nbconvert --to script Lagrangian_Entrainment_Plotting.ipynb
python -u Lagrangian_Entrainment_Plotting.py