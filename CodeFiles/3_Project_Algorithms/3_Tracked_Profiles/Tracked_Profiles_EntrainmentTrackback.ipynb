{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cac61f8e-07d4-466d-9bbc-7db78e94af5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "#ENVIRONMENT SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37181109-7bb0-4238-8f70-c7f13877142b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "import matplotlib.gridspec as gridspec\n",
    "import xarray as xr\n",
    "\n",
    "import sys; import os; import time; from datetime import timedelta\n",
    "import pickle\n",
    "import h5py\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab3bffd3-e090-4026-923a-2cc4bc557d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAIN DIRECTORIES\n",
    "def GetDirectories():\n",
    "    mainDirectory='/mnt/lustre/koa/koastore/torri_group/air_directory/Projects/DCI-Project/'\n",
    "    mainCodeDirectory=os.path.join(mainDirectory,\"Code/CodeFiles/\")\n",
    "    scratchDirectory='/mnt/lustre/koa/scratch/air673/'\n",
    "    codeDirectory=os.getcwd()\n",
    "    return mainDirectory,mainCodeDirectory,scratchDirectory,codeDirectory\n",
    "\n",
    "[mainDirectory,mainCodeDirectory,scratchDirectory,codeDirectory] = GetDirectories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7d39021-473b-4586-b4cd-c5f501b14ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT CLASSES\n",
    "sys.path.append(os.path.join(mainCodeDirectory,\"2_Variable_Calculation\"))\n",
    "from CLASSES_Variable_Calculation import ModelData_Class, SlurmJobArray_Class, DataManager_Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0688da7-0218-448e-8ec6-fba1185442b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT FUNCTIONS\n",
    "sys.path.append(os.path.join(mainCodeDirectory,\"2_Variable_Calculation\"))\n",
    "import FUNCTIONS_Variable_Calculation\n",
    "from FUNCTIONS_Variable_Calculation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a02959c-50c9-42a2-8258-00ed6ec4dbf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CM1 Data Summary ===\n",
      " Simulation #:   2\n",
      " Resolution:     1km\n",
      " Time step:      1min\n",
      " Vertical levels:95\n",
      " Parcels:        50e6\n",
      " Data file:      /mnt/lustre/koa/scratch/air673/cm1out_1km_1min_95nz.nc\n",
      " Parcel file:    /mnt/lustre/koa/scratch/air673/cm1out_pdata_1km_1min_50e6np.nc\n",
      " Time steps:     661\n",
      "========================= \n",
      "\n",
      "=== DataManager Summary ===\n",
      " inputDirectory #:   /mnt/lustre/koa/koastore/torri_group/air_directory/Projects/DCI-Project/Code/OUTPUT/Variable_Calculation/TimeSplitModelData\n",
      " outputDirectory #:   /mnt/lustre/koa/koastore/torri_group/air_directory/Projects/DCI-Project/Code/OUTPUT/Project_Algorithms/Tracking_Algorithms\n",
      " inputDataDirectory #:   /mnt/lustre/koa/koastore/torri_group/air_directory/Projects/DCI-Project/Code/OUTPUT/Variable_Calculation/TimeSplitModelData/1km_1min_95nz/ModelData\n",
      " inputParcelDirectory #:   /mnt/lustre/koa/koastore/torri_group/air_directory/Projects/DCI-Project/Code/OUTPUT/Variable_Calculation/TimeSplitModelData/1km_1min_95nz/ParcelData\n",
      " outputDataDirectory #:   /mnt/lustre/koa/koastore/torri_group/air_directory/Projects/DCI-Project/Code/OUTPUT/Project_Algorithms/Tracking_Algorithms/1km_1min_95nz/Lagrangian_UpdraftTracking\n",
      "========================= \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#data loading class\n",
    "ModelData = ModelData_Class(mainDirectory, scratchDirectory, simulationNumber=2)\n",
    "#data manager class\n",
    "DataManager = DataManager_Class(mainDirectory, scratchDirectory, ModelData.res, ModelData.t_res, ModelData.Nz_str,\n",
    "                                ModelData.Np_str, dataType=\"Tracking_Algorithms\", dataName=\"Lagrangian_UpdraftTracking\",\n",
    "                                dtype='float32',codeSection = \"Project_Algorithms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e5c2320-7863-48af-aa19-3fb08f326864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DataManager Summary ===\n",
      " inputDirectory #:   /mnt/lustre/koa/koastore/torri_group/air_directory/Projects/DCI-Project/Code/OUTPUT/Variable_Calculation/TimeSplitModelData\n",
      " outputDirectory #:   /mnt/lustre/koa/koastore/torri_group/air_directory/Projects/DCI-Project/Code/OUTPUT/Project_Algorithms/Tracked_Profiles\n",
      " inputDataDirectory #:   /mnt/lustre/koa/koastore/torri_group/air_directory/Projects/DCI-Project/Code/OUTPUT/Variable_Calculation/TimeSplitModelData/1km_1min_95nz/ModelData\n",
      " inputParcelDirectory #:   /mnt/lustre/koa/koastore/torri_group/air_directory/Projects/DCI-Project/Code/OUTPUT/Variable_Calculation/TimeSplitModelData/1km_1min_95nz/ParcelData\n",
      " outputDataDirectory #:   /mnt/lustre/koa/koastore/torri_group/air_directory/Projects/DCI-Project/Code/OUTPUT/Project_Algorithms/Tracked_Profiles/1km_1min_95nz/Tracked_Profiles\n",
      "========================= \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#data manager class (for saving data)\n",
    "DataManager_TrackedProfiles = DataManager_Class(mainDirectory, scratchDirectory, ModelData.res, ModelData.t_res, ModelData.Nz_str,\n",
    "                                ModelData.Np_str, dataType=\"Tracked_Profiles\", dataName=\"Tracked_Profiles\",\n",
    "                                dtype='float32',codeSection = \"Project_Algorithms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08c628b2-be48-45f1-927d-f2b140595918",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT CLASSES\n",
    "sys.path.append(os.path.join(mainCodeDirectory,\"3_Project_Algorithms\",\"2_Tracking_Algorithms\"))\n",
    "from CLASSES_TrackingAlgorithms import TrackingAlgorithms_DataLoading_Class, Results_InputOutput_Class, TrackedParcel_Loading_Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b54d26b-1af4-44a5-80f2-902188c9c105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT CLASSES\n",
    "sys.path.append(os.path.join(mainCodeDirectory,\"3_Project_Algorithms\",\"3_Tracked_Profiles\"))\n",
    "from CLASSES_TrackedProfiles import TrackedProfiles_DataLoading_CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7c87b83-3479-4043-bd76-8a25e7beadd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "path=os.path.join(mainCodeDirectory,'Functions/')\n",
    "sys.path.append(path)\n",
    "\n",
    "import NumericalFunctions\n",
    "from NumericalFunctions import * # import NumericalFunctions \n",
    "import PlottingFunctions\n",
    "from PlottingFunctions import * # import PlottingFunctions\n",
    "\n",
    "# # Get all functions in NumericalFunctions\n",
    "# import inspect\n",
    "# functions = [f[0] for f in inspect.getmembers(NumericalFunctions, inspect.isfunction)]\n",
    "# functions\n",
    "\n",
    "#####\n",
    "\n",
    "#Import StatisticalFunctions \n",
    "import sys\n",
    "dir2='/mnt/lustre/koa/koastore/torri_group/air_directory/Projects/DCI-Project/'\n",
    "path=dir2+'Functions/'\n",
    "sys.path.append(path)\n",
    "\n",
    "import StatisticalFunctions\n",
    "from StatisticalFunctions import * # import NumericalFunctions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3e71475-984b-4da3-a1f3-5551963b7e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "#JOB ARRAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09729c6a-2637-46be-b33c-a691d9bb9e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running timesteps from 0:1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#JOB ARRAY SETUP\n",
    "UsingJobArray=True\n",
    "\n",
    "def GetNumJobs(res,t_res):\n",
    "    if res=='1km':\n",
    "        if t_res=='5min':\n",
    "            num_jobs=132\n",
    "        elif t_res=='1min':\n",
    "            num_jobs=660\n",
    "    elif res=='250m': \n",
    "        if t_res=='1min':\n",
    "            num_jobs=660\n",
    "    return num_jobs\n",
    "num_jobs = GetNumJobs(ModelData.res,ModelData.t_res)\n",
    "SlurmJobArray = SlurmJobArray_Class(total_elements=ModelData.Ntime, num_jobs=num_jobs, UsingJobArray=UsingJobArray)\n",
    "start_job = SlurmJobArray.start_job; end_job = SlurmJobArray.end_job\n",
    "\n",
    "def GetNumElements():\n",
    "    loop_elements = np.arange(ModelData.Ntime)[start_job:end_job]\n",
    "    return loop_elements\n",
    "loop_elements = GetNumElements()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "79dcac64-8089-49fd-b25b-f096bca9c630",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "#DATA LOADING FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "38f0ccba-84fe-4382-9f18-32f3ac6b340d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def MakeDataDictionary(variableNames,t,printstatement=False):\n",
    "    timeString = ModelData.timeStrings[t]\n",
    "    # print(f\"Getting data from {timeString}\",\"\\n\")\n",
    "    \n",
    "    dataDictionary = {variableName: CallLagrangianArray(ModelData, DataManager, timeString, variableName=variableName, printstatement=printstatement) \n",
    "                      for variableName in variableNames}      \n",
    "    return dataDictionary\n",
    "    \n",
    "def GetSpatialData(t):    \n",
    "    variableNames = ['Z','Y','X']\n",
    "    dataDictionary = MakeDataDictionary(variableNames,t)\n",
    "    [Z,Y,X] = (dataDictionary[k] for k in variableNames)\n",
    "    return Z,Y,X\n",
    "\n",
    "def GetLangrangianBinaryArray(t):\n",
    "    variableNames=['PROCESSED_A_g','PROCESSED_A_c']\n",
    "    binaryDictionary = MakeDataDictionary(variableNames,t)\n",
    "    \n",
    "    A_g = binaryDictionary['PROCESSED_A_g']\n",
    "    A_c = binaryDictionary['PROCESSED_A_c']\n",
    "\n",
    "    return A_g,A_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "42a6d268-c714-47a0-bba8-2acb1f8fc659",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "#RUNNING FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "7f3f9380-ba6f-4f6b-8d1b-af30906893e5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Functions for Initializing Profile Arrays\n",
    "def CopyStructure(dictionary, placeholder=None):\n",
    "    \"\"\"Deep-copy dictionary structure, replacing leaves with a given placeholder.\"\"\"\n",
    "    if isinstance(dictionary, dict):\n",
    "        return {k: CopyStructure(v, placeholder) for k, v in dictionary.items()}\n",
    "    else:\n",
    "        return placeholder\n",
    "        \n",
    "def InitializeHistograms(trackedArrays, varNames, time_bins,zBins_km_g,zBins_km_c, property_bins_Dictionary):\n",
    "    \"\"\"\n",
    "    Create a nested structure matching trackedArrays,\n",
    "    with empty histogram arrays for each variable:\n",
    "        - var_hist2d\n",
    "        - var_parcel_last_time_hist2d\n",
    "    \"\"\"\n",
    "    \n",
    "    histogramsDictionary = {}\n",
    "    n_time = len(time_bins) - 1\n",
    "    \n",
    "    for category, depth_dict in trackedArrays.items():  # e.g. 'CL', 'SBF'\n",
    "        histogramsDictionary[category] = {}\n",
    "\n",
    "        for depth_type in depth_dict.keys():  # e.g. 'ALL', 'SHALLOW', 'DEEP'\n",
    "            histogramsDictionary[category][depth_type] = {}\n",
    "\n",
    "            for varName in varNames:\n",
    "\n",
    "                # ---- initialize varName level\n",
    "                histogramsDictionary[category][depth_type][varName] = {}\n",
    "                for mode in [\"g\",\"c\"]:\n",
    "                    histogramsDictionary[category][depth_type][varName][mode] = {}\n",
    "\n",
    "                # number of property bins for this variable\n",
    "                n_prop = len(property_bins_Dictionary[varName]) - 1\n",
    "\n",
    "                # initialized z-subsetted empty histograms\n",
    "                for mode, zBins in {\n",
    "                    \"g\": zBins_km_g,\n",
    "                    \"c\": zBins_km_c,\n",
    "                }.items():\n",
    "                    for z1, z2 in zBins:\n",
    "                        zKey = f\"{z1}_{z2}km_hist2d\"\n",
    "                        histogramsDictionary[category][depth_type][varName][mode][zKey] = np.zeros(\n",
    "                            (n_time, n_prop)\n",
    "                        )\n",
    "\n",
    "    return histogramsDictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "b2239d20-968f-4380-9869-ca8894461321",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def GetParcelNumbers(trackedArray, t):\n",
    "    \"\"\"\n",
    "    Return all parcel indices (p) and their corresponding row indices\n",
    "    for parcels that are active at time t.\n",
    "    Vectorized, no row-by-row loops.\n",
    "    \"\"\"\n",
    "    t_start = trackedArray[:, 1]\n",
    "    t_end   = np.minimum(trackedArray[:, 2] + trackedArray[:, 3], ModelData.Ntime)\n",
    "\n",
    "    # Boolean mask for rows active at time t\n",
    "    mask = (t >= t_start) & (t <= t_end)\n",
    "\n",
    "    # Extract parcel numbers and their corresponding row indices\n",
    "    selectedRows = np.where(mask)[0]\n",
    "    selectedPs = trackedArray[selectedRows, 0]\n",
    "    leftRightIndexes = trackedArray[selectedRows, 4]\n",
    "\n",
    "    return selectedRows, selectedPs, leftRightIndexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "bede13c2-291c-407a-a798-acbcbc4bd68d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#FUNCTIONS FOR GETTING GRID BOX MATCHES\n",
    "\n",
    "def GetGridBoxMatches_V1(Z,Y,X, zLevels,yLevels,xLevels):\n",
    "    gridboxMatches = [\n",
    "        np.where((Z == zLevel) & (Y == yLevel) & (X == xLevel))[0]\n",
    "        for zLevel, yLevel, xLevel in zip(zLevels, yLevels, xLevels)\n",
    "    ]\n",
    "    if len(gridboxMatches) == 0:\n",
    "        return None\n",
    "    return gridboxMatches\n",
    "\n",
    "from collections import defaultdict\n",
    "def BuildGridboxIndex(Z, Y, X):\n",
    "    gridIndex = defaultdict(list)\n",
    "    for i in range(len(Z)):\n",
    "        gridIndex[(Z[i], Y[i], X[i])].append(i)\n",
    "    return gridIndex\n",
    "def GetGridBoxMatches_V2(Z,Y,X, zLevels,yLevels,xLevels):\n",
    "    gridIndex = BuildGridboxIndex(Z, Y, X)\n",
    "    gridboxMatches = [\n",
    "        np.asarray(gridIndex[(z, y, x)], dtype=int)\n",
    "        for z, y, x in zip(zLevels, yLevels, xLevels)\n",
    "    ]\n",
    "    if len(gridboxMatches) == 0:\n",
    "        return None\n",
    "    return gridboxMatches\n",
    "\n",
    "\n",
    "# def CheckIfSame_GridBoxMatches(one,two):\n",
    "#     same = (\n",
    "#         len(one) == len(two)\n",
    "#         and all(\n",
    "#             np.array_equal(a, b)\n",
    "#             for a, b in zip(one, two)\n",
    "#         )\n",
    "#     )\n",
    "#     print(same,\"#\"*10,\"\\n\")\n",
    "\n",
    "# gridboxMatches_original = GetGridBoxMatches_V1(Z,Y,X, zLevels,yLevels,xLevels)\n",
    "# gridboxMatches = GetGridBoxMatches_V2(Z,Y,X, zLevels,yLevels,xLevels)\n",
    "# CheckIfSame_GridBoxMatches(gridboxMatches_original,gridboxMatches)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "8e908c93-e2d9-4efe-bdeb-2aedc1c7b38a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#FUNCTIONS FOR APPLYING CLOUD MASK TO PARCELS\n",
    "\n",
    "def GetEntrainmentMask(A_g,A_g_Prior,\n",
    "                       A_c,A_c_Prior,\n",
    "                       selectedPs):\n",
    "    mask_g = (A_g & (~A_g_Prior)).astype(bool)\n",
    "    mask_g[selectedPs] = False #remove the selected parcels themselves\n",
    "    mask_c = (A_c & (~A_c_Prior)).astype(bool)            \n",
    "    mask_c[selectedPs] = False #remove the selected parcels themselves\n",
    "    return mask_g,mask_c\n",
    "    \n",
    "# def GetWhereOtherEntrainedParcels_V1(mask_c,gridboxMatches):\n",
    "#     whereOtherEntrainedParcels_c = [idx[mask_c[idx]]\n",
    "#                                     for idx in gridboxMatches]\n",
    "#     if len(whereOtherEntrainedParcels_c) == 0:\n",
    "#         return None\n",
    "#     collapsed = np.concatenate(whereOtherEntrainedParcels_c)\n",
    "#     return collapsed\n",
    "\n",
    "def GetWhereOtherEntrainedParcels_V2(mask_c,gridboxMatches):\n",
    "    collapsed = np.concatenate(gridboxMatches)\n",
    "    collapsed = collapsed[mask_c[collapsed]]\n",
    "    if collapsed.size == 0:\n",
    "        return None\n",
    "    return collapsed\n",
    "    \n",
    "# def CheckIfSame_WhereOtherEntrainedParcel(one,two):\n",
    "#     same = np.array_equal(np.sort(one),\n",
    "#                           np.sort(two))\n",
    "#     print(same,\"#\"*10,\"\\n\")\n",
    "# collapsed_original = GetWhereOtherEntrainedParcels_V1(mask_c,gridboxMatches)\n",
    "# collapsed = GetWhereOtherEntrainedParcels_V2(mask_c,gridboxMatches)\n",
    "# CheckIfSame_WhereOtherEntrainedParcel(collapsed_original,collapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "476bb97c-9d5c-4495-a60b-c5819d6258a3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#FUNCTIONS FOR MAKING PROPERTY HISTOGRAM\n",
    "\n",
    "def AccumulatePropertyHistogram(histogramsDictionary,\n",
    "                                key1,key2,varName,\n",
    "                                array,Z,\n",
    "                                collapsed_g,collapsed_c,\n",
    "                                relative_time,\n",
    "                                property_bins_Dictionary,\n",
    "                                time_bins,zBins_km_g,zBins_km_c):\n",
    "    for mode, collapsed, zBins_km in (\n",
    "        (\"g\", collapsed_g, zBins_km_g),\n",
    "        (\"c\", collapsed_c, zBins_km_c),\n",
    "    ):\n",
    "        if (collapsed is None): continue\n",
    "\n",
    "        #GETTING PROPERTY HISTOGRAMS\n",
    "        ##########\n",
    "        # property values at this time for these entrained parcels\n",
    "        properties = array[collapsed]\n",
    "        zVals_km = ModelData.zh[Z[collapsed]]\n",
    "        \n",
    "        # time arrays for histogram2d\n",
    "        times = np.full(properties.shape, relative_time)\n",
    "        # property bins for each varName\n",
    "        property_bins = property_bins_Dictionary[varName]\n",
    "    \n",
    "        # ==========================================================\n",
    "        # Make histograms\n",
    "        # ==========================================================\n",
    "        for z1, z2 in zBins_km:\n",
    "            zMask = (zVals_km >= z1) & (zVals_km < z2)\n",
    "            if not np.any(zMask):\n",
    "                continue\n",
    "            property_hist2d_Z, _, _ = np.histogram2d(\n",
    "                times[zMask],\n",
    "                properties[zMask],\n",
    "                bins=(time_bins, property_bins)\n",
    "            )\n",
    "    \n",
    "            zKey = f\"{z1}_{z2}km_hist2d\"\n",
    "            histogramsDictionary[key1][key2][varName][mode][zKey] += property_hist2d_Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "ccbc448f-ad42-4efc-ab9a-18530e8f5cec",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def MakeTrackedProfiles(trackedArrays,histogramsDictionary,property_bins_Dictionary,varNames,\n",
    "                        Z,Y,X,t, A_g,A_c,A_g_Prior,A_c_Prior,\n",
    "                        zBins_km_g,zBins_km_c,\n",
    "                        printstatement=True):\n",
    "    \"\"\"\n",
    "    Update profileArraysDictionary with variable data for parcels active at time t.\n",
    "    Accumulates sums and counts in both profile_array and profile_array_squares.\n",
    "    \"\"\"\n",
    "    #CALCULATING\n",
    "    for key1, subdict in trackedArrays.items():         # e.g. 'CL', 'SBF'\n",
    "        print(\"\\t\",f'working on {key1}')\n",
    "        for key2, trackedArray in subdict.items():           # e.g. 'ALL', 'DEEP'\n",
    "            print(\"\\t\\t\",f'working on {key2}')\n",
    "    \n",
    "            #Part 1: getting parcels in trackedArray to run through\n",
    "            if printstatement: print(f\"Part 1: getting parcels in trackedArray to run through\")\n",
    "                \n",
    "            _, selectedPs, leftRightIndexes = GetParcelNumbers(trackedArray, t) #get parcels that are counted at time t\n",
    "            if printstatement: print(f\"\\tRunning for {len(selectedPs)} Parcels\")\n",
    "            \n",
    "            #getting Z,Y,X data\n",
    "            zLevels = Z[selectedPs]; yLevels = Y[selectedPs]; xLevels = X[selectedPs]\n",
    "\n",
    "            #Part 2: find which other parcels exist in each grid box\n",
    "            if printstatement: print(f\"Part 2: find which other parcels exist in each grid box\")\n",
    "                \n",
    "            # Step a: compute spatial matches once\n",
    "            if printstatement: print(\"\\tStep a: compute spatial matches once\") #SLOW POINT HERE\n",
    "            gridboxMatches = GetGridBoxMatches_V2(Z,Y,X, zLevels,yLevels,xLevels)\n",
    "            if gridboxMatches is None:\n",
    "                continue\n",
    "\n",
    "            #Part 3: find which of those parcels were entrained into a general/cloudy updraft\n",
    "            if printstatement: print(f\"Part 3: find which of those parcels were entrained into a general/cloudy updraft\")\n",
    "            \n",
    "            # Step a: compute entrainment masks\n",
    "            if printstatement: print(\"\\tStep a: compute entrainment masks\")\n",
    "            mask_g,mask_c = GetEntrainmentMask(A_g,A_g_Prior,\n",
    "                                               A_c,A_c_Prior,\n",
    "                                               selectedPs)\n",
    "\n",
    "            # Step b: apply masks to find all parcels\n",
    "            if printstatement: print(\"\\tStep b: apply masks to find all parcels\") #SLOW POINT HERE\n",
    "            collapsed_g = GetWhereOtherEntrainedParcels_V2(mask_g,gridboxMatches)\n",
    "            collapsed_c = GetWhereOtherEntrainedParcels_V2(mask_c,gridboxMatches)\n",
    "            if (collapsed_g is None) and (collapsed_c is None): continue\n",
    "\n",
    "            # Step c: track parcels back (last 30 minutes) and read properties\n",
    "            if printstatement: print(\"\\tStep c: track parcels back (last 60 minutes) and read properties\")\n",
    "            \n",
    "            trackTimes = np.arange(t,(t-timesteps_per_hour)-1,-1)\n",
    "            for count, t_back in enumerate(tqdm(trackTimes,desc=\"\\t\\tTracking back parcels\",leave=False)):\n",
    "                relative_time = t_back - t\n",
    "\n",
    "                VARs = MakeDataDictionary(varNames, t_back)   \n",
    "                for varName, array in VARs.items():\n",
    "                    #GETTING PROPERTY HISTOGRAMS\n",
    "                    AccumulatePropertyHistogram(histogramsDictionary,\n",
    "                                                key1,key2,varName,\n",
    "                                                array,Z,\n",
    "                                                collapsed_g,collapsed_c,\n",
    "                                                relative_time,\n",
    "                                                property_bins_Dictionary,\n",
    "                                                time_bins,zBins_km_g,zBins_km_c)\n",
    "    return histogramsDictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "8dd77179-8256-471e-bbb8-b87068468dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "#RUNNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e734a16b-8f55-4603-a820-55cfff9b95b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CL: ALL=1660231, SHALLOW=1220502, DEEP=42069\n",
      "nonCL: ALL=712151, SHALLOW=551287, DEEP=12496\n",
      "SBF: ALL=237335, SHALLOW=141001, DEEP=12635\n",
      "ColdPool: ALL=1422896, SHALLOW=1079501, DEEP=29434\n",
      "Mean Cloudbase is: 1.21 km\n",
      "\n",
      "Min Cloudbase is: 1.18 km\n",
      "\n",
      "Mean LFC is: 1.86 km\n",
      "\n",
      "Mean LCL is: 1.77 km\n",
      "\n",
      "Min LFC is: 1.25 km\n",
      "\n",
      "Min LCL is: 1.23 km\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Loading in Tracked Parcels Info\n",
    "trackedArrays,LevelsDictionary = TrackedParcel_Loading_Class.LoadingSubsetParcelData(ModelData,DataManager,\n",
    "                                                         Results_InputOutput_Class)\n",
    "trackedArrays.pop(\"ColdPool\") #removing this extra unneeded category\n",
    "\n",
    "#needed parameters\n",
    "timesteps_per_min = 1/(ModelData.time[1].item()/1e9/60 )\n",
    "timesteps_per_hour = int(60*timesteps_per_min)\n",
    "qcqi_thresh = 1e-6\n",
    "# time_bins = np.arange(0,(0-timesteps_per_hour)-1,-1)[::-1]\n",
    "time_bins = np.arange(0.5, -timesteps_per_hour-1.5, -1)[::-1]\n",
    "\n",
    "#variables \n",
    "varNames = [\"QV\", \"QCQI\", \"W\", \"THETA_v\"]\n",
    "\n",
    "#property bins for each variable\n",
    "n_bins = 500\n",
    "property_bins_Dictionary = {\n",
    "    \"QV\":    np.linspace(0, 20/1e3, n_bins),        # water vapor mixing ratio\n",
    "    \"QCQI\":  np.linspace(1e-6, 1e-3, n_bins),         # cloud+ice mixing ratio\n",
    "    \"W\":     np.linspace(-5, 10, n_bins),         # vertical velocity bins\n",
    "    \"THETA_v\":    np.linspace(300, 320, n_bins),       # potential temperature\n",
    "}\n",
    "zBins_km_g = [\n",
    "    (0, 3),\n",
    "    \n",
    "    (0, 1),\n",
    "    (1, 3)]\n",
    "zBins_km_c = [\n",
    "    (0, 7),\n",
    "    \n",
    "    (1, 3),\n",
    "    (3, 5),\n",
    "    (5, 7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3bbd35-57dc-444d-a94d-509e179efd53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for t in tqdm(loop_elements, desc=\"Processing\"):\n",
    "    if t <= timesteps_per_hour:\n",
    "        print(f\"skipping time {t} since too close to first hour\")\n",
    "        continue\n",
    "        \n",
    "    print(\"#\" * 40,\"\\n\",f\"Processing timestep {t}/{loop_elements[-1]}\")\n",
    "    timeString = ModelData.timeStrings[t]\n",
    "\n",
    "    #Forming Dictionary for Profile Arrays for current timestep\n",
    "    trackedProfileArrays = CopyStructure(trackedArrays)\n",
    "    histogramsDictionary = InitializeHistograms(trackedProfileArrays,varNames, time_bins,zBins_km_g,zBins_km_c, property_bins_Dictionary)\n",
    "    \n",
    "    #getting variable data\n",
    "    Z,Y,X = GetSpatialData(t)\n",
    "    A_g,A_c = GetLangrangianBinaryArray(t)\n",
    "    A_g_Prior,A_c_Prior = GetLangrangianBinaryArray(t-1)\n",
    "    \n",
    "    #making tracked profiles\n",
    "    print(\"MAKING TRACKED PROFILES\")\n",
    "    histogramsDictionary = MakeTrackedProfiles(trackedArrays,histogramsDictionary,property_bins_Dictionary,varNames,\n",
    "                                               Z,Y,X,t, A_g,A_c,A_g_Prior,A_c_Prior,\n",
    "                                               zBins_km_g,zBins_km_c)\n",
    "    \n",
    "    #saving tracked profiles for current timestep\n",
    "    TrackedProfiles_DataLoading_CLASS.SaveProfile(ModelData,DataManager_TrackedProfiles, histogramsDictionary, dataName=\"EntrainmentTrackback\", t=t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4e8f899-20fc-4c32-ab90-868f713c9d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "#RECOMBINE SEPERATE JOB_ARRAYS AFTER\n",
    "recombine=False #KEEP FALSE WHEN JOBARRAY IS RUNNING\n",
    "# recombine=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d0dc44c-f952-4c49-835f-ac33dc413b90",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "def RecombineProfiles(ModelData, DataManager):\n",
    "    \"\"\"\n",
    "    Combine tracked profiles across all timesteps using the first as a template.\n",
    "    \"\"\"\n",
    "    print(f\"Recombining {ModelData.Ntime} TrackedProfiles files...\\n\")\n",
    "\n",
    "    histogramsDictionary_combined = None\n",
    "\n",
    "    for t in tqdm(range(ModelData.Ntime), desc=\"Combining Profiles\", unit=\"timestep\"):\n",
    "\n",
    "        if t <= timesteps_per_hour:\n",
    "            print(f\"skipping time {t} since too close to first hour\")\n",
    "            continue\n",
    "        \n",
    "        histogramsDictionary = TrackedProfiles_DataLoading_CLASS.LoadProfile(ModelData, DataManager, dataName=\"EntrainmentTrackback\", t=t)\n",
    "         \n",
    "        # --- initialize on first timestep ---\n",
    "        if histogramsDictionary_combined is None:\n",
    "            histogramsDictionary_combined = copy.deepcopy(histogramsDictionary)\n",
    "            continue\n",
    "    \n",
    "        # --- accumulate later timesteps ---\n",
    "        for key1 in histogramsDictionary:\n",
    "            for key2 in histogramsDictionary[key1]:\n",
    "                for varName in histogramsDictionary[key1][key2]:\n",
    "                    for mode in histogramsDictionary[key1][key2][varName]:\n",
    "                        for zKey in histogramsDictionary[key1][key2][varName][mode]:\n",
    "                            histogramsDictionary_combined[key1][key2][varName][mode][zKey] += (\n",
    "                                histogramsDictionary[key1][key2][varName][mode][zKey]\n",
    "                            )\n",
    "    return histogramsDictionary_combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bab6f30d-611f-4f08-a484-65c89e142f7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recombining 661 TrackedProfiles files...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Combining Profiles:   0%|          | 0/661 [00:00<?, ?timestep/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping time 0 since too close to first hour\n",
      "skipping time 1 since too close to first hour\n",
      "skipping time 2 since too close to first hour\n",
      "skipping time 3 since too close to first hour\n",
      "skipping time 4 since too close to first hour\n",
      "skipping time 5 since too close to first hour\n",
      "skipping time 6 since too close to first hour\n",
      "skipping time 7 since too close to first hour\n",
      "skipping time 8 since too close to first hour\n",
      "skipping time 9 since too close to first hour\n",
      "skipping time 10 since too close to first hour\n",
      "skipping time 11 since too close to first hour\n",
      "skipping time 12 since too close to first hour\n",
      "skipping time 13 since too close to first hour\n",
      "skipping time 14 since too close to first hour\n",
      "skipping time 15 since too close to first hour\n",
      "skipping time 16 since too close to first hour\n",
      "skipping time 17 since too close to first hour\n",
      "skipping time 18 since too close to first hour\n",
      "skipping time 19 since too close to first hour\n",
      "skipping time 20 since too close to first hour\n",
      "skipping time 21 since too close to first hour\n",
      "skipping time 22 since too close to first hour\n",
      "skipping time 23 since too close to first hour\n",
      "skipping time 24 since too close to first hour\n",
      "skipping time 25 since too close to first hour\n",
      "skipping time 26 since too close to first hour\n",
      "skipping time 27 since too close to first hour\n",
      "skipping time 28 since too close to first hour\n",
      "skipping time 29 since too close to first hour\n",
      "skipping time 30 since too close to first hour\n",
      "skipping time 31 since too close to first hour\n",
      "skipping time 32 since too close to first hour\n",
      "skipping time 33 since too close to first hour\n",
      "skipping time 34 since too close to first hour\n",
      "skipping time 35 since too close to first hour\n",
      "skipping time 36 since too close to first hour\n",
      "skipping time 37 since too close to first hour\n",
      "skipping time 38 since too close to first hour\n",
      "skipping time 39 since too close to first hour\n",
      "skipping time 40 since too close to first hour\n",
      "skipping time 41 since too close to first hour\n",
      "skipping time 42 since too close to first hour\n",
      "skipping time 43 since too close to first hour\n",
      "skipping time 44 since too close to first hour\n",
      "skipping time 45 since too close to first hour\n",
      "skipping time 46 since too close to first hour\n",
      "skipping time 47 since too close to first hour\n",
      "skipping time 48 since too close to first hour\n",
      "skipping time 49 since too close to first hour\n",
      "skipping time 50 since too close to first hour\n",
      "skipping time 51 since too close to first hour\n",
      "skipping time 52 since too close to first hour\n",
      "skipping time 53 since too close to first hour\n",
      "skipping time 54 since too close to first hour\n",
      "skipping time 55 since too close to first hour\n",
      "skipping time 56 since too close to first hour\n",
      "skipping time 57 since too close to first hour\n",
      "skipping time 58 since too close to first hour\n",
      "skipping time 59 since too close to first hour\n",
      "skipping time 60 since too close to first hour\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Combining Profiles: 100%|██████████| 661/661 [02:57<00:00,  3.72timestep/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved output to /mnt/lustre/koa/koastore/torri_group/air_directory/Projects/DCI-Project/Code/OUTPUT/Project_Algorithms/Tracked_Profiles/1km_1min_95nz/Tracked_Profiles/TrackedProfiles_EntrainmentTrackback_1km_1min_95nz_combined.pkl \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if recombine==True:\n",
    "\n",
    "    histogramsDictionary_combined = RecombineProfiles(ModelData, DataManager_TrackedProfiles)\n",
    "    TrackedProfiles_DataLoading_CLASS.SaveProfile(ModelData,DataManager_TrackedProfiles, \n",
    "                                                  histogramsDictionary_combined, dataName=\"EntrainmentTrackback\", t='combined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ae7f95-4705-4085-a510-ef5f5e5d33a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa1def83-2cb1-4c73-8c2f-71ed504dbcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "#PLOTTING FUNCTIONS\n",
    "plotting=False\n",
    "plotting=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fca27306-32b1-4d44-8ef2-740897527302",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Back In\n",
    "if plotting:\n",
    "    histogramsDictionary_combined = TrackedProfiles_DataLoading_CLASS.LoadProfile(ModelData,DataManager_TrackedProfiles, dataName=\"EntrainmentTrackback\", t='combined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "838048c1-600d-492b-9e2f-bc187537021e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def NormalizeHistogram(histogram):\n",
    "    histogram_sum = histogram.sum(axis=1, keepdims=True)\n",
    "    histogram_normalized = np.divide(histogram,histogram_sum, \n",
    "                          out=np.zeros_like(histogram, dtype=float),\n",
    "                          where=histogram_sum != 0)\n",
    "    return histogram_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "132b4c34-fa38-4c92-8852-ed01dcbffa51",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def CombinedPlot_PropertyHistogram_V1(parcelType,mode,zKey,\n",
    "                                      plotType=\"contour\",normalize = True):\n",
    "    mins=ModelData.time[1].item()/1e9/60\n",
    "    \n",
    "    varNames     = [\"QV\", \"QCQI\", \"W\", \"THETA_v\"]\n",
    "    parcelDepths = [\"ALL\", \"SHALLOW\", \"DEEP\"]\n",
    "\n",
    "    nrows = len(parcelDepths)\n",
    "    ncols = len(varNames)\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows, ncols,\n",
    "        figsize=(4.5 * ncols, 3.5 * nrows),\n",
    "        constrained_layout=True\n",
    "    )\n",
    "\n",
    "    for i, parcelDepth in enumerate(parcelDepths):\n",
    "        for j, varName in enumerate(varNames):\n",
    "\n",
    "            ax = axes[i, j]\n",
    "\n",
    "            a = histogramsDictionary_combined[parcelType][parcelDepth][varName][mode][zKey]\n",
    "\n",
    "            if normalize:\n",
    "                a = NormalizeHistogram(a)\n",
    "                a *= 100\n",
    "                colorbarTitle = \"Frequency (%)\" if j == ncols - 1 else \"\"\n",
    "            else:\n",
    "                colorbarTitle = \"Count\" if j == ncols - 1 else \"\"\n",
    "\n",
    "            x = mins * time_bins\n",
    "            y = property_bins_Dictionary[varName]\n",
    "\n",
    "            x_centers = 0.5 * (x[:-1] + x[1:])\n",
    "            y_centers = 0.5 * (y[:-1] + y[1:])\n",
    "            X, Y = np.meshgrid(x_centers, y_centers)\n",
    "\n",
    "            multiplier = 1e3 if varName in [\"QV\", \"QCQI\"] else 1\n",
    "\n",
    "            if plotType == \"contour\":\n",
    "                plotObject = ax.contourf(\n",
    "                    X,\n",
    "                    multiplier * Y,\n",
    "                    a.T,\n",
    "                    cmap=\"turbo\",\n",
    "                    levels=20\n",
    "                )\n",
    "            else:\n",
    "                plotObject = ax.pcolormesh(\n",
    "                    x,\n",
    "                    multiplier * y,\n",
    "                    a.T,\n",
    "                    cmap=\"turbo\",\n",
    "                    shading=\"auto\"\n",
    "                )\n",
    "\n",
    "            # ---- labels ----\n",
    "            if i == nrows - 1:\n",
    "                ax.set_xlabel(\"Backwards Time (mins)\")\n",
    "            if j == 0:\n",
    "                ax.set_ylabel(f\"{parcelDepth}\\n{varName}\")\n",
    "            else:\n",
    "                ax.set_ylabel(varName)\n",
    "\n",
    "            ax.set_title(varName if i == 0 else \"\")\n",
    "\n",
    "            plt.colorbar(plotObject, ax=ax, label=colorbarTitle)\n",
    "\n",
    "    plt.suptitle(\n",
    "        f\"Parcel History Histograms ({parcelType}) ({zKey.replace('_', '-', 1).split(\"_\")[0]})\",\n",
    "        fontsize=16\n",
    "    )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2089900-3af0-42e5-a25b-a01118bf21b5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def GetPlottingDirectory(plotFileName, plotType):\n",
    "    plottingDirectory = mainCodeDirectory=os.path.join(mainDirectory,\"Code\",\"PLOTTING\")\n",
    "    \n",
    "    specificPlottingDirectory = os.path.join(plottingDirectory, plotType, \n",
    "                                             f\"{ModelData.res}_{ModelData.t_res}_{ModelData.Nz_str}nz\")\n",
    "    os.makedirs(specificPlottingDirectory, exist_ok=True)\n",
    "\n",
    "    plottingFileName=os.path.join(specificPlottingDirectory, plotFileName)\n",
    "\n",
    "    return plottingFileName\n",
    "    \n",
    "def SaveFigure(fig,fileName,\n",
    "               plotType=f\"Project_Algorithms/Tracked_Profiles/Tracked_Profiles_EntrainmentTrackback\"):\n",
    "    plotFileName = f\"{fileName}_{ModelData.res}_{ModelData.t_res}_{ModelData.Np_str}.jpg\"\n",
    "    plottingFileName = GetPlottingDirectory(plotFileName, plotType)\n",
    "    \n",
    "    print(f\"Saving figure to {plottingFileName}\")\n",
    "    fig.savefig(plottingFileName, dpi=300, bbox_inches='tight')\n",
    "    plt.close(fig) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d97d2c1a-2eaf-4176-885d-55f80fd71389",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "#PLOTTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45504a9f-3a24-42dd-8c3c-f7d44560b9c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if plotting:\n",
    "    parcelTypes = [\"CL\",\"nonCL\",\"SBF\"]\n",
    "    for parcelType in tqdm(parcelTypes):\n",
    "        for mode, zBins_km in (\n",
    "                (\"g\", zBins_km_g),\n",
    "                (\"c\", zBins_km_c)):\n",
    "            \n",
    "            for z1, z2 in zBins_km:\n",
    "                zKey = f\"{z1}_{z2}km_hist2d\"\n",
    "                fig = CombinedPlot_PropertyHistogram_V1(parcelType,mode,zKey)\n",
    "                fileName = f\"EntrainmentTrackback_PropertyHistogram_{parcelType}_{mode}_{zKey}\"\n",
    "                SaveFigure(fig,fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c9bd8c-cd1a-4665-9f4d-94fd1f046090",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7958bb-b7e5-4bf8-a2f7-11182d15a9a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c7f4b8-d9b3-4bc1-9368-4058b38fac51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39376703-9b0d-4797-a73d-37656faac1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "#DEPRECATED RECOMBINE (before adding mode and zKey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b667d4be-3ee9-4ef9-ae57-4a5ba6d2f372",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# import copy\n",
    "# def RecombineProfiles(ModelData, DataManager):\n",
    "#     \"\"\"\n",
    "#     Combine tracked profiles across all timesteps using the first as a template.\n",
    "#     \"\"\"\n",
    "#     print(f\"Recombining {ModelData.Ntime} TrackedProfiles files...\\n\")\n",
    "\n",
    "#     histogramsDictionary_combined = None\n",
    "\n",
    "#     for t in tqdm(range(ModelData.Ntime), desc=\"Combining Profiles\", unit=\"timestep\"):\n",
    "\n",
    "#         if t <= timesteps_per_hour:\n",
    "#             print(f\"skipping time {t} since too close to first hour\")\n",
    "#             continue\n",
    "        \n",
    "#         histogramsDictionary = TrackedProfiles_DataLoading_CLASS.LoadProfile(ModelData, DataManager, dataName=\"EntrainmentTrackback\", t=t)\n",
    "         \n",
    "#         # --- initialize on first timestep ---\n",
    "#         if histogramsDictionary_combined is None:\n",
    "#             histogramsDictionary_combined = copy.deepcopy(histogramsDictionary)\n",
    "#             continue\n",
    "    \n",
    "#         # --- accumulate later timesteps ---\n",
    "#         for key1 in histogramsDictionary:\n",
    "#             for key2 in histogramsDictionary[key1]:\n",
    "#                 for arrayName in histogramsDictionary[key1][key2]:\n",
    "#                     histogramsDictionary_combined[key1][key2][arrayName] += (\n",
    "#                         histogramsDictionary[key1][key2][arrayName]\n",
    "#                     )\n",
    "#     return histogramsDictionary_combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0c7d0d-3f23-4fa4-9f89-c1252c697648",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "#DEPRECATED PLOT TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b17bbc0-99c2-47a4-bdc3-e27a6e98ba70",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def CombinedPlot_PropertyHistogram_V2(parcelType,\n",
    "#                                      plotType=\"line\",\n",
    "#                                      normalize=True): #an idea for clearness, created a weighted mean plot #CURRENTLY DEPRECATED\n",
    "\n",
    "#     mins = ModelData.time[1].item() / 1e9 / 60\n",
    "\n",
    "#     varNames     = [\"QV\", \"QCQI\", \"W\", \"THETA_v\"]\n",
    "#     parcelDepths = [\"ALL\", \"SHALLOW\", \"DEEP\"]\n",
    "\n",
    "#     nrows = len(parcelDepths)\n",
    "#     ncols = len(varNames)\n",
    "\n",
    "#     fig, axes = plt.subplots(\n",
    "#         nrows, ncols,\n",
    "#         figsize=(4.5 * ncols, 3.5 * nrows),\n",
    "#         constrained_layout=True\n",
    "#     )\n",
    "\n",
    "#     for i, parcelDepth in enumerate(parcelDepths):\n",
    "#         for j, varName in enumerate(varNames):\n",
    "\n",
    "#             ax = axes[i, j]\n",
    "\n",
    "#             # ---- load histogram ----\n",
    "#             # expected shape: (n_time_bins, n_property_bins)\n",
    "#             a = histogramsDictionary_combined[parcelType][parcelDepth][\n",
    "#                 f\"{varName}_hist2d\"\n",
    "#             ]\n",
    "\n",
    "#             if normalize:\n",
    "#                 a = NormalizeHistogram(a)\n",
    "#                 a *= 100.0\n",
    "\n",
    "#             # ---- bins ----\n",
    "#             x = mins * time_bins\n",
    "#             y = property_bins_Dictionary[varName]\n",
    "\n",
    "#             x_centers = 0.5 * (x[:-1] + x[1:])\n",
    "#             y_centers = 0.5 * (y[:-1] + y[1:])\n",
    "\n",
    "#             multiplier = 1e3 if varName in [\"QV\", \"QCQI\"] else 1.0\n",
    "\n",
    "#             # ---- weighted mean over property bins ----\n",
    "#             counts = a.T                     # (n_property_bins, n_time_bins)\n",
    "#             total  = counts.sum(axis=0)      # per time bin\n",
    "\n",
    "#             mean_y = np.full_like(total, np.nan, dtype=float)\n",
    "#             valid  = total > 0\n",
    "\n",
    "#             mean_y[valid] = (\n",
    "#                 (counts[:, valid] * y_centers[:, None]).sum(axis=0)\n",
    "#                 / total[valid]\n",
    "#             )\n",
    "\n",
    "#             # ---- plot ----\n",
    "#             ax.plot(\n",
    "#                 x_centers,\n",
    "#                 multiplier * mean_y,\n",
    "#                 lw=2,\n",
    "#                 color=\"k\"\n",
    "#             )\n",
    "\n",
    "#             # ---- labels ----\n",
    "#             if i == nrows - 1:\n",
    "#                 ax.set_xlabel(\"Backwards Time (mins)\")\n",
    "#             if j == 0:\n",
    "#                 ax.set_ylabel(f\"{parcelDepth}\\n{varName}\")\n",
    "#             else:\n",
    "#                 ax.set_ylabel(varName)\n",
    "\n",
    "#             ax.set_title(varName if i == 0 else \"\")\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "#     #ALIGNING AXIS LIMITS\n",
    "#     for j in range(ncols):\n",
    "#         colAxes = list(axes[:, j])   \n",
    "#         MatchAxisLimits_V2(colAxes, dim=\"y\")\n",
    " \n",
    "#     plt.suptitle(\n",
    "#         f\"Parcel History (Weighted Mean) ({parcelType})\",\n",
    "#         fontsize=16\n",
    "#     )\n",
    "\n",
    "#     return fig\n",
    "\n",
    "# if plotting:\n",
    "#     for parcelType in tqdm(parcelTypes):\n",
    "#         fig = CombinedPlot_PropertyHistogram_V2(parcelType)\n",
    "#         fileName = f\"EntrainmentTrackback_PropertyHistogram_WeightedMean_{parcelType}\"\n",
    "#         SaveFigure(fig,fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dc9292-a103-4f05-91b7-f1c3c889d9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "#DEPRECATED METHOD (LAST CLOUD TIME HISTOGRAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b781902d-8177-4fba-b9d2-abc6ef05d260",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def InitializeHistograms(trackedArrays, varNames, time_bins, property_bins_Dictionary):\n",
    "#     \"\"\"\n",
    "#     Create a nested structure matching trackedArrays,\n",
    "#     with empty histogram arrays for each variable:\n",
    "#         - var_hist2d\n",
    "#         - var_parcel_last_time_hist2d\n",
    "#     \"\"\"\n",
    "    \n",
    "#     histogramsDictionary = {}\n",
    "#     n_time = len(time_bins) - 1\n",
    "    \n",
    "#     for category, depth_dict in trackedArrays.items():  # e.g. 'CL', 'SBF'\n",
    "#         histogramsDictionary[category] = {}\n",
    "\n",
    "#         for depth_type in depth_dict.keys():  # e.g. 'ALL', 'SHALLOW', 'DEEP'\n",
    "#             histogramsDictionary[category][depth_type] = {}\n",
    "\n",
    "#             for varName in varNames:\n",
    "\n",
    "#                 # number of property bins for this variable\n",
    "#                 n_prop = len(property_bins_Dictionary[varName]) - 1\n",
    "\n",
    "#                 # initialize empty histograms\n",
    "#                 histogramsDictionary[category][depth_type][f\"{varName}_hist2d\"] = \\\n",
    "#                     np.zeros((n_time, n_prop))\n",
    "\n",
    "#                 # histogramsDictionary[category][depth_type][f\"{varName}_parcel_last_time_hist2d\"] = \\ #deprecated\n",
    "#                 #     np.zeros((n_time, n_prop))\n",
    "#     return histogramsDictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f27443-1310-458b-9e67-8d55cd368159",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# #FUNCTIONS FOR MAKING LAST CLOUD TIME HISTOGRAM\n",
    "\n",
    "# def UpdateLastCloudState(last_cloud_time,last_property_value,\n",
    "#                          VARs,collapsed,relative_time,count,\n",
    "#                          qcqi_thresh=1e-6):\n",
    "#     #GETTING LAST TIME PARCEL IN CLOUD\n",
    "#     ##########\n",
    "#     if count > 0: #make sure doesn't occur at \n",
    "#         # QCQI/QV for all entrained parcels\n",
    "#         qcqi_values = VARs[\"QCQI\"][collapsed]\n",
    "\n",
    "#         # Which parcels currently in cloud\n",
    "#         in_cloud_now = (qcqi_values >= qcqi_thresh)\n",
    "        \n",
    "#         # Which parcels have NOT been assigned a last-cloud-time yet\n",
    "#         not_recorded = np.isnan(last_cloud_time)\n",
    "#         # Newly identified parcels whose LAST cloud time is t_back\n",
    "#         new_cloud_hits = in_cloud_now & not_recorded\n",
    "\n",
    "#         # Update the last-cloud-time + variables at that time\n",
    "#         last_cloud_time[new_cloud_hits] = relative_time\n",
    "#         for varName, array in VARs.items():\n",
    "#             property_values = array[collapsed]\n",
    "#             last_property_value[varName][new_cloud_hits] = property_values[new_cloud_hits]\n",
    "#     ##########\n",
    "\n",
    "\n",
    "# def MakeLastCloudHistogram(histogramsDictionary,\n",
    "#                            key1,key2,\n",
    "#                            last_cloud_time,last_property_value,\n",
    "#                            varNames,\n",
    "#                            property_bins_Dictionary,time_bins):\n",
    "\n",
    "#     # GETTING LAST TIME PARCEL IN CLOUD HISTOGRAM\n",
    "#     ##########\n",
    "#     valid = ~np.isnan(last_cloud_time)\n",
    "#     if not np.any(valid):\n",
    "#         return\n",
    "\n",
    "#     for varName in varNames:\n",
    "#         property_values = last_property_value[varName][valid]\n",
    "#         property_bins   = property_bins_Dictionary[varName]\n",
    "        \n",
    "#         parcel_last_time_hist2d, _, _ = np.histogram2d(\n",
    "#             last_cloud_time[valid],\n",
    "#             property_values,\n",
    "#             bins=(time_bins, property_bins)\n",
    "#         )\n",
    "#         histogramsDictionary[key1][key2][f\"{varName}_parcel_last_time_hist2d\"] = parcel_last_time_hist2d\n",
    "#     ##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b6bf4c-2090-47d9-982d-1342d4228952",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def MakeTrackedProfiles(trackedArrays,histogramsDictionary,property_bins_Dictionary,varNames,Z,Y,X,t, A_g,A_c,A_g_Prior,A_c_Prior,\n",
    "#                         printstatement=True):\n",
    "#     \"\"\"\n",
    "#     Update profileArraysDictionary with variable data for parcels active at time t.\n",
    "#     Accumulates sums and counts in both profile_array and profile_array_squares.\n",
    "#     \"\"\"\n",
    "#     #CALCULATING\n",
    "#     for key1, subdict in trackedArrays.items():         # e.g. 'CL', 'SBF'\n",
    "#         print(\"\\t\",f'working on {key1}')\n",
    "#         for key2, trackedArray in subdict.items():           # e.g. 'ALL', 'DEEP'\n",
    "#             print(\"\\t\\t\",f'working on {key2}')\n",
    "    \n",
    "#             #Part 1: getting parcels in trackedArray to run through\n",
    "#             if printstatement: print(f\"Part 1: getting parcels in trackedArray to run through\")\n",
    "                \n",
    "#             _, selectedPs, leftRightIndexes = GetParcelNumbers(trackedArray, t) #get parcels that are counted at time t\n",
    "#             if printstatement: print(f\"\\tRunning for {len(selectedPs)} Parcels\")\n",
    "            \n",
    "#             #getting Z data\n",
    "#             zLevels = Z[selectedPs]\n",
    "#             yLevels = Y[selectedPs]\n",
    "#             xLevels = X[selectedPs]\n",
    "\n",
    "#             #Part 2: find which other parcels exist in each grid box\n",
    "#             if printstatement: print(f\"Part 2: find which other parcels exist in each grid box\")\n",
    "                \n",
    "#             # Step a: compute spatial matches once\n",
    "#             if printstatement: print(\"\\tStep a: compute spatial matches once\") #SLOW POINT HERE\n",
    "#             gridboxMatches = GetGridBoxMatches_V2(Z,Y,X, zLevels,yLevels,xLevels)\n",
    "#             if gridboxMatches is None:\n",
    "#                 continue\n",
    "\n",
    "#             #Part 3: find which of those parcels were entrained into a general/cloudy updraft\n",
    "#             if printstatement: print(f\"Part 3: find which of those parcels were entrained into a general/cloudy updraft\")\n",
    "            \n",
    "#             # Step a: compute entrainment masks\n",
    "#             if printstatement: print(\"\\tStep a: compute entrainment masks\")\n",
    "#             mask_c = (A_c & (~A_c_Prior)).astype(bool)\n",
    "\n",
    "#             # Step b: apply masks to find all parcels\n",
    "#             if printstatement: print(\"\\tStep b: apply masks to find all parcels\") #SLOW POINT HERE\n",
    "#             collapsed = GetWhereOtherEntrainedParcels_V2(mask_c,gridboxMatches)\n",
    "#             if collapsed is None:\n",
    "#                 continue\n",
    "\n",
    "#             # Step c: track parcels back (last 30 minutes) and read properties\n",
    "#             if printstatement: print(\"\\tStep c: track parcels back (last 30 minutes) and read properties\")\n",
    "#             ##GETTING LAST TIME PARCEL IN CLOUD #deprecated\n",
    "#             # last_cloud_time = np.full(len(collapsed), np.nan) #deprecated\n",
    "#             # last_property_value = {varName: np.full(len(collapsed), np.nan) for varName in varNames} #deprecated\n",
    "            \n",
    "#             trackTimes = np.arange(t,(t-timesteps_per_hour)-1,-1)\n",
    "#             for count, t_back in enumerate(tqdm(trackTimes,desc=\"\\t\\tTracking back parcels\",leave=False)):\n",
    "#                 relative_time = t_back - t\n",
    "\n",
    "#                 VARs = MakeDataDictionary(varNames, t_back)   \n",
    "\n",
    "#                 for varName, array in VARs.items():\n",
    "#                     #GETTING PROPERTY HISTOGRAMS\n",
    "#                     AccumulatePropertyHistogram(histogramsDictionary,\n",
    "#                                                 key1,key2,varName,\n",
    "#                                                 array,collapsed,relative_time,\n",
    "#                                                 property_bins_Dictionary,time_bins)\n",
    "\n",
    "#                 # # GETTING LAST TIME PARCEL IN CLOUD #***DEPRECATED***\n",
    "#                 # UpdateLastCloudState(last_cloud_time,last_property_value,\n",
    "#                 #                      VARs,collapsed,relative_time,count,\n",
    "#                 #                      qcqi_thresh=1e-6)\n",
    "\n",
    "#             # # GETTING LAST TIME PARCEL IN CLOUD HISTOGRAM #***DEPRECATED***\n",
    "#             # MakeLastCloudHistogram(histogramsDictionary,\n",
    "#             #                        key1,key2,\n",
    "#             #                        last_cloud_time,last_property_value,\n",
    "#             #                        varNames,\n",
    "#             #                        property_bins_Dictionary,time_bins)\n",
    "#     return histogramsDictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829ef121-8e0e-4af3-8ba7-088357310d29",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def CombinedPlot_LastCloudTimeHistogram_V1(parcelType,\n",
    "#                                         plotType=\"contour\",normalize=True):\n",
    "\n",
    "#     mins=ModelData.time[1].item()/1e9/60\n",
    "\n",
    "#     varNames     = [\"QV\", \"QCQI\", \"W\", \"THETA_v\"]\n",
    "#     parcelDepths = [\"ALL\", \"SHALLOW\", \"DEEP\"]\n",
    "\n",
    "#     nrows = len(parcelDepths)\n",
    "#     ncols = len(varNames)\n",
    "\n",
    "#     fig, axes = plt.subplots(\n",
    "#         nrows, ncols,\n",
    "#         figsize=(4.5 * ncols, 3.5 * nrows),\n",
    "#         constrained_layout=True\n",
    "#     )\n",
    "\n",
    "#     for i, parcelDepth in enumerate(parcelDepths):\n",
    "#         for j, varName in enumerate(varNames):\n",
    "\n",
    "#             ax = axes[i, j]\n",
    "\n",
    "#             a = histogramsDictionary_combined[parcelType][parcelDepth][\n",
    "#                 f\"{varName}_parcel_last_time_hist2d\"\n",
    "#             ]\n",
    "\n",
    "#             if normalize:\n",
    "#                 a = NormalizeHistogram(a)\n",
    "#                 a *= 100\n",
    "#                 colorbarTitle = \"Frequency (%)\" if j == ncols - 1 else \"\"\n",
    "#             else:\n",
    "#                 colorbarTitle = \"Count\" if j == ncols - 1 else \"\"\n",
    "\n",
    "#             x = mins * time_bins\n",
    "#             y = property_bins_Dictionary[varName]\n",
    "\n",
    "#             x_centers = 0.5 * (x[:-1] + x[1:])\n",
    "#             y_centers = 0.5 * (y[:-1] + y[1:])\n",
    "#             X, Y = np.meshgrid(x_centers, y_centers)\n",
    "\n",
    "#             multiplier = 1e3 if varName in [\"QV\", \"QCQI\"] else 1\n",
    "#             colorbarLevels = 20 if varName not in [\"QCQI\"] else 20#np.linspace(0, 10)\n",
    "\n",
    "#             if plotType == \"contour\":\n",
    "#                 plotObject = ax.contourf(\n",
    "#                     X,\n",
    "#                     multiplier * Y,\n",
    "#                     a.T,\n",
    "#                     cmap=\"turbo\",\n",
    "#                     levels=colorbarLevels\n",
    "#                 )\n",
    "#             else:\n",
    "#                 plotObject = ax.pcolormesh(\n",
    "#                     x,\n",
    "#                     multiplier * y,\n",
    "#                     a.T,\n",
    "#                     cmap=\"turbo\",\n",
    "#                     shading=\"auto\"\n",
    "#                 )\n",
    "\n",
    "#             # ---- labels ----\n",
    "#             if i == nrows - 1:\n",
    "#                 ax.set_xlabel(\"Backwards Time (mins)\")\n",
    "#             if j == 0:\n",
    "#                 ax.set_ylabel(f\"{parcelDepth}\\n{varName}\")\n",
    "#             else:\n",
    "#                 ax.set_ylabel(varName)\n",
    "\n",
    "#             ax.set_title(varName if i == 0 else \"\")\n",
    "\n",
    "#             plt.colorbar(plotObject, ax=ax, label=colorbarTitle)\n",
    "\n",
    "#     plt.suptitle(\n",
    "#         f\"Last-Cloud-Time Histograms ({parcelType})\",\n",
    "#         fontsize=16\n",
    "#     )\n",
    "#     return fig\n",
    "\n",
    "# if plotting:\n",
    "#     for parcelType in tqdm(parcelTypes):\n",
    "#         fig = CombinedPlot_LastCloudTimeHistogram_V1(parcelType)\n",
    "#         fileName = f\"EntrainmentTrackback_LastCloudTimeHistogram_{parcelType}\"\n",
    "#         SaveFigure(fig,fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2312389-6f23-4471-8864-a791b3a4b654",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def CombinedPlot_LastCloudTimeHistogram_V2(parcelType,\n",
    "#                                            plotType=\"line\",\n",
    "#                                            normalize=True):\n",
    "\n",
    "#     mins = ModelData.time[1].item() / 1e9 / 60\n",
    "\n",
    "#     varNames     = [\"QV\", \"QCQI\", \"W\", \"THETA_v\"]\n",
    "#     parcelDepths = [\"ALL\", \"SHALLOW\", \"DEEP\"]\n",
    "\n",
    "#     nrows = len(parcelDepths)\n",
    "#     ncols = len(varNames)\n",
    "\n",
    "#     fig, axes = plt.subplots(\n",
    "#         nrows, ncols,\n",
    "#         figsize=(4.5 * ncols, 3.5 * nrows),\n",
    "#         constrained_layout=True\n",
    "#     )\n",
    "\n",
    "#     for i, parcelDepth in enumerate(parcelDepths):\n",
    "#         for j, varName in enumerate(varNames):\n",
    "\n",
    "#             ax = axes[i, j]\n",
    "\n",
    "#             # ---- load histogram ----\n",
    "#             # shape after transpose: (n_property_bins, n_time_bins)\n",
    "#             a = histogramsDictionary_combined[parcelType][parcelDepth][\n",
    "#                 f\"{varName}_parcel_last_time_hist2d\"\n",
    "#             ].T\n",
    "\n",
    "#             # ---- bins ----\n",
    "#             x = mins * time_bins\n",
    "#             y = property_bins_Dictionary[varName]\n",
    "\n",
    "#             x_centers = 0.5 * (x[:-1] + x[1:])\n",
    "#             y_centers = 0.5 * (y[:-1] + y[1:])\n",
    "\n",
    "#             multiplier = 1e3 if varName in [\"QV\", \"QCQI\"] else 1\n",
    "\n",
    "#             # ---- weighted mean over property bins ----\n",
    "#             counts = a\n",
    "#             total  = counts.sum(axis=0)  # per time bin\n",
    "\n",
    "#             mean_y = np.full_like(total, np.nan, dtype=float)\n",
    "#             valid  = total > 0\n",
    "\n",
    "#             mean_y[valid] = (\n",
    "#                 (counts[:, valid] * y_centers[:, None]).sum(axis=0)\n",
    "#                 / total[valid]\n",
    "#             )\n",
    "\n",
    "#             # ---- plot ----\n",
    "#             ax.plot(\n",
    "#                 x_centers,\n",
    "#                 multiplier * mean_y,\n",
    "#                 lw=2,\n",
    "#                 color=\"k\"\n",
    "#             )\n",
    "\n",
    "#             # ---- labels ----\n",
    "#             if i == nrows - 1:\n",
    "#                 ax.set_xlabel(\"Backwards Time (mins)\")\n",
    "#             if j == 0:\n",
    "#                 ax.set_ylabel(f\"{parcelDepth}\\n{varName}\")\n",
    "#             else:\n",
    "#                 ax.set_ylabel(varName)\n",
    "\n",
    "#             ax.set_title(varName if i == 0 else \"\")\n",
    "\n",
    "\n",
    "#     #ALIGNING AXIS LIMITS\n",
    "#     for j in range(ncols):\n",
    "#         colAxes = list(axes[:, j])   \n",
    "#         MatchAxisLimits_V2(colAxes, dim=\"y\")\n",
    "        \n",
    "#     plt.suptitle(\n",
    "#         f\"Last-Cloud-Time Property (Weighted Mean) ({parcelType})\",\n",
    "#         fontsize=16\n",
    "#     )\n",
    "\n",
    "#     return fig\n",
    "\n",
    "# if plotting:\n",
    "#     for parcelType in tqdm(parcelTypes):\n",
    "#         fig = CombinedPlot_LastCloudTimeHistogram_V2(parcelType)\n",
    "#         fileName = f\"EntrainmentTrackback_LastCloudTimeHistogram_WeightedMean_{parcelType}\"\n",
    "#         SaveFigure(fig,fileName)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "work"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
