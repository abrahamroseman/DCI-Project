{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e77ffcf4-41b6-4939-a5fe-71b00310d7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "#ENVIRONMENT SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1db11099-d71a-464f-b01c-34d6797ef72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "import matplotlib.gridspec as gridspec\n",
    "import xarray as xr\n",
    "\n",
    "import sys; import os; import time; from datetime import timedelta\n",
    "import pickle\n",
    "import h5py\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd960628-c670-49c9-b586-2a1aecc96c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAIN DIRECTORIES\n",
    "def GetDirectories():\n",
    "    mainDirectory='/mnt/lustre/koa/koastore/torri_group/air_directory/Projects/DCI-Project/'\n",
    "    mainCodeDirectory=os.path.join(mainDirectory,\"Code/CodeFiles/\")\n",
    "    scratchDirectory='/mnt/lustre/koa/scratch/air673/'\n",
    "    codeDirectory=os.getcwd()\n",
    "    return mainDirectory,mainCodeDirectory,scratchDirectory,codeDirectory\n",
    "\n",
    "[mainDirectory,mainCodeDirectory,scratchDirectory,codeDirectory] = GetDirectories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5465be3-bae2-4d9b-9e32-5ae8ef8577a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT CLASSES\n",
    "sys.path.append(os.path.join(mainCodeDirectory,\"2_Variable_Calculation\"))\n",
    "from CLASSES_Variable_Calculation import ModelData_Class, DataManager_Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2750bd32-beb7-4b9e-8a99-6c33e40004d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CM1 Data Summary ===\n",
      " Simulation #:   1\n",
      " Resolution:     1km\n",
      " Time step:      5min\n",
      " Vertical levels:34\n",
      " Parcels:        1e6\n",
      " Data file:      /mnt/lustre/koa/koastore/torri_group/air_directory/Projects/DCI-Project/Model/cm1r20.3/run/cm1out_1km_5min_34nz.nc\n",
      " Parcel file:    /mnt/lustre/koa/koastore/torri_group/air_directory/Projects/DCI-Project/Model/cm1r20.3/run/cm1out_pdata_1km_5min_1e6np.nc\n",
      " Time steps:     133\n",
      "========================= \n",
      "\n",
      "=== DataManager Summary ===\n",
      " inputDirectory #:   /mnt/lustre/koa/koastore/torri_group/air_directory/Projects/DCI-Project/Code/OUTPUT/Variable_Calculation/TimeSplitModelData\n",
      " outputDirectory #:   /mnt/lustre/koa/koastore/torri_group/air_directory/Projects/DCI-Project/Code/OUTPUT/Project_Algorithms/Tracking_Algorithms\n",
      " inputDataDirectory #:   /mnt/lustre/koa/koastore/torri_group/air_directory/Projects/DCI-Project/Code/OUTPUT/Variable_Calculation/TimeSplitModelData/1km_5min_34nz/ModelData\n",
      " inputParcelDirectory #:   /mnt/lustre/koa/koastore/torri_group/air_directory/Projects/DCI-Project/Code/OUTPUT/Variable_Calculation/TimeSplitModelData/1km_5min_34nz/ParcelData\n",
      " outputDataDirectory #:   /mnt/lustre/koa/koastore/torri_group/air_directory/Projects/DCI-Project/Code/OUTPUT/Project_Algorithms/Tracking_Algorithms/1km_5min_34nz/Lagrangian_UpdraftTracking\n",
      "========================= \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#data loading class\n",
    "ModelData = ModelData_Class(mainDirectory, scratchDirectory, simulationNumber=1)\n",
    "#data manager class\n",
    "DataManager = DataManager_Class(mainDirectory, scratchDirectory, ModelData.res, ModelData.t_res, ModelData.Nz_str,\n",
    "                                ModelData.Np_str, dataType=\"Tracking_Algorithms\", dataName=\"Lagrangian_UpdraftTracking\",\n",
    "                                dtype='float32',codeSection = \"Project_Algorithms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de514d0b-021a-40ac-978d-c2c711c8f773",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT FUNCTIONS\n",
    "sys.path.append(os.path.join(mainCodeDirectory,\"2_Variable_Calculation\"))\n",
    "import FUNCTIONS_Variable_Calculation\n",
    "from FUNCTIONS_Variable_Calculation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b1fa69b-ad0f-49b4-9d15-74451cea2f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT CLASSES\n",
    "sys.path.append(os.path.join(mainCodeDirectory,\"3_Project_Algorithms\",\"2_Tracking_Algorithms\"))\n",
    "from CLASSES_TrackingAlgorithms import TrackingAlgorithms_DataLoading_Class, Results_InputOutput_Class, SlurmJobArray_Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64126a32-08a8-49c9-9f3d-ef208371d458",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "#PRINTING FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7335eb9f-8fcf-4e3d-a2f0-aa00e795e64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Global variable to store original stdout\n",
    "_original_stdout = sys.stdout\n",
    "\n",
    "def BlockPrint():\n",
    "    \"\"\"Suppress all print() output.\"\"\"\n",
    "    global _original_stdout\n",
    "    sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "def RestorePrint():\n",
    "    \"\"\"Restore print() output.\"\"\"\n",
    "    global _original_stdout\n",
    "    sys.stdout.close()\n",
    "    sys.stdout = _original_stdout\n",
    "\n",
    "# NO_PRINT=False\n",
    "NO_PRINT=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cbd538d-a080-402a-a043-9fb34e95a02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "#JOBARRAY SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f356472e-c20b-4b75-b726-d7d95374737a",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "#JOB ARRAY SETUP\n",
    "################################\n",
    "# how many total jobs are being run? i.e. array=1-100 ==> num_jobs=100\n",
    "if '1e6' in ModelData.Np_str:\n",
    "    num_jobs=60 #1M parcels\n",
    "    num_slurm_jobs=10\n",
    "if '50e6' in ModelData.Np_str:\n",
    "    num_jobs=200 #50M parcels\n",
    "    num_slurm_jobs=60\n",
    "##############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "353e61b6-a852-4e84-b739-049cde5842a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "#MODEL AND ALGORITHM NUMERICAL PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6215c447-19b3-4025-9de4-7ddbeba48956",
   "metadata": {},
   "outputs": [],
   "source": [
    "times=ModelData.time/(1e9 * 60); times=times.astype(float);\n",
    "minutes=1/times[1] #1 / minutes per timestep = timesteps per minute\n",
    "kms=np.argmax(ModelData.xh-ModelData.xh[0] >= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e0ad1ff-734d-4814-86ef-8c6d73e52821",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "#DATA LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9e4ceea-0923-4775-b0b9-950fb4b501cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened dataset: /mnt/lustre/koa/koastore/torri_group/air_directory/Projects/DCI-Project/Model/cm1r20.3/run/cm1out_pdata_1km_5min_1e6np.nc\n"
     ]
    }
   ],
   "source": [
    "parcel1 = ModelData.OpenParcel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d00a5ac8-fbca-41b5-a72e-db3e539baff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = f\"/mnt/lustre/koa/koastore/torri_group/air_directory/Projects/DCI-Project/Code/OUTPUT/Variable_Calculation/LagrangianArrays/{ModelData.res}_{ModelData.t_res}_{ModelData.Nz_str}nz/Lagrangian_Binary_Array/\"\n",
    "Lagrangian_Binary_Array_Data,files = OpenMultipleSingleTimes_LagrangianArray(directory, ModelData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a466d50f-37c7-45bf-84c5-f1a1009789c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = f\"/mnt/lustre/koa/koastore/torri_group/air_directory/Projects/DCI-Project/Code/OUTPUT/Variable_Calculation/LagrangianArrays/{ModelData.res}_{ModelData.t_res}_{ModelData.Nz_str}nz/LFC/\"\n",
    "\n",
    "LFC_LCL_Data,files = OpenMultipleSingleTimes_LagrangianArray(directory, ModelData,pattern=\"LFC_*.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc6ee962-2536-485e-81ba-4fb5093478af",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "#DATA LOADING FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ff859fa-09d1-410f-8c3a-b5f8a840e45a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#SUBSETTING PARCEL DATA\n",
    "def GetData(parcel1,start_job,end_job):\n",
    "    parcel=parcel1.isel(xh=slice(start_job,end_job))\n",
    "    return parcel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a0b814b-8426-4310-a5e1-465fdb1aecf7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def GetSpatialData(Lagrangian_Binary_Array_Data, start_job,end_job):\n",
    "    parcel_z = Lagrangian_Binary_Array_Data['z'].isel(p=slice(start_job,end_job)).data.compute()\n",
    "    parcel_x = Lagrangian_Binary_Array_Data['x'].isel(p=slice(start_job,end_job)).data.compute()\n",
    "\n",
    "    parcel_w = Lagrangian_Binary_Array_Data['w'].isel(p=slice(start_job,end_job)).data.compute()\n",
    "    parcel_u = Lagrangian_Binary_Array_Data['u'].isel(p=slice(start_job,end_job)).data.compute()\n",
    "    \n",
    "    # Load the dataset by its name\n",
    "    Z = Lagrangian_Binary_Array_Data['Z'].isel(p=slice(start_job,end_job)).data.compute()\n",
    "    Y = Lagrangian_Binary_Array_Data['Y'].isel(p=slice(start_job,end_job)).data.compute()\n",
    "    X = Lagrangian_Binary_Array_Data['X'].isel(p=slice(start_job,end_job)).data.compute()\n",
    "    W = Lagrangian_Binary_Array_Data['W'].isel(p=slice(start_job,end_job)).data.compute()\n",
    "\n",
    "    return parcel_z,parcel_x,parcel_u,parcel_w,Z,Y,X,W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e428e62d-8d62-4411-b2a4-f6e84aebec56",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def GetLFCData(LFC_LCL_Data, start_job,end_job):\n",
    "    LFC = LFC_LCL_Data['LFC'].isel(p=slice(start_job,end_job)).data.compute()\n",
    "    LCL = LFC_LCL_Data['LCL'].isel(p=slice(start_job,end_job)).data.compute()\n",
    "    return LFC,LCL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d870bad5-ac84-40d8-85a4-293750f205fd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#LOADING CL MAXS FROM CL TRACKING ALGORITHM\n",
    "def Get_Conv_X(t,z,y):\n",
    "\n",
    "    timeString = ModelData.timeStrings[t]\n",
    "    outputDataDirectory=os.path.normpath(os.path.join(DataManager.outputDataDirectory,\"..\",\"Eulerian_CLTracking\"))\n",
    "    Dictionary = TrackingAlgorithms_DataLoading_Class.LoadData(ModelData, DataManager, timeString,\n",
    "                     dataName=\"Eulerian_CLTracking\",outputDataDirectory=outputDataDirectory)\n",
    "    whereCL = Dictionary[\"maxConvergence_X\"]\n",
    "    Conv_X_Max=whereCL[z,y]\n",
    "    return Conv_X_Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0dc9aece-9953-47b6-a4a5-0e03463efcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "#ALGORITHM FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68e02e69-4333-411f-8340-6781385925b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Updated Lagrangian Tracking Algorithm\n",
    "\n",
    "#Algorithm Steps:\n",
    "#(1) Find the first time a parcel is above the LFC:\n",
    "#(2) First check if the parcel ascends (w>=0.1) for another 20 minutes\n",
    "#(3) If so, find first time, the parcel slows down (w<0.1)\n",
    "#(4) If that time is when the parcel is above 750m, save it, \"forget\", and move on to next parcel\n",
    "#(5) If that time is when the parcel is below 750m, check if it is within 2km of the CL_Max found from the CL Tracking Algorithm\n",
    "#(6) If the parcel is near the CL, store in, otherwise save it, \"forget\", and move on to next parcel\n",
    "#(7) Continue to next parcel\n",
    "\n",
    "#(Also, if during, traceback, the parcel escapes the x or z boundary, \"forget\" parcel, and move on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e645e76-ec24-4464-bc25-f4d9632cf0e9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Numerical Settings\n",
    "Nt=ModelData.Ntime\n",
    "dt=times[1]*60\n",
    "#Height parcel must be below to be counted\n",
    "CLmaxheight=750 #750m\n",
    "#BL slow-down-threshold\n",
    "w_thresh=0.1\n",
    "def GetNp(parcel):\n",
    "    Np=len(parcel['xh'])\n",
    "    return Np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "68f5e82e-6419-49c5-901e-dc7de91030da",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# if ((x + dt*u)==0) or ((z + dt*w)==0)\n",
    "# u=u[t,Z[t,p],Y[t,p],X[t,p]]; W=W[t,p]\n",
    "# [u[t,Z[t,p],Y[t,p],X[t,p]] for t in time_arr] >np.max(data['xf'].values) or < np.min(data['xf'].values)\n",
    "# similarly for w\n",
    "################################################################################################################\n",
    "#BOUNDARY-ESCAPE CONDITION\n",
    "xmin=np.min(ModelData.xf)*1e3\n",
    "xmax=np.max(ModelData.xf)*1e3\n",
    "zmin=np.min(ModelData.zf)*1e3\n",
    "zmax=np.max(ModelData.zf)*1e3\n",
    "\n",
    "def check_boundary(p, where_BL, above_LFC,\n",
    "                   parcel_x, parcel_u, \n",
    "                   parcel_z, parcel_w,\n",
    "                   Z, Y, X):\n",
    "\n",
    "    time_arr=np.arange(where_BL,above_LFC)\n",
    "\n",
    "    def get_x(t,p):\n",
    "        # return parcel['x'][t,p].item()\n",
    "        return parcel_x[t,p] \n",
    "    def get_u(t,p):\n",
    "        # return data['uinterp'].isel(time=t,zh=Z[t,p],yh=Y[t,p],xh=X[t,p]).item() #TESTING\n",
    "        # return parcel['u'][t,p].item() \n",
    "        return parcel_u[t,p]\n",
    "    def get_z(t,p):\n",
    "        # return parcel['z'][t,p].item()\n",
    "        return parcel_z[t,p]\n",
    "    def get_w(t,p):\n",
    "        # return data['winterp'].isel(time=t,zh=Z[t,p],yh=Y[t,p],xh=X[t,p]).item()\n",
    "        # return parcel['w'][t,p].item()\n",
    "        return parcel_w[t,p]\n",
    "        \n",
    "\n",
    "    # x_tend = [get_x(t, p) + dt * get_u(t, z, y, x)   #THIS IS OLD, LESS IDEAL\n",
    "    #       for (t, z, y, x) in zip(time_arr, Z[time_arr, p], Y[time_arr, p], X[time_arr, p])] \n",
    "    # z_tend = [get_z(t, p) + dt * get_w(t, z, y, x)  \n",
    "    #       for (t, z, y, x) in zip(time_arr, Z[time_arr, p], Y[time_arr, p], X[time_arr, p])] \n",
    "    \n",
    "    x_tend = [get_x(t, p) + dt * get_u(t,p)   \n",
    "          for (t, z, y, x) in zip(time_arr, Z[time_arr, p], Y[time_arr, p], X[time_arr, p])] \n",
    "    z_tend = [get_z(t, p) + dt * get_w(t,p)  \n",
    "          for (t, z, y, x) in zip(time_arr, Z[time_arr, p], Y[time_arr, p], X[time_arr, p])] \n",
    "\n",
    "    x_bound=any(val < xmin or val > xmax for val in x_tend)*1\n",
    "    z_bound=any(val < zmin or val > zmax for val in z_tend)*1\n",
    "\n",
    "    out=(x_bound,z_bound)\n",
    "    if out[0]==1:\n",
    "        print(f'parcel {p} crossed x-boundary between t={where_BL} and t={above_LFC}')\n",
    "    elif out[1]==1:\n",
    "        print(f'parcel {p} crossed z-boundary between t={where_BL} and t={above_LFC}')\n",
    "    return out\n",
    "#############################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "387b950e-bac3-4933-9a40-095ca570d4a4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Initialize Output Storage Vector\n",
    "def InitializeData(Np):\n",
    "    out_arr=np.zeros((Np,3),dtype=np.int32) \n",
    "    save_arr=np.zeros((Np,3),dtype=np.int32) #This one is for saving continued-ascent, slow-below-750m parcels that are not with 2 km of CL\n",
    "    save2_arr=np.zeros((Np,3),dtype=np.int32) #This one is for saving continued-ascent, slow-above-750m parcels\n",
    "    return out_arr,save_arr,save2_arr\n",
    "# [out_arr,save_arr,save2_arr]=InitializeData(Np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e0eed3f-6b8c-4230-9abc-37e560986dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################################################\n",
    "#The Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b1f6fe0-558b-4087-8ba1-f6ca642d5b4e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ParcelTracking(Np,W,LFC,\n",
    "                   parcel_z,parcel_x,\n",
    "                   parcel_w,parcel_u, \n",
    "                   Z,Y,X,\n",
    "                   out_arr,save_arr,save2_arr,\n",
    "                   ascent_condition=False):\n",
    "    #1--------------Looping over each parcel\n",
    "    for count,p in enumerate(np.arange(Np)): \n",
    "        if np.mod(p,5e4)==0: print(f'current parcel: {p}/{Np}')\n",
    "\n",
    "        z_p = parcel_z[:,p]\n",
    "        W_p = W[:,p]\n",
    "        LFC_p = LFC[:,p] \n",
    "       \n",
    "        #----FIND WHERE PARCEL IS ABOVE LFC----\n",
    "        indices = np.where(z_p >= LFC_p)[0]; above_LFC = indices[0] if indices.size > 0 else -999; #FIRST TIME ABOVE LFC\n",
    "        if above_LFC ==-999:\n",
    "            # print(f'parcel {p} never above LFC')\n",
    "            continue #if the parcel is never above the LFC, skip the parcel\n",
    "\n",
    "        #----CHECK IF ASCENDS FOR >= 20 minutes AFTER LFC----\n",
    "        if ascent_condition == True:\n",
    "            #Note: currently set to False, so it doesn't matter how far above LFC a parcel rises\n",
    "            # This is because later there is a subsetting algorithm which further subsets parcels based on ascent\n",
    "            ascend_array=W_p[above_LFC+1:]\n",
    "            indices=np.where(ascend_array<0)[0]; ascend_stop=indices[0] if indices.size > 0 else 1e6; #location of where parcel stops ascending \n",
    "        else: \n",
    "            ascend_stop = 1e6\n",
    "        if ascend_stop>=20*minutes:\n",
    "        \n",
    "            #----FIND THE FIRST TIME W_p<=w_thresh----\n",
    "            indices=np.where(W_p[0:above_LFC]<w_thresh)[0]\n",
    "            where_BL=indices[-1] if indices.size > 0 else -999 #FIRST PRIOR TIME W<0.1 (IN THE BL) (ADDED 1 TO GET TIME RIGHT AFTER INTERACTION)\n",
    "            if where_BL ==-999:\n",
    "                # print(f'parcel {p} w is never below threshold prior to t={above_LFC}')\n",
    "                continue #if the parcel never slows down backwards in time (unlikely), skip the parcel\n",
    "                \n",
    "            #check for boundary escapes\n",
    "            ################################\n",
    "            future_location=check_boundary(p, where_BL, above_LFC,\n",
    "                                           parcel_x, parcel_u, \n",
    "                                           parcel_z, parcel_w,\n",
    "                                           Z, Y, X)\n",
    "            if (future_location[0]+future_location[1]>=1): continue #if parcel crosses boundary, skips current parcel\n",
    "            ################################\n",
    "            \n",
    "            #----CHECK IF PARCEL SLOWED DOWN LOW ENOUGH----\n",
    "            if parcel_z[where_BL,p]<=CLmaxheight: #PARCEL MUST BE BELOW 750m WHEN CONTACTING CL #***\n",
    "            # if LCL[where_BL,p]==0: #PARCEL MUST BE BELOW LCL WHEN CONTACTING CL (not recommended)\n",
    "        \n",
    "                #----CHECK IF CL IS WITHIN 2km----\n",
    "                #Find the CL-max x-location\n",
    "                t=where_BL; z=Z[where_BL,p]; y=Y[where_BL,p]; x=X[where_BL,p]\n",
    "                CONV_X=Get_Conv_X(t,z,y)\n",
    "                within_CL=np.any(np.isin(CONV_X, np.arange(x-2*kms,x+3*kms)))\n",
    "                \n",
    "                if within_CL==True:\n",
    "                    #save X's (t,p) \n",
    "                    print(f'Parcel {p} is success at time {where_BL}')\n",
    "                    out_arr[p,0]=p\n",
    "                    out_arr[p,1]=where_BL\n",
    "                    out_arr[p,2]=above_LFC \n",
    "                else: #continued-ascent, slow-below-750m parcels that are not with 2 km of CL\n",
    "                    #SAVE PARCEL\n",
    "                    # print(f'Parcel {p} not near CL at t={where_BL}')\n",
    "                    save_arr[p,0]=p\n",
    "                    save_arr[p,1]=where_BL\n",
    "                    save_arr[p,2]=above_LFC \n",
    "        \n",
    "            else: #continued-ascent, slow-above-750m parcels\n",
    "                #SAVE PARCEL\n",
    "                # print(f'Parcel {p} above {CLmaxheight}m at t={where_BL}')\n",
    "                save2_arr[p,0]=p\n",
    "                save2_arr[p,1]=where_BL\n",
    "                save2_arr[p,2]=above_LFC         \n",
    "                \n",
    "            #END OF LOOP, THEN WE MOVE ON TO NEXT PARCEL p\n",
    "    return out_arr,save_arr,save2_arr\n",
    "# [out_arr,save_arr,save2_arr]=ParcelTracking(Np,W,LFC,parcel_z,Z,Y,X,out_arr,save_arr,save2_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4eade392-bb34-4c0f-a93a-1cc1da5fea0b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def CorrectParcelID(out_arr,save_arr,save2_arr,index_adjust):\n",
    "    #CORRECTING DATA PARCEL ID BASED ON JOB NUMBER\n",
    "    #####################################################\n",
    "    out_arr[np.where(np.any(out_arr != 0, axis=1))[0],0]+=index_adjust #*needed for job array*+=index_adjust #*needed for job array*\n",
    "    save_arr[np.where(np.any(save_arr != 0, axis=1))[0],0]+=index_adjust #*needed for job array*+=index_adjust #*needed for job array*\n",
    "    save2_arr[np.where(np.any(save2_arr != 0, axis=1))[0],0]+=index_adjust #*needed for job array*+=index_adjust #*needed for job array*\n",
    "    return out_arr,save_arr,save2_arr\n",
    "# [out_arr,save_arr,save2_arr]=CorrectParcelID(out_arr,save_arr,save2_arr,index_adjust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "32b12a89-f869-4b35-81b5-5f1b56cacbc0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#REMOVING BLANK ROWS\n",
    "def RemoveZeroRows(arr):\n",
    "    arr = arr[~np.all(arr == 0, axis=1)]\n",
    "    return arr\n",
    "# out_arr=RemoveZeroRows(out_arr);save_arr=RemoveZeroRows(save_arr);save2_arr=RemoveZeroRows(save2_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2b9dd1af-32c7-4389-a1c6-ec1930730bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "#RUNNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a686e2cd-14ec-4a0c-83dc-844a9ec320eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RunAlgorithm(job_id_list):\n",
    "    for job_id in job_id_list:\n",
    "        if job_id % 1 == 0: print(f'current job_id = {job_id}')\n",
    "        [start_job,end_job,index_adjust]=SlurmJobArray_Class.StartJobArray(ModelData,job_id,num_jobs)\n",
    "        \n",
    "        #SLICING DATA\n",
    "        print(\"SLICING DATA\")\n",
    "        parcel=GetData(parcel1,start_job,end_job)\n",
    "    \n",
    "        #GETTING REQUIRED DATA\n",
    "        print(\"GETTING REQUIRED DATA\")\n",
    "        [parcel_z,parcel_x,parcel_u,parcel_w,Z,Y,X,W] = GetSpatialData(Lagrangian_Binary_Array_Data, start_job,end_job)\n",
    "        LFC,LCL = GetLFCData(LFC_LCL_Data, start_job,end_job)\n",
    "    \n",
    "        #INITIALIZING DATA\n",
    "        print(\"INITIALIZING DATA\")\n",
    "        Np=GetNp(parcel)\n",
    "        [out_arr,save_arr,save2_arr]=InitializeData(Np)\n",
    "    \n",
    "        #RUNNING ALGORITHM\n",
    "        print(\"RUNNING ALGORITHM\")\n",
    "        start_time = time.time()\n",
    "        if NO_PRINT==True: BlockPrint()\n",
    "        [out_arr,save_arr,save2_arr]=ParcelTracking(Np,W,LFC,\n",
    "                                                    parcel_z,parcel_x,\n",
    "                                                    parcel_w,parcel_u, \n",
    "                                                    Z,Y,X,\n",
    "                                                    out_arr,save_arr,save2_arr,\n",
    "                                                    ascent_condition=False)\n",
    "        if NO_PRINT==True: RestorePrint()\n",
    "        end_time = time.time(); elapsed_time = end_time - start_time; print(f\"Elapsed Time: {elapsed_time} seconds\")  \n",
    "    \n",
    "        #CORRECTING PARCEL ID FOR JOBARRAY\n",
    "        [out_arr,save_arr,save2_arr]=CorrectParcelID(out_arr,save_arr,save2_arr,index_adjust)\n",
    "    \n",
    "        #REMOVING BLANK ROWS FROMRESULTS\n",
    "        out_arr=RemoveZeroRows(out_arr);save_arr=RemoveZeroRows(save_arr);save2_arr=RemoveZeroRows(save2_arr)\n",
    "    \n",
    "        #SAVING\n",
    "        print(\"SAVING\")\n",
    "        Dictionary = {\"out_arr\": out_arr,\n",
    "                      \"save_arr\": save_arr,\n",
    "                      \"save2_arr\": save2_arr}\n",
    "        \n",
    "        Results_InputOutput_Class.SaveOutFile(ModelData,DataManager, Dictionary,job_id)\n",
    "    return Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2677b5c1-8300-40b4-961f-e8acfb0f98eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on Slurm_Jobs for Slurm_Job_Ids: (1, 5)\n",
      "current job_id = 1\n",
      "SLICING DATA\n",
      "GETTING REQUIRED DATA\n",
      "INITIALIZING DATA\n",
      "RUNNING ALGORITHM\n",
      "Elapsed Time: 3.1962413787841797 seconds\n",
      "SAVING\n",
      "Saved output to /mnt/lustre/koa/koastore/torri_group/air_directory/Projects/DCI-Project/Code/OUTPUT/Project_Algorithms/Tracking_Algorithms/1km_5min_34nz/Lagrangian_UpdraftTracking/Lagrangian_UpdraftTracking_1km_5min_34nz_job1.h5 \n",
      "\n",
      "Total Elapsed Time: 17.27579689025879 seconds\n"
     ]
    }
   ],
   "source": [
    "#starting job arrays\n",
    "[start_slurm_job,end_slurm_job]=SlurmJobArray_Class.StartSlurmJobArray(num_jobs=num_jobs,num_slurm_jobs=num_slurm_jobs,ISRUN=True) #if ISRUN is False, then will not run using slurm_job_array\n",
    "print(f\"Running on Slurm_Jobs for Slurm_Job_Ids: {(start_slurm_job,end_slurm_job-1)}\")\n",
    "job_id_list=np.arange(start_slurm_job,end_slurm_job)\n",
    "\n",
    "#running algorithm\n",
    "StartTime = time.time()\n",
    "Dictionary = RunAlgorithm(job_id_list)\n",
    "EndTime = time.time(); ElapsedTime = EndTime - StartTime; print(f\"Total Elapsed Time: {ElapsedTime} seconds\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf3e239-e1ec-411b-b5b3-62d69ce4059e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d45441b-f86b-493c-8d68-7cec57f1e011",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf62b3c-0f6c-41e6-9566-f33b9bb911b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bf7a78cc-b1ba-4495-a482-dc791048a1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "#Run after finishing job_array\n",
    "recombine=False #KEEP FALSE WHEN JOB_ARRAY IS RUNNING\n",
    "# recombine=True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a834896f-b2e3-4859-8bf5-8f00e42178b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakeUnique(arr):\n",
    "    return np.unique(arr, axis=0)\n",
    "\n",
    "def get_total_count(ModelData, DataManager, var_name, num_jobs):\n",
    "    \"\"\"\n",
    "    Sum the total length (axis 0) of `var_name` across all job output files\n",
    "    using LoadOutFile().\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    for job_id in range(1, num_jobs + 1):\n",
    "        try:\n",
    "            data_dict = Results_InputOutput_Class.LoadOutFile(ModelData, DataManager, job_id)\n",
    "            if var_name in data_dict:\n",
    "                total += data_dict[var_name].shape[0]\n",
    "            else:\n",
    "                print(f\"Warning: {var_name} not found in job {job_id}\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Warning: Missing file for job {job_id}\")\n",
    "            continue\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1e0c83bc-0063-4eae-80af-317f43baf3a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Recombine(num_jobs): #*#*\n",
    "    var_names = ['out_arr', 'save_arr', 'save2_arr']\n",
    "    recombined_arrays = {}  # Store final arrays here\n",
    "\n",
    "\n",
    "    # Preallocate arrays\n",
    "    for var_name in var_names:\n",
    "        total_count = get_total_count(ModelData, DataManager, var_name, num_jobs)\n",
    "        recombined_arrays[var_name] = np.zeros((total_count, 3), dtype=np.int32)\n",
    "\n",
    "    # Fill arrays\n",
    "    for var_name in var_names:\n",
    "        print(f\"Combining data for {var_name}\")\n",
    "        left_ind = 0\n",
    "        for job_id in range(1, num_jobs + 1):\n",
    "            # if job_id % 10 == 0: print(f\"{var_name}: processing job {job_id}\")\n",
    "            arr = Results_InputOutput_Class.LoadOutFile(ModelData, DataManager, job_id, varName=var_name)\n",
    "            n_rows = arr.shape[0]; right_ind = left_ind + n_rows\n",
    "            recombined_arrays[var_name][left_ind:right_ind, :] = arr\n",
    "            left_ind = right_ind\n",
    "\n",
    "    #Make Unique\n",
    "    for var_name in var_names:\n",
    "        recombined_arrays[var_name]=MakeUnique(recombined_arrays[var_name])\n",
    "        \n",
    "    # Write to file\n",
    "    Results_InputOutput_Class.SaveOutFile(ModelData,DataManager, recombined_arrays,job_id=\"combined\")\n",
    "\n",
    "    return recombined_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0f1b74d1-ba85-4b12-9e14-3100ba52fe1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining data for out_arr\n",
      "Combining data for save_arr\n",
      "Combining data for save2_arr\n",
      "Saved output to /mnt/lustre/koa/koastore/torri_group/air_directory/Projects/DCI-Project/Code/OUTPUT/Project_Algorithms/Tracking_Algorithms/1km_5min_34nz/Lagrangian_UpdraftTracking/Lagrangian_UpdraftTracking_1km_5min_34nz_jobcombined.h5 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "if recombine==True:\n",
    "    recombined_arrays = Recombine(num_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d599022-7a7c-4b97-9168-94781a663336",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddef9c75-2aa7-412b-9e51-9f589ada093c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f3c370-8799-468c-a40c-3fd5a6db9b28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6a25eeb2-6b94-436c-bff5-142551453075",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "#LOADING BACK IN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e6ea522e-734b-407b-9cfa-081d43743c8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'out_arr': array([[    18,     76,     80],\n",
       "        [    74,     65,     70],\n",
       "        [   126,     67,     73],\n",
       "        ...,\n",
       "        [999613,     77,     83],\n",
       "        [999635,     53,     57],\n",
       "        [999860,     87,     91]], shape=(14356, 3), dtype=int32),\n",
       " 'save2_arr': array([[   248,     43,     44],\n",
       "        [   483,     36,     37],\n",
       "        [   535,     43,     44],\n",
       "        ...,\n",
       "        [999763,     77,     78],\n",
       "        [999795,     43,     44],\n",
       "        [999972,     38,     39]], shape=(16787, 3), dtype=int32),\n",
       " 'save_arr': array([[    72,     65,     72],\n",
       "        [   149,     52,     57],\n",
       "        [   160,     54,     59],\n",
       "        ...,\n",
       "        [999952,     56,     61],\n",
       "        [999960,     52,     59],\n",
       "        [999967,     56,     60]], shape=(15312, 3), dtype=int32)}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dictionary = Results_InputOutput_Class.LoadOutFile(ModelData, DataManager, job_id=\"combined\")\n",
    "# Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ed181424-66eb-4849-80eb-6e71d2d71a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "#TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "1df4c7ea-c070-4198-b446-ff7b119404f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #comparing to old_version combined output\n",
    "\n",
    "# dir = \"/mnt/lustre/koa/koastore/torri_group/air_directory/Projects/DCI-Project/Code/CodeFiles/3_Project_Algorithms/2_Tracking_Algorithms/Old_Version/OUTPUT\"\n",
    "# fileName = \"parcel_tracking_1km_5min_1e6.h5\"\n",
    "# filePath = os.path.join(dir,fileName)\n",
    "\n",
    "# with h5py.File(filePath, 'r') as f:\n",
    "#     out_arr_OG = f[\"out_arr\"][:]\n",
    "#     save_arr_OG = f[\"save_arr\"][:]\n",
    "\n",
    "# Dictionary = Results_InputOutput_Class.LoadOutFile(ModelData, DataManager, job_id=\"combined\")\n",
    "\n",
    "# out_arr = Dictionary['out_arr']\n",
    "# save_arr = Dictionary['save_arr']\n",
    "\n",
    "# a = out_arr_OG[:, 0]\n",
    "# b = out_arr[:, 0]\n",
    "\n",
    "# setA = set(a)\n",
    "# setB = set(b)\n",
    "\n",
    "# # Elements that differ (not shared between both)\n",
    "# diffElements = setA.symmetric_difference(setB)\n",
    "\n",
    "# # Count how many unique differing values there are\n",
    "# numDifferences = len(diffElements)\n",
    "\n",
    "# print(\"Number of differing values (order ignored):\", numDifferences)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "work"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
