{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "229f8b57-48ba-4449-9377-367a271031cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cold pool tracking (step1-4) by Mingyue Tang\n",
    "## step 1 for tracking cold pools\n",
    "## already calculate density potential temperature\n",
    "# 4-D BFS \n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import glob\n",
    "import torch\n",
    "import time as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8eb7ba6-a180-4bff-8120-30a1c584cd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sensitive thresholds ########################################\n",
    "Nz_sc    = 10   # bottom 10 layers for PBL\n",
    "qp_thr_1 = 1.0/1000 #kg/kg   #*** \n",
    "cp_thr_1 = 1.0 #K(kg/kg)       #***\n",
    "\n",
    "####### read data #################################################\n",
    "path = '/mnt/lustre/koa/koastore/torri_group/air_directory/cold pool tracking/'\n",
    "path_3D = path+'*'\n",
    "list_of_paths = glob.glob(path_3D)\n",
    "list_of_paths.sort()\n",
    "\n",
    "nc_path_0 = [path for path in list_of_paths if path.split('/')[-1].startswith('QPDPTAnomaly')][0]\n",
    "ncfile_0 = xr.open_dataset(nc_path_0)\n",
    "x = ncfile_0[\"xh\"] #coordinates from euler (xh) also background wind speed\n",
    "y = ncfile_0[\"yh\"] \n",
    "z = ncfile_0[\"zh\"] \n",
    "z_sc = z[:Nz_sc]  #Only select PBL\n",
    "nt = len(ncfile_0['time']) # nt = len(list_of_paths) OLD\n",
    "time = range(0, nt, 1)\n",
    "\n",
    "x_grd = range(0, len(x), 1)\n",
    "y_grd = range(0, len(y), 1)\n",
    "z_grd = range(0, len(z_sc), 1)  \n",
    "\n",
    "################# Return variables ########################################\n",
    "flag_return  = np.ndarray( shape=(len(time), len(z), len(y_grd), len(x_grd)), dtype=int)\n",
    "cores_tzyx_gn = torch.zeros(0, 5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f31021de-57c3-4743-8dbb-1dd8aa1dd194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current time step: 0/79\n",
      "current time step: 25/79\n",
      "current time step: 50/79\n",
      "current time step: 75/79\n",
      "Total Elapsed Time: 347.4357056617737 seconds\n"
     ]
    }
   ],
   "source": [
    "################ Find cores at every time step 06/20/2022 ################### ******\n",
    "start_time=timer.time()\n",
    "for prnt,it in enumerate(range(nt)):\n",
    "    if np.mod(prnt,25)==0: print(f'current time step: {prnt}/{nt}')\n",
    "    # ncapth_i = list_of_paths[it] OLD\n",
    "    ncfile = ncfile_0.isel(time=it) # ncfile = xr.open_dataset(ncapth_i) OLD\n",
    "    flag_return_i = np.ndarray( shape=( len(z), len(y_grd), len(x_grd)), dtype=int)\n",
    "\n",
    "    thr_a = ncfile[\"DPTAnomaly\"] [:Nz_sc]  # PBL 10 levels\n",
    "    qp    = ncfile[\"QP\"] [:Nz_sc]          # PBL 10 levels\n",
    "\n",
    "    ## Flag cold cores\n",
    "    sum_tzyx =  len(z)*len(y)*len(x)\n",
    "    which_cold_core = np.where( (thr_a <= -cp_thr_1) & (qp >= qp_thr_1) )\n",
    "    flag_return_i[which_cold_core]  = 1  \n",
    "    flag_return[it,:,:,:] = flag_return_i[:,:,:]\n",
    "\n",
    "    ######## add flag_return as tensor to original tensor at every time step 06/23/2022 ########\n",
    "    cores_yzx_gn_it = torch.zeros(len(which_cold_core[0]), 5) \n",
    "    cores_yzx_gn_it[:,0] = it\n",
    "    for i in range(len(which_cold_core[0])):\n",
    "        for j in range(3):\n",
    "            cores_yzx_gn_it[i,j+1] = which_cold_core[j][i]\n",
    "\n",
    "    cores_tzyx_gn = torch.cat([cores_tzyx_gn, cores_yzx_gn_it], dim=0) \n",
    "end_time = timer.time(); elapsed_time = end_time - start_time; print(f\"Total Elapsed Time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9de64a8c-33e0-4462-a185-8839f9a7ee8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## save flag_return & gn_return  ######################################################\n",
    "# ds = xr.Dataset(\n",
    "#     data_vars = dict(\n",
    "#         flag_return = (['time','z','y','x'], flag_return), \n",
    "#     ),\n",
    "#     coords = dict(\n",
    "#         x = x.values,\n",
    "#         y = y.values,\n",
    "#         z = z.values,\n",
    "#         time = time,\n",
    "#     ),\n",
    "#     attrs=dict(description=\"flag cold cores without searching clusters\"),\n",
    "# )\n",
    "\n",
    "from datetime import datetime\n",
    "date=datetime.now()\n",
    "date=f'{date.strftime(\"%y\")}{date.strftime(\"%m\")}{date.strftime(\"%d\")}'\n",
    "# ds.to_netcdf(path+f'step1-FindFlag_Cores-{date}.nc')\n",
    "\n",
    "######## save flag_return as tensor ######################################################\n",
    "torch.save(cores_tzyx_gn, path+f'step1-findflag_cores_tzyx_tensor-{date}.pt') #88 bytes -- 11M"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
